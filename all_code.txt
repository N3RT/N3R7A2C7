# SNAPSHOT OF PROJECT FILES (TEXT)
# Each file is separated by a marker line: ## FILE: <relative_path>

## FILE: DEV_LOG.txt
[2026-02-05 11:59] –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∫–∞—Ä–∫–∞—Å–∞ –ø—Ä–æ–µ–∫—Ç–∞ rag_advct –∏ –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è —Å –ª–æ–∫–∞–ª—å–Ω–æ–π LLM —á–µ—Ä–µ–∑ ollama_chat_4b.
–°–µ–π—á–∞—Å —Å–æ—Å—Ç–æ—è–Ω–∏–µ —Ç–∞–∫–æ–µ (–≤—Å—ë —É–∂–µ –≤ –º–∞—Å—Ç–µ—Ä–µ –∏ –ø—Ä–æ—Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–æ):

–ö–æ–Ω—Ñ–∏–≥–∏ –∏ –æ–∫—Ä—É–∂–µ–Ω–∏–µ

config/system.yaml —Å environment=dev –∏ –ø—É—Ç—è–º–∏ –¥–ª—è data/chromadb/sqlite/logs.

config/tasks/demo_hello.yaml, config/tasks/demo_rules.yaml ‚Äî –¥–≤–µ demo-–∑–∞–¥–∞—á–∏ —Å technical_prompt.

–Ø–¥—Ä–æ –∏ RAG

app/core/config_loader.py ‚Äî –∑–∞–≥—Ä—É–∑–∫–∞ system.yaml.

app/core/task_config.py ‚Äî TaskConfig + load_task_config.

app/core/task_registry.py ‚Äî registry, —Å–∫–∞–Ω–∏—Ä—É–µ—Ç config/tasks/*.yaml, –æ—Ç–¥–∞—ë—Ç RegisteredTask.

app/core/access_control.py ‚Äî –ø—Ä–∞–≤–∏–ª–∞ demo/corporate + env.

app/core/chroma_client.py ‚Äî –∫–ª–∏–µ–Ω—Ç ChromaDB —Å persistent storage.

app/core/rag_pipeline.py ‚Äî –¥–≤–µ –∫–æ–ª–ª–µ–∫—Ü–∏–∏ (demo_hello_texts, demo_rules_texts), –º–∏–Ω–∏–º–∞–ª—å–Ω—ã–π retrieval –∏ —Å–±–æ—Ä —Å–∏—Å—Ç–µ–º–Ω–æ–≥–æ –ø—Ä–æ–º–ø—Ç–∞.

API –∏ CLI

app/main.py ‚Äî FastAPI, /api/v1/health, –ø–æ–¥–∫–ª—é—á–µ–Ω–∏–µ —Ä–æ—É—Ç–µ—Ä–∞.

app/api/v1/routes.py ‚Äî

GET /api/v1/health (—á–µ—Ä–µ–∑ main);

GET /api/v1/tasks –∏ GET /api/v1/tasks/{task_id};

POST /api/v1/task/query —Å TaskRegistry + AccessControl + RAG + LLM.
‚Äã

app/cli/admin_cli.py ‚Äî env, task-info <task_id>, tasks-loaded.

–ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è —Å LLM

llm_connectors/connector_dev.py ‚Äî –≤—ã–∑–æ–≤ –ª–æ–∫–∞–ª—å–Ω–æ–≥–æ ollama_chat_4b —á–µ—Ä–µ–∑ httpx, —Ä–µ–∂–∏–º dev.
‚Äã

–ò–Ω—Ñ—Ä–∞—Å—Ç—Ä—É–∫—Ç—É—Ä–∞

requirements.txt –∑–∞—Ñ–∏–∫—Å–∏—Ä–æ–≤–∞–Ω —á–µ—Ä–µ–∑ pip list --format=freeze.

tests/test_api.py ‚Äî 5 —Ç–µ—Å—Ç–æ–≤, pytest -q ‚Üí 5 passed.
‚Äã
‚Äã

code_collector.py + all_code.txt, DEV_LOG.txt –≤–µ–¥—É—Ç—Å—è –ø–æ –≤–∞–π–±–∫–æ–¥–∏–Ω–≥—É.

–ö–∞–∫ –º—ã –≤–∑–∞–∏–º–æ–¥–µ–π—Å—Ç–≤—É–µ–º –¥–∞–ª—å—à–µ (—á–µ—Ä–µ–∑ cat –∏ –∫–æ–º–∞–Ω–¥—ã)
–í–æ—Ç –¥–æ–≥–æ–≤–æ—Ä—ë–Ω–Ω—ã–π workflow, –∫–æ—Ç–æ—Ä—ã–π –º—ã —É–∂–µ –ø—Ä–∏–¥–µ—Ä–∂–∏–≤–∞–µ–º—Å—è –∏ –±—É–¥–µ–º –¥–∞–ª—å—à–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å:
‚Äã

–Ø –¥–∞—é –≥–æ—Ç–æ–≤—ã–µ –∫–æ–º–∞–Ω–¥—ã —Å cat

–§–æ—Ä–º–∞—Ç –¥–ª—è –∫–æ–¥–∞:

bash
cat > app/core/some_module.py << 'EOF'
# –∑–¥–µ—Å—å –≥–æ—Ç–æ–≤—ã–π –∫–æ–¥
EOF
–¢—ã –ø—Ä–æ—Å—Ç–æ –∫–æ–ø–∏—Ä—É–µ—à—å —ç—Ç–æ—Ç –±–ª–æ–∫ —Ü–µ–ª–∏–∫–æ–º –≤ —Ç–µ—Ä–º–∏–Ω–∞–ª ‚Üí —Ñ–∞–π–ª —Å–æ–∑–¥–∞—ë—Ç—Å—è/–ø–µ—Ä–µ–∑–∞–ø–∏—Å—ã–≤–∞–µ—Ç—Å—è —Å—Ä–∞–∑—É –≤ –Ω—É–∂–Ω–æ–º –≤–∏–¥–µ.
‚Äã

–Ø–≤–Ω–æ–µ —Ä–∞–∑–¥–µ–ª–µ–Ω–∏–µ —Ç–∏–ø–æ–≤ –∫–æ–º–∞–Ω–¥

–°–æ–∑–¥–∞—Ç—å/–æ–±–Ω–æ–≤–∏—Ç—å —Ñ–∞–π–ª ‚Äî –≤—Å–µ–≥–¥–∞ —á–µ—Ä–µ–∑ —Ç–∞–∫–æ–π cat > ... << 'EOF' –±–ª–æ–∫.

–ó–∞–ø—É—Å—Ç–∏—Ç—å —Å–µ—Ä–≤–∏—Å/CLI/—Ç–µ—Å—Ç—ã ‚Äî –¥–∞—é —á–∏—Å—Ç—ã–µ –∫–æ–º–∞–Ω–¥—ã:

bash
uvicorn app.main:app --reload --host 0.0.0.0 --port 8000
python -m app.cli.admin_cli env
pytest -q
–¢—ã –∏—Ö –∫–æ–ø–∏—Ä—É–µ—à—å –∏ –∑–∞–ø—É—Å–∫–∞–µ—à—å –±–µ–∑ –∏–∑–º–µ–Ω–µ–Ω–∏–π.

–§–∏–∫—Å–∞—Ü–∏—è —à–∞–≥–æ–≤ –≤ –ª–æ–≥–∞—Ö/–∫–æ–¥–µ

–ü–æ—Å–ª–µ –ª–æ–≥–∏—á–µ—Å–∫–∏ –∑–∞–≤–µ—Ä—à—ë–Ω–Ω–æ–≥–æ —à–∞–≥–∞ (—Ñ–∏—á–∞/–∏–∑–º–µ–Ω–µ–Ω–∏–µ):

–Ø –¥–∞—é —Ç–µ–∫—Å—Ç –±–ª–æ–∫–∞ –¥–ª—è DEV_LOG.txt ‚Äî —Ç—ã –¥–æ–±–∞–≤–ª—è–µ—à—å –µ–≥–æ —á–µ—Ä–µ–∑ —Å–≤–æ–π —Å—Ü–µ–Ω–∞—Ä–∏–π (–∏–ª–∏ —Ä—É–∫–∞–º–∏).

–¢—ã –∑–∞–ø—É—Å–∫–∞–µ—à—å:

bash
python code_collector.py
–Ø –¥–∞—é —Ç–æ—á–Ω—ã–π git add ... && git commit -m "..." && git push, —Ç—ã –∫–æ–ø–∏—Ä—É–µ—à—å.

–ü—Ä–æ–≤–µ—Ä–∫–∞ API –∏ CLI

–î–ª—è –∫–∞–∂–¥–æ–≥–æ –Ω–æ–≤–æ–≥–æ —ç–Ω–¥–ø–æ–∏–Ω—Ç–∞/—Ñ–∏—á–∏ —è —Å—Ä–∞–∑—É –¥–∞—é –≥–æ—Ç–æ–≤—ã–µ curl/CLI-–∫–æ–º–∞–Ω–¥—ã, –Ω–∞–ø—Ä–∏–º–µ—Ä:

bash
curl http://127.0.0.1:8000/api/v1/tasks
curl -X POST http://127.0.0.1:8000/api/v1/task/query ...
python -m app.cli.admin_cli task-info demo_hello
–¢—ã –∑–∞–ø—É—Å–∫–∞–µ—à—å –∏ —Å–∫–∏–¥—ã–≤–∞–µ—à—å –º–Ω–µ –ª–æ–≥ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è (–∫–∞–∫ —É–∂–µ –¥–µ–ª–∞–ª–∏).

–¢–µ—Å—Ç—ã

–ù–æ–≤—ã–π —Ñ—É–Ω–∫—Ü–∏–æ–Ω–∞–ª —Å—Ç–∞—Ä–∞–µ–º—Å—è –Ω–∞–∫—Ä—ã–≤–∞—Ç—å —Ç–µ—Å—Ç–æ–º –≤ tests/test_api.py.

–Ø –¥–∞—é –ø–æ–ª–Ω—ã–π –±–ª–æ–∫ cat > tests/test_api.py << 'EOF' ... EOF (–∏–ª–∏ –¥–æ–±–∞–≤–ª–µ–Ω–∏–µ –Ω–æ–≤–æ–≥–æ —Ç–µ—Å—Ç–∞) + –∫–æ–º–∞–Ω–¥—É pytest -q.



1. –°—Ç—Ä—É–∫—Ç—É—Ä–∞ –ø—Ä–æ–µ–∫—Ç–∞
- –°–æ–∑–¥–∞–Ω –±–∞–∑–æ–≤—ã–π –∫–∞—Ä–∫–∞—Å –∫–∞—Ç–∞–ª–æ–≥–∞ rag_advct –ø–æ –¢–ó RAG-—Å–∏—Å—Ç–µ–º—ã:
  - app/ (–∏—Å—Ö–æ–¥–Ω–∏–∫–∏ —Å–µ—Ä–≤–∏—Å–∞)
  - app/api/, app/core/, app/ingestion/, app/postprocessing/, app/bot/, app/cli/
  - config/ (system.yaml + –∑–∞–≥–æ—Ç–æ–≤–∫–∞ –¥–ª—è tasks/)
  - data/ (data/.gitkeep, –ø–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –ø–æ–¥ chromadb/sqlite/logs)
  - docker/ (Dockerfile, docker-compose.dev.yml ‚Äì –ø–æ–∫–∞ –ø—É—Å—Ç—ã–µ –∑–∞–≥–ª—É—à–∫–∏)
  - llm_connectors/ (–º–æ–¥—É–ª–∏ –¥–ª—è –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è –∫ LLM)
  - tests/ (test_api.py ‚Äì –∑–∞–≥–æ—Ç–æ–≤–∫–∞)
- –í .gitignore –¥–æ–±–∞–≤–ª–µ–Ω—ã:
  - .env
  - –∫–∞—Ç–∞–ª–æ–≥ data/ (–∫—Ä–æ–º–µ data/.gitkeep)
  - *.log, –≤—Ä–µ–º–µ–Ω–Ω—ã–µ *.md.tmp, *.docx
  - all_code.py, DEV_LOG.txt, PROJECT_PLAN.txt
  —á—Ç–æ–±—ã –≤ —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–∏ –Ω–µ –±—ã–ª–æ –ª–æ–∫–∞–ª—å–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö, –ª–æ–≥–æ–≤ –∏ —Å–Ω–∞–ø—à–æ—Ç–æ–≤.

2. –í–∏—Ä—Ç—É–∞–ª—å–Ω–æ–µ –æ–∫—Ä—É–∂–µ–Ω–∏–µ –∏ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏
- –°–æ–∑–¥–∞–Ω–æ –≤–∏—Ä—Ç—É–∞–ª—å–Ω–æ–µ –æ–∫—Ä—É–∂–µ–Ω–∏–µ .venv –≤ –∫–æ—Ä–Ω–µ –ø—Ä–æ–µ–∫—Ç–∞.
- –í .venv —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω—ã:
  - fastapi[standard]
  - uvicorn
  - requests
  - httpx
- –í—Å–µ –¥–∞–ª—å–Ω–µ–π—à–∏–µ –∫–æ–º–∞–Ω–¥—ã —Ä–∞–∑—Ä–∞–±–æ—Ç–∫–∏ –∏ –∑–∞–ø—É—Å–∫–∞ —Å–µ—Ä–≤–∏—Å–∞ –≤—ã–ø–æ–ª–Ω—è—é—Ç—Å—è —á–µ—Ä–µ–∑:
  - source .venv/bin/activate

3. –°–∏—Å—Ç–µ–º–Ω–∞—è –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è
- –°–æ–∑–¥–∞–Ω —Ñ–∞–π–ª config/system.yaml —Å –±–∞–∑–æ–≤—ã–º–∏ –Ω–∞—Å—Ç—Ä–æ–π–∫–∞–º–∏:
  - environment: dev
  - paths:
      data_root: ./data
      chromadb_dir: ./data/chromadb
      sqlite_path: ./data/sqlite/tables.db
      logs_path: ./data/logs/app.log
  - llm:
      mode: dev
      connector: "llm_connectors.connector_dev:call_llm"
- –≠—Ç–æ –∑–∞–≥–æ—Ç–æ–≤–∫–∞ –¥–ª—è –±—É–¥—É—â–µ–≥–æ –∫–æ–Ω—Ñ–∏–≥-–ª–æ–∞–¥–µ—Ä–∞ –∏ –ø–µ—Ä–µ–∫–ª—é—á–µ–Ω–∏—è —Ä–µ–∂–∏–º–æ–≤ (dev/test/prod) —Å—Ç—Ä–æ–≥–æ —á–µ—Ä–µ–∑ –∫–æ–Ω—Ñ–∏–≥, –∫–∞–∫ –æ–ø–∏—Å–∞–Ω–æ –≤ –¢–ó.

4. –ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è —Å –ª–æ–∫–∞–ª—å–Ω–æ–π LLM —á–µ—Ä–µ–∑ ollama_chat_4b
- –ü—Ä–∏–Ω—è—Ç–æ —Ä–µ—à–µ–Ω–∏–µ –æ—Ç–∫–∞–∑–∞—Ç—å—Å—è –æ—Ç –≤–Ω–µ—à–Ω–∏—Ö API (DeepSeek/OpenRouter) –≤ dev –∏–∑-–∑–∞ –æ—Ç—Å—É—Ç—Å—Ç–≤–∏—è —Å—Ç–∞–±–∏–ª—å–Ω–æ–≥–æ –±–µ—Å–ø–ª–∞—Ç–Ω–æ–≥–æ –ª–∏–º–∏—Ç–∞ –∏ –∑–∞–≤—è–∑–∫–∏ –Ω–∞ –±–∏–ª–ª–∏–Ω–≥.
- –í –∫–∞—á–µ—Å—Ç–≤–µ dev-LLM –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –ª–æ–∫–∞–ª—å–Ω—ã–π —Å—Ç–µ–∫:
  - –¥–≤–∏–∂–æ–∫ Ollama —Å –º–æ–¥–µ–ª—è–º–∏ llama3.2:1b –∏ llama3.2:3b
  - –æ—Ç–¥–µ–ª—å–Ω—ã–π —Å–µ—Ä–≤–∏—Å ollama_chat_4b (FastAPI + uvicorn) —Å HTTP API:
    - POST http://127.0.0.1:4004/api/chat
    - —Ç–µ–ª–æ: {"messages": [...], "model": "llama3.2:1b"|"llama3.2:3b" (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)}
    - –æ—Ç–≤–µ—Ç: {"reply": "...", "raw": {... –ø–æ–ª–Ω—ã–π –æ—Ç–≤–µ—Ç Ollama ...}}
- –í rag_advct —Å–æ–∑–¥–∞–Ω –∫–æ–Ω–Ω–µ–∫—Ç–æ—Ä llm_connectors/connector_dev.py:
  - –∏—Å–ø–æ–ª—å–∑—É–µ—Ç httpx.AsyncClient —Å —Ç–∞–π–º–∞—É—Ç–æ–º 120 —Å–µ–∫—É–Ω–¥
  - —á–∏—Ç–∞–µ—Ç OLLAMA_CHAT_URL –∏–∑ –æ–∫—Ä—É–∂–µ–Ω–∏—è (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é http://127.0.0.1:4004/api/chat)
  - —Ñ—É–Ω–∫—Ü–∏—è async call_llm(messages, model=None):
    - –æ—Ç–ø—Ä–∞–≤–ª—è–µ—Ç messages –≤ —Ñ–æ—Ä–º–∞—Ç–µ OpenAI (role/content) –Ω–∞ –ª–æ–∫–∞–ª—å–Ω—ã–π —Å–µ—Ä–≤–∏—Å
    - –ø—Ä–∏ model != None –¥–æ–±–∞–≤–ª—è–µ—Ç –ø–æ–ª–µ "model" –≤ –∑–∞–ø—Ä–æ—Å (–Ω–∞–ø—Ä–∏–º–µ—Ä "llama3.2:1b" –∏–ª–∏ "llama3.2:3b")
    - –æ–∂–∏–¥–∞–µ—Ç –æ—Ç–≤–µ—Ç {"reply": "...", "raw": {...}}
    - –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç dict –≤ —Ñ–æ—Ä–º–∞—Ç–µ, —Å–æ–≤–º–µ—Å—Ç–∏–º–æ–º —Å OpenAI:
      {
        "model": <–∏–º—è –º–æ–¥–µ–ª–∏ –∏–ª–∏ "default">,
        "choices": [
          {"message": {"role": "assistant", "content": reply}}
        ],
        "raw": <–æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–π –æ—Ç–≤–µ—Ç —Å–µ—Ä–≤–∏—Å–∞>
      }
    - –≤ —Å–ª—É—á–∞–µ –æ—à–∏–±–∫–∏ —Å—Ç–∞—Ç—É—Å–∞ –≤—ã–±—Ä–∞—Å—ã–≤–∞–µ—Ç LLMError —Å —Ç–µ–∫—Å—Ç–æ–º –≤–∏–¥–∞ "ollama_chat_4b error <code>: <body>"

5. –û—Å–Ω–æ–≤–Ω–æ–π FastAPI-—Å–µ—Ä–≤–∏—Å (app/main.py)
- –†–µ–∞–ª–∏–∑–æ–≤–∞–Ω–æ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–µ FastAPI, –∫–æ—Ç–æ—Ä–æ–µ –≤ –±—É–¥—É—â–µ–º —Å—Ç–∞–Ω–µ—Ç REST-—Å–µ—Ä–≤–∏—Å–æ–º RAG:
  - title="RAG Service", version="0.1.0"
- –î–æ–±–∞–≤–ª–µ–Ω —ç–Ω–¥–ø–æ–∏–Ω—Ç GET /api/v1/health:
  - –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç JSON:
    {
      "status": "ok",
      "environment": "dev",
      "chromadb": "unknown",
      "sqlite": "unknown",
      "llm_mode": "ollama_chat_4b",
      "uptime_seconds": 0
    }
  - –ø–æ–∫–∞ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –∫–∞–∫ –ø—Ä–æ—Å—Ç–æ–π health-check –±–µ–∑ —Ä–µ–∞–ª—å–Ω–æ–≥–æ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è –∫ –ë–î/ChromaDB.
- –î–æ–±–∞–≤–ª–µ–Ω —Ç–µ—Å—Ç–æ–≤—ã–π —ç–Ω–¥–ø–æ–∏–Ω—Ç GET /api/v1/llm_test:
  - –≤—ã–∑—ã–≤–∞–µ—Ç async call_llm –∏–∑ llm_connectors/connector_dev.py
  - –ø–µ—Ä–µ–¥–∞—ë—Ç –æ–¥–Ω–æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å—Å–∫–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ "–°–∫–∞–∂–∏ –æ–¥–Ω–æ —Å–ª–æ–≤–æ: —Ç–µ—Å—Ç."
  - –ø—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω–æ –∑–∞–¥–∞—ë—Ç model="llama3.2:1b"
  - –∏–∑–≤–ª–µ–∫–∞–µ—Ç —Ç–µ–∫—Å—Ç –æ—Ç–≤–µ—Ç–∞ –∏–∑ resp["choices"][0]["message"]["content"]
  - –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç JSON:
    - {"ok": True, "answer": "<–æ—Ç–≤–µ—Ç –ª–æ–∫–∞–ª—å–Ω–æ–π –º–æ–¥–µ–ª–∏>"} –ø—Ä–∏ —É—Å–ø–µ—Ö–µ
    - {"ok": False, "error": "<—Ç–µ–∫—Å—Ç –æ—à–∏–±–∫–∏>"} –ø—Ä–∏ –∏—Å–∫–ª—é—á–µ–Ω–∏–∏ LLMError
- –≠–Ω–¥–ø–æ–∏–Ω—Ç /api/v1/llm_test —É—Å–ø–µ—à–Ω–æ –ø—Ä–æ–≤–µ—Ä–µ–Ω —á–µ—Ä–µ–∑ curl:
  - –ø—Ä–∏ –∑–∞–ø—É—â–µ–Ω–Ω—ã—Ö ollama –∏ ollama_chat_4b –≤–æ–∑–≤—Ä–∞—Ç:
    {"ok": true, "answer": "–¢–µ—Å—Ç - ..."} (–∂–∏–≤–æ–π –æ—Ç–≤–µ—Ç –ª–æ–∫–∞–ª—å–Ω–æ–π –º–æ–¥–µ–ª–∏),
    —á—Ç–æ –ø–æ–¥—Ç–≤–µ—Ä–∂–¥–∞–µ—Ç —Ä–∞–±–æ—á—É—é —Å–≤—è–∑–∫—É rag_advct ‚Üí ollama_chat_4b ‚Üí Ollama.

6. .env –∏ –æ–∫—Ä—É–∂–µ–Ω–∏–µ
- –¢–µ–∫—É—â–∏–π .env —Å–æ–¥–µ—Ä–∂–∏—Ç –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ –¥–ª—è –ª–æ–∫–∞–ª—å–Ω–æ–π –∏–Ω—Ñ—Ä–∞—Å—Ç—Ä—É–∫—Ç—É—Ä—ã:
  - OLLAMA_CHAT_URL=http://127.0.0.1:4004/api/chat
- –ü–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –æ–∫—Ä—É–∂–µ–Ω–∏—è –¥–ª—è rag_advct —Å–µ–π—á–∞—Å –º–∏–Ω–∏–º–∞–ª—å–Ω—ã, –≤–Ω–µ—à–Ω–∏–µ —Å–µ—Ä–≤–∏—Å—ã LLM –æ—Ç–∫–ª—é—á–µ–Ω—ã.

7. –ò—Ç–æ–≥–∏ —à–∞–≥–∞
- –ï—Å—Ç—å —Ä–∞–±–æ—á–∏–π –∫–∞—Ä–∫–∞—Å —Å–µ—Ä–≤–∏—Å–∞ rag_advct:
  - FastAPI-–ø—Ä–∏–ª–æ–∂–µ–Ω–∏–µ —Å health-—ç–Ω–¥–ø–æ–∏–Ω—Ç–æ–º –∏ —Ç–µ—Å—Ç–æ–º –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–∏ LLM.
  - –ö–æ–Ω–Ω–µ–∫—Ç–æ—Ä –∫ –ª–æ–∫–∞–ª—å–Ω–æ–º—É LLM-—Å–µ—Ä–≤–∏—Å—É ollama_chat_4b.
  - –í–∏—Ä—Ç—É–∞–ª—å–Ω–æ–µ –æ–∫—Ä—É–∂–µ–Ω–∏–µ –∏ –±–∞–∑–æ–≤–∞—è –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è system.yaml –¥–ª—è –¥–∞–ª—å–Ω–µ–π—à–µ–π —Ä–µ–∞–ª–∏–∑–∞—Ü–∏–∏ TaskConfig, RAG-–ø–∞–π–ø–ª–∞–π–Ω–∞ –∏ —Ä–µ–∂–∏–º–æ–≤ prod/dev/test.
- –°–ª–µ–¥—É—é—â–∏–π —à–∞–≥ (–≤ –æ—Ç–¥–µ–ª—å–Ω–æ–π –≤–µ—Ç–∫–µ):
  - —Ä–µ–∞–ª–∏–∑–æ–≤–∞—Ç—å config_loader –∏ –º–æ–¥–µ–ª—å TaskConfig –ø–æ –¢–ó,
  - –¥–æ–±–∞–≤–∏—Ç—å —ç–Ω–¥–ø–æ–∏–Ω—Ç /api/v1/task/query, –∫–æ—Ç–æ—Ä—ã–π –±—É–¥–µ—Ç –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏–π –ø—Ä–æ–º–ø—Ç –∑–∞–¥–∞—á–∏ –∏ –ª–æ–∫–∞–ª—å–Ω—É—é LLM —á–µ—Ä–µ–∑ –∫–æ–Ω–Ω–µ–∫—Ç–æ—Ä.


[2026-02-05 13:02] –î–µ–º–æ-—ç–Ω–¥–ø–æ–∏–Ω—Ç /api/v1/task/query –∏ –∫–æ–Ω—Ñ–∏–≥-–ª–æ–∞–¥–µ—Ä.

1. –ö–æ–Ω—Ñ–∏–≥-–ª–æ–∞–¥–µ—Ä
- –î–æ–±–∞–≤–ª–µ–Ω –º–æ–¥—É–ª—å app/core/config_loader.py –Ω–∞ –±–∞–∑–µ pathlib + yaml.safe_load.
- –†–µ–∞–ª–∏–∑–æ–≤–∞–Ω –∫—ç—à–∏—Ä—É–µ–º—ã–π load_system_config –∏ —Ö–µ–ª–ø–µ—Ä—ã get_environment, get_llm_mode, get_llm_connector_path.
- –ö–æ–Ω—Ñ–∏–≥ —á–∏—Ç–∞–µ—Ç—Å—è –∏–∑ config/system.yaml, –≤–∞–ª–∏–¥–∞—Ü–∏—è environment (dev/test/prod).

2. API /api/v1/task/query
- –î–æ–±–∞–≤–ª–µ–Ω —Ä–æ—É—Ç–µ—Ä app/api/v1/routes.py —Å APIRouter(prefix="/api/v1").
- –û–ø–∏—Å–∞–Ω—ã –º–æ–¥–µ–ª–∏ TaskQueryRequest/TaskQueryResponse –Ω–∞ Pydantic v2 (pattern –¥–ª—è task_type).
- –†–µ–∞–ª–∏–∑–æ–≤–∞–Ω POST /api/v1/task/query:
  - –±–ª–æ–∫–∏—Ä—É–µ—Ç –∫–æ—Ä–ø–æ—Ä–∞—Ç–∏–≤–Ω—ã–µ –∑–∞–¥–∞—á–∏ (task_type=corporate) –ø—Ä–∏ environment != prod;
  - –¥–ª—è demo-–∑–∞–¥–∞—á –≤ dev –≤—ã–∑—ã–≤–∞–µ—Ç –ª–æ–∫–∞–ª—å–Ω—É—é LLM —á–µ—Ä–µ–∑ call_llm —Å –ø—Ä–æ—Å—Ç—ã–º —Å–∏—Å—Ç–µ–º–Ω—ã–º –ø—Ä–æ–º–ø—Ç–æ–º;
  - –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç JSON {ok, answer|error}.

3. –ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è —Å FastAPI
- –í app/main.py –ø–æ–¥–∫–ª—é—á–µ–Ω —Ä–æ—É—Ç–µ—Ä api_v1_router.
- –≠–Ω–¥–ø–æ–∏–Ω—Ç /api/v1/health –∏—Å–ø–æ–ª—å–∑—É–µ—Ç get_environment –∏ get_llm_mode –∏–∑ –∫–æ–Ω—Ñ–∏–≥-–ª–æ–∞–¥–µ—Ä–∞.
- –ü—Ä–æ–≤–µ—Ä–µ–Ω—ã —Ä—É—á–∫–∏ —á–µ—Ä–µ–∑ curl:
  - /api/v1/health –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å—Ç–∞—Ç—É—Å ok –∏ environment=dev;
  - /api/v1/task/query —Å demo-–∑–∞–¥–∞—á–µ–π –æ—Ç–¥–∞–µ—Ç –æ—Ç–≤–µ—Ç –ª–æ–∫–∞–ª—å–Ω–æ–π –º–æ–¥–µ–ª–∏;
  - /api/v1/task/query —Å corporate-–∑–∞–¥–∞—á–µ–π –≤ dev –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç 403 "–ö–æ—Ä–ø–æ—Ä–∞—Ç–∏–≤–Ω—ã–µ –∑–∞–¥–∞—á–∏ —Ä–∞–∑—Ä–µ—à–µ–Ω—ã —Ç–æ–ª—å–∫–æ –≤ —Ä–µ–∂–∏–º–µ prod".


[2026-02-05 13:05] TaskConfig –∏ —Ñ–∞–π–ª–æ–≤—ã–µ –∫–æ–Ω—Ñ–∏–≥–∏ –∑–∞–¥–∞—á.

1. –ú–æ–¥–µ–ª—å TaskConfig
- –î–æ–±–∞–≤–ª–µ–Ω –º–æ–¥—É–ª—å app/core/task_config.py.
- –†–µ–∞–ª–∏–∑–æ–≤–∞–Ω–∞ dataclass-–º–æ–¥–µ–ª—å TaskConfig —Å –ø–æ–ª—è–º–∏ task_id, name, description, task_type, technical_prompt.
- –î–æ–±–∞–≤–ª–µ–Ω load_task_config(task_id), –∫–æ—Ç–æ—Ä—ã–π —á–∏—Ç–∞–µ—Ç config/tasks/<task_id>.yaml –∏ –≤–∞–ª–∏–¥–∏—Ä—É–µ—Ç task_type (demo/corporate).

2. –ö–æ–Ω—Ñ–∏–≥ –∑–∞–¥–∞—á–∏ demo_hello
- –°–æ–∑–¥–∞–Ω –∫–∞—Ç–∞–ª–æ–≥ config/tasks.
- –î–æ–±–∞–≤–ª–µ–Ω —Ñ–∞–π–ª config/tasks/demo_hello.yaml —Å –º–∏–Ω–∏–º–∞–ª—å–Ω—ã–º TaskConfig:
  - task_id=demo_hello, task_type=demo;
  - —á–µ–ª–æ–≤–µ–∫–æ—á–∏—Ç–∞–µ–º—ã–µ name/description;
  - technical_prompt —Å –±–∏–∑–Ω–µ—Å-–æ–ø–∏—Å–∞–Ω–∏–µ–º –¥–µ–º–æ-—Å–∏—Å—Ç–µ–º—ã –∑–∞—è–≤–æ–∫.

3. –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ /api/v1/task/query
- –≠–Ω–¥–ø–æ–∏–Ω—Ç /api/v1/task/query –ø–µ—Ä–µ–∫–ª—é—á—ë–Ω –Ω–∞ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ TaskConfig:
  - –≥—Ä—É–∑–∏—Ç –∫–æ–Ω—Ñ–∏–≥ –ø–æ task_id —á–µ—Ä–µ–∑ load_task_config;
  - –ø—Ä–æ–≤–µ—Ä—è–µ—Ç —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ request.task_type –∏ TaskConfig.task_type;
  - –±–ª–æ–∫–∏—Ä—É–µ—Ç corporate-–∑–∞–¥–∞—á–∏ –ø—Ä–∏ environment != prod;
  - –¥–ª—è demo-–∑–∞–¥–∞—á –≤ dev –≤—ã–∑—ã–≤–∞–µ—Ç –ª–æ–∫–∞–ª—å–Ω—É—é LLM —Å —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏–º –ø—Ä–æ–º–ø—Ç–æ–º –∏–∑ TaskConfig.
- –ü—Ä–æ–≤–µ—Ä–∫–∞ —á–µ—Ä–µ–∑ curl —Å task_id=demo_hello –≤–µ—Ä–Ω—É–ª–∞ –æ—Å–º—ã—Å–ª–µ–Ω–Ω—ã–π –±–∏–∑–Ω–µ—Å-–æ—Ç–≤–µ—Ç –æ –¥–µ–º–æ-—Å–∏—Å—Ç–µ–º–µ –∑–∞—è–≤–æ–∫.

[2026-02-05 14:38] –ú–∏–Ω–∏–º–∞–ª—å–Ω—ã–π demo-RAG –Ω–∞ ChromaDB –∏ —Ñ–∏–∫—Å–∞—Ü–∏—è –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π.

1. ChromaDB –∏ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏
- –í .venv —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω—ã chromadb –∏ sentence-transformers –¥–ª—è —Ä–µ–∞–ª–∏–∑–∞—Ü–∏–∏ —Ç–µ–∫—Å—Ç–æ–≤–æ–≥–æ –ø–æ–∏—Å–∫–∞ –≤ RAG.
- –ó–∞—Ñ–∏–∫—Å–∏—Ä–æ–≤–∞–Ω —Ç–µ–∫—É—â–∏–π —Å—Ç–µ–∫ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π –ø—Ä–æ–µ–∫—Ç–∞ –∫–æ–º–∞–Ω–¥–æ–π:
  pip list --format=freeze > requirements.txt
- requirements.txt —Ç–µ–ø–µ—Ä—å —Å–æ–¥–µ—Ä–∂–∏—Ç –ø–æ–ª–Ω—ã–π —Å–ø–∏—Å–æ–∫ –ø–∞–∫–µ—Ç–æ–≤ –¥–ª—è –≤–æ—Å–ø—Ä–æ–∏–∑–≤–æ–¥–∏–º–æ–≥–æ —Ä–∞–∑–≤—ë—Ä—Ç—ã–≤–∞–Ω–∏—è.

2. –ö–ª–∏–µ–Ω—Ç ChromaDB
- –î–æ–±–∞–≤–ª–µ–Ω –º–æ–¥—É–ª—å app/core/chroma_client.py.
- –†–µ–∞–ª–∏–∑–æ–≤–∞–Ω get_chroma_client() —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º config/system.yaml (paths.chromadb_dir) –∏ persistent-—Ö—Ä–∞–Ω–∏–ª–∏—â–∞ –≤ ./data/chromadb.
- –ü—Ä–∏ –æ—Ç—Å—É—Ç—Å—Ç–≤–∏–∏ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏ –ø–æ–¥ —Ö—Ä–∞–Ω–∏–ª–∏—â–µ –æ–Ω–∞ —Å–æ–∑–¥–∞—ë—Ç—Å—è –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏.

3. –ú–∏–Ω–∏–º–∞–ª—å–Ω—ã–π RAG-–ø–∞–π–ø–ª–∞–π–Ω
- –î–æ–±–∞–≤–ª–µ–Ω –º–æ–¥—É–ª—å app/core/rag_pipeline.py.
- ensure_demo_hello_collection() –ª–µ–Ω–∏–≤–æ —Å–æ–∑–¥–∞—ë—Ç –∫–æ–ª–ª–µ–∫—Ü–∏—é demo_hello_texts –∏ –¥–æ–±–∞–≤–ª—è–µ—Ç –≤ –Ω–µ—ë –¥–µ–º–æ-–¥–æ–∫—É–º–µ–Ω—Ç –æ —Å–∏—Å—Ç–µ–º–µ –∑–∞—è–≤–æ–∫.
- retrieve_text_chunks(...) –≤—ã–ø–æ–ª–Ω—è–µ—Ç –ø–æ–∏—Å–∫ top-k —Ñ—Ä–∞–≥–º–µ–Ω—Ç–æ–≤ –ø–æ ChromaDB –¥–ª—è demo_hello.
- build_llm_prompt(...) –∫–æ–º–±–∏–Ω–∏—Ä—É–µ—Ç technical_prompt –∏–∑ TaskConfig –∏ –Ω–∞–π–¥–µ–Ω–Ω—ã–π –∫–æ–Ω—Ç–µ–∫—Å—Ç –≤ –µ–¥–∏–Ω—ã–π —Å–∏—Å—Ç–µ–º–Ω—ã–π –ø—Ä–æ–º–ø—Ç –¥–ª—è LLM.

4. –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ /api/v1/task/query –ø–æ–¥ RAG
- –≠–Ω–¥–ø–æ–∏–Ω—Ç /api/v1/task/query –¥–ª—è demo-–∑–∞–¥–∞—á —Ç–µ–ø–µ—Ä—å:
  - –≥—Ä—É–∑–∏—Ç TaskConfig –ø–æ task_id;
  - –¥–µ–ª–∞–µ—Ç retrieve_text_chunks(...) –∏ —Ñ–æ—Ä–º–∏—Ä—É–µ—Ç —Å–∏—Å—Ç–µ–º–Ω—ã–π –ø—Ä–æ–º–ø—Ç —á–µ—Ä–µ–∑ build_llm_prompt(...);
  - –≤—ã–∑—ã–≤–∞–µ—Ç –ª–æ–∫–∞–ª—å–Ω—É—é LLM —á–µ—Ä–µ–∑ call_llm —Å –ø–æ–¥–º–µ—à–∞–Ω–Ω—ã–º –∫–æ–Ω—Ç–µ–∫—Å—Ç–æ–º.
- –ü—Ä–æ–≤–µ—Ä–∫–∞ —á–µ—Ä–µ–∑ curl —Å task_id=demo_hello –ø–æ–∫–∞–∑–∞–ª–∞, —á—Ç–æ –æ—Ç–≤–µ—Ç—ã –º–æ–¥–µ–ª–∏ —Å—Å—ã–ª–∞—é—Ç—Å—è –Ω–∞ –∏–¥–µ—é –≤–Ω—É—Ç—Ä–µ–Ω–Ω–∏—Ö –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ –∏ —Å–∏—Å—Ç–µ–º—ã –∑–∞—è–≤–æ–∫, —Ç–æ –µ—Å—Ç—å –∫–æ–Ω—Ç–µ–∫—Å—Ç –∏–∑ ChromaDB —Ä–µ–∞–ª—å–Ω–æ –≤–ª–∏—è–µ—Ç –Ω–∞ –æ—Ç–≤–µ—Ç.

[2026-02-05 14:44] TaskRegistry –∏ AccessControl –¥–ª—è –∑–∞–¥–∞—á.

1. –†–µ–µ—Å—Ç—Ä –∑–∞–¥–∞—á
- –î–æ–±–∞–≤–ª–µ–Ω –º–æ–¥—É–ª—å app/core/task_registry.py.
- –†–µ–∞–ª–∏–∑–æ–≤–∞–Ω TaskRegistry —Å –∫–µ—à–∏—Ä–æ–≤–∞–Ω–∏–µ–º TaskConfig –ø–æ task_id –∏ –ø—Ä–æ—Å—Ç—ã–º —Å–ø–∏—Å–∫–æ–º RegisteredTask.
- –í–≤–µ–¥—ë–Ω –≥–ª–æ–±–∞–ª—å–Ω—ã–π singleton task_registry –¥–ª—è –¥–æ—Å—Ç—É–ø–∞ –∏–∑ API –∏ –¥—Ä—É–≥–∏—Ö –º–æ–¥—É–ª–µ–π.

2. Access control –ø–æ –¢–ó
- –î–æ–±–∞–≤–ª–µ–Ω –º–æ–¥—É–ª—å app/core/access_control.py.
- –§—É–Ω–∫—Ü–∏—è check_task_access(TaskConfig) —Ä–µ–∞–ª–∏–∑—É–µ—Ç –ø—Ä–∞–≤–∏–ª–∞:
  - task_type=demo —Ä–∞–∑—Ä–µ—à—ë–Ω –≤ –ª—é–±—ã—Ö —Ä–µ–∂–∏–º–∞—Ö (dev/test/prod);
  - task_type=corporate —Ä–∞–∑—Ä–µ—à—ë–Ω —Ç–æ–ª—å–∫–æ –≤ prod, –≤ dev/test –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç –æ—Ç–∫–∞–∑.
- –í–æ–∑–≤—Ä–∞—â–∞–µ–º–∞—è —Å—Ç—Ä—É–∫—Ç—É—Ä–∞ AccessDecision –∏–Ω–∫–∞–ø—Å—É–ª–∏—Ä—É–µ—Ç —Ñ–ª–∞–≥ allowed –∏ reason.

3. –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ /api/v1/task/query
- –≠–Ω–¥–ø–æ–∏–Ω—Ç /api/v1/task/query –ø–µ—Ä–µ–∫–ª—é—á—ë–Ω –Ω–∞ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ task_registry –≤–º–µ—Å—Ç–æ –ø—Ä—è–º–æ–≥–æ –≤—ã–∑–æ–≤–∞ load_task_config.
- –ü–æ—Å–ª–µ –∑–∞–≥—Ä—É–∑–∫–∏ TaskConfig –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ –ø—Ä–æ–≤–µ—Ä—è–µ—Ç—Å—è —Å–æ–≥–ª–∞—Å–æ–≤–∞–Ω–Ω–æ—Å—Ç—å request.task_type –∏ TaskConfig.task_type.
- –†–µ—à–µ–Ω–∏–µ –æ –¥–æ—Å—Ç—É–ø–µ –¥–µ–ª–µ–≥–∏—Ä–æ–≤–∞–Ω–æ –º–æ–¥—É–ª—é AccessControl; –ø—Ä–∏ –æ—Ç–∫–∞–∑–µ –∫–ª–∏–µ–Ω—Ç –ø–æ–ª—É—á–∞–µ—Ç 403 –∏ —Ç–µ–∫—Å—Ç–æ–≤–æ–µ reason.
- –ü—Ä–∏ —É—Å–ø–µ—à–Ω–æ–º –¥–æ—Å—Ç—É–ø–µ demo-–∑–∞–¥–∞—á–∏ pipeline –æ—Å—Ç–∞—ë—Ç—Å—è –ø—Ä–µ–∂–Ω–∏–º: retrieve_text_chunks + build_llm_prompt + –≤—ã–∑–æ–≤ –ª–æ–∫–∞–ª—å–Ω–æ–π LLM.

4. –ü—Ä–æ–≤–µ—Ä–∫–∞ –ø–æ—Å–ª–µ –∏–∑–º–µ–Ω–µ–Ω–∏–π
- –ó–∞–ø—Ä–æ—Å —á–µ—Ä–µ–∑ curl –∫ demo_hello –ø–æ–¥—Ç–≤–µ—Ä–¥–∏–ª, —á—Ç–æ demo-–∑–∞–¥–∞—á–∞ –ø—Ä–æ–¥–æ–ª–∂–∞–µ—Ç —Ä–∞–±–æ—Ç–∞—Ç—å –∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç –æ—Å–º—ã—Å–ª–µ–Ω–Ω—ã–π –æ—Ç–≤–µ—Ç –ø–æ—Å–ª–µ –≤–Ω–µ–¥—Ä–µ–Ω–∏—è —Ä–µ–µ—Å—Ç—Ä–∞ –∑–∞–¥–∞—á –∏ access control.

[2026-02-05 15:03] –ê–¥–º–∏–Ω-CLI n3r7 –¥–ª—è –ø—Ä–æ—Å–º–æ—Ç—Ä–∞ –∑–∞–¥–∞—á.

1. –ê–¥–º–∏–Ω-CLI
- –î–æ–±–∞–≤–ª–µ–Ω –º–æ–¥—É–ª—å app/cli/admin_cli.py –Ω–∞ –±–∞–∑–µ –±–∏–±–ª–∏–æ—Ç–µ–∫–∏ click.
- –í CLI –¥–æ–±–∞–≤–ª–µ–Ω–∞ –∫–æ–º–∞–Ω–¥–∞ env –¥–ª—è –≤—ã–≤–æ–¥–∞ —Ç–µ–∫—É—â–µ–≥–æ environment (dev/test/prod) —á–µ—Ä–µ–∑ get_environment().
- –î–æ–±–∞–≤–ª–µ–Ω–∞ –∫–æ–º–∞–Ω–¥–∞ task-info <task_id>, –∫–æ—Ç–æ—Ä–∞—è:
  - –≤—ã—Ç—è–≥–∏–≤–∞–µ—Ç TaskConfig —á–µ—Ä–µ–∑ task_registry.get_task_config;
  - –≤—ã–≤–æ–¥–∏—Ç task_id, name, description, task_type –ø–æ –∑–∞–¥–∞—á–µ.
- –î–æ–±–∞–≤–ª–µ–Ω–∞ –∫–æ–º–∞–Ω–¥–∞ tasks-loaded –¥–ª—è –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏—è –∑–∞–¥–∞—á, —É–∂–µ –∑–∞–≥—Ä—É–∂–µ–Ω–Ω—ã—Ö –≤ TaskRegistry –∑–∞ –≤—Ä–µ–º—è –∂–∏–∑–Ω–∏ –ø—Ä–æ—Ü–µ—Å—Å–∞.

2. –ü—Ä–æ–≤–µ—Ä–∫–∞ CLI
- –í—ã–ø–æ–ª–Ω–µ–Ω–∞ –∫–æ–º–∞–Ω–¥–∞: python -m app.cli.admin_cli env ‚Üí –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ –æ—Ç–æ–±—Ä–∞–∂–∞–µ—Ç Environment: dev.
- –í—ã–ø–æ–ª–Ω–µ–Ω–∞ –∫–æ–º–∞–Ω–¥–∞: python -m app.cli.admin_cli task-info demo_hello ‚Üí –≤—ã–≤–æ–¥–∏—Ç –¥–∞–Ω–Ω—ã–µ TaskConfig –¥–ª—è demo_hello.
- –í—ã–ø–æ–ª–Ω–µ–Ω–∞ –∫–æ–º–∞–Ω–¥–∞: python -m app.cli.admin_cli tasks-loaded ‚Üí –ø–æ–∫–∞ —Å–æ–æ–±—â–∞–µ—Ç, —á—Ç–æ –∑–∞–¥–∞—á –≤ —Ä–µ–µ—Å—Ç—Ä–µ –Ω–µ—Ç (—Å–ø–∏—Å–æ–∫ –±—É–¥–µ—Ç –Ω–∞–ø–æ–ª–Ω—è—Ç—å—Å—è –ø–æ –º–µ—Ä–µ –æ–±—Ä–∞—â–µ–Ω–∏–π –∫ API –∏ CLI).


[2026-02-05 15:05] –í—Ç–æ—Ä–∞—è demo-–∑–∞–¥–∞—á–∞ demo_rules –∏ –º–Ω–æ–≥–æ–∑–∞–¥–∞—á–Ω—ã–π RAG.

1. –ù–æ–≤—ã–π TaskConfig demo_rules
- –î–æ–±–∞–≤–ª–µ–Ω —Ñ–∞–π–ª config/tasks/demo_rules.yaml.
- –û–ø–∏—Å–∞–Ω–∞ demo-–∑–∞–¥–∞—á–∞ "Demo: —Ä–µ–≥–ª–∞–º–µ–Ω—Ç—ã –∏ –ø—Ä–∞–≤–∏–ª–∞" —Å —Ç–∏–ø–æ–º task_type=demo.
- technical_prompt –æ—Ä–∏–µ–Ω—Ç–∏—Ä–æ–≤–∞–Ω –Ω–∞ –æ–±—ä—è—Å–Ω–µ–Ω–∏–µ –≤–Ω—É—Ç—Ä–µ–Ω–Ω–∏—Ö –ø—Ä–∞–≤–∏–ª –∏ —Ä–µ–≥–ª–∞–º–µ–Ω—Ç–æ–≤ –ø—Ä–æ—Å—Ç—ã–º —è–∑—ã–∫–æ–º.

2. –†–∞—Å—à–∏—Ä–µ–Ω–∏–µ RAG-–ø–∞–π–ø–ª–∞–π–Ω–∞
- –û–±–Ω–æ–≤–ª—ë–Ω app/core/rag_pipeline.py:
  - —Ä–µ–∞–ª–∏–∑–æ–≤–∞–Ω–∞ ensure_collection_for_task(task_cfg) —Å –ø–æ–¥–¥–µ—Ä–∂–∫–æ–π:
    - demo_hello ‚Üí –∫–æ–ª–ª–µ–∫—Ü–∏—è demo_hello_texts;
    - demo_rules ‚Üí –∫–æ–ª–ª–µ–∫—Ü–∏—è demo_rules_texts.
  - –¥–ª—è demo_rules –¥–æ–±–∞–≤–ª–µ–Ω –¥–µ–º–æ-–¥–æ–∫—É–º–µ–Ω—Ç —Å –æ–ø–∏—Å–∞–Ω–∏–µ–º –±–∞–∑–æ–≤—ã—Ö —Ä–µ–≥–ª–∞–º–µ–Ω—Ç–æ–≤: –∑–∞—è–≤–∫–∏ –Ω–∞ –¥–æ—Å—Ç—É–ø—ã, –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–æ–Ω–Ω–∞—è –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç—å, —É—Ç–≤–µ—Ä–∂–¥—ë–Ω–Ω—ã–µ –∫–∞–Ω–∞–ª—ã –∫–æ–º–º—É–Ω–∏–∫–∞—Ü–∏–∏.
- –§—É–Ω–∫—Ü–∏—è retrieve_text_chunks(...) —Ç–µ–ø–µ—Ä—å —Ä–∞–±–æ—Ç–∞–µ—Ç —Å –ª—é–±–æ–π –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º–æ–π demo-–∑–∞–¥–∞—á–µ–π —á–µ—Ä–µ–∑ ensure_collection_for_task.
- build_llm_prompt(...) –±–µ–∑ –∏–∑–º–µ–Ω–µ–Ω–∏–π, –Ω–æ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è —É–∂–µ —Å–æ –≤—Ç–æ—Ä—ã–º —Ç–∏–ø–æ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞.

3. –ü—Ä–æ–≤–µ—Ä–∫–∞ demo_rules —á–µ—Ä–µ–∑ API
- –í—ã–ø–æ–ª–Ω–µ–Ω –∑–∞–ø—Ä–æ—Å:
  - task_id=demo_rules, task_type=demo;
  - –≤–æ–ø—Ä–æ—Å –ø—Ä–æ –±–∞–∑–æ–≤—ã–µ –ø—Ä–∞–≤–∏–ª–∞ –ø–æ –∑–∞—è–≤–∫–∞–º –∏ –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç–∏.
- –û—Ç–≤–µ—Ç –ª–æ–∫–∞–ª—å–Ω–æ–π LLM —Å–æ–¥–µ—Ä–∂–∏—Ç –æ—Ç—Å—ã–ª–∫—É –∫ –∑–∞—è–≤–∫–∞–º, –¥–æ—Å—Ç—É–ø–∞–º –∫ —Å–∏—Å—Ç–µ–º–∞–º –∏ –ø—Ä–∞–≤–∏–ª–∞–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–æ–Ω–Ω–æ–π –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç–∏, —á—Ç–æ –ø–æ–¥—Ç–≤–µ—Ä–∂–¥–∞–µ—Ç –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ –Ω–æ–≤–æ–≥–æ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ –∏–∑ demo_rules_texts.

4. –ü—Ä–æ–≤–µ—Ä–∫–∞ demo_rules —á–µ—Ä–µ–∑ CLI
- –ö–æ–º–∞–Ω–¥–∞ python -m app.cli.admin_cli task-info demo_rules –≤—ã–≤–æ–¥–∏—Ç TaskConfig –¥–ª—è demo_rules (task_id, name, description, task_type).


[2026-02-05 15:09] REST-—ç–Ω–¥–æ–∏–Ω—Ç—ã —Å–ø–∏—Å–∫–∞ –∑–∞–¥–∞—á –∏ —É–ª—É—á—à–µ–Ω–Ω—ã–π TaskRegistry.

1. TaskRegistry: —Å–∫–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ —Ñ–∞–π–ª–æ–≤—ã—Ö –∫–æ–Ω—Ñ–∏–≥–æ–≤
- –û–±–Ω–æ–≤–ª—ë–Ω app/core/task_registry.py.
- –†–µ–∞–ª–∏–∑–æ–≤–∞–Ω –º–µ—Ç–æ–¥ _scan_tasks_dir() –¥–ª—è –ø–æ–∏—Å–∫–∞ config/tasks/*.yaml –∏ –∏–∑–≤–ª–µ—á–µ–Ω–∏—è task_id.
- list_registered_tasks() —Ç–µ–ø–µ—Ä—å —Å–∫–∞–Ω–∏—Ä—É–µ—Ç —Ñ–∞–π–ª–æ–≤—É—é —Å–∏—Å—Ç–µ–º—É, –ø–æ–¥–Ω–∏–º–∞–µ—Ç TaskConfig –∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç RegisteredTask –ø–æ –≤—Å–µ–º –Ω–∞–π–¥–µ–Ω–Ω—ã–º –∑–∞–¥–∞—á–∞–º (–∞ –Ω–µ —Ç–æ–ª—å–∫–æ —Ä–∞–Ω–µ–µ –∑–∞–≥—Ä—É–∂–µ–Ω–Ω—ã–º).

2. REST-—ç–Ω–¥–æ–∏–Ω—Ç—ã –∑–∞–¥–∞—á
- –í app/api/v1/routes.py –¥–æ–±–∞–≤–ª–µ–Ω—ã –º–æ–¥–µ–ª–∏ TaskInfo –∏ –¥–≤–∞ —ç–Ω–¥–ø–æ–∏–Ω—Ç–∞:
  - GET /api/v1/tasks:
    - –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å–ø–∏—Å–æ–∫ –∑–∞–¥–∞—á (task_id, task_type, name, description) –Ω–∞ –æ—Å–Ω–æ–≤–µ TaskRegistry.
  - GET /api/v1/tasks/{task_id}:
    - –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –ø–æ –æ–¥–Ω–æ–π –∑–∞–¥–∞—á–µ —á–µ—Ä–µ–∑ task_registry.get_task_config;
    - –ø—Ä–∏ –æ—Ç—Å—É—Ç—Å—Ç–≤–∏–∏ –∫–æ–Ω—Ñ–∏–≥–∞ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç 404.

3. –ü—Ä–æ–≤–µ—Ä–∫–∞ API
- GET /api/v1/tasks –≤–µ—Ä–Ω—É–ª –¥–≤–µ demo-–∑–∞–¥–∞—á–∏: demo_hello –∏ demo_rules —Å –∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–º–∏ –ø–æ–ª—è–º–∏.
- GET /api/v1/tasks/demo_rules –≤–µ—Ä–Ω—É–ª JSON —Å task_id=demo_rules, task_type=demo, –∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–º–∏ name –∏ description.

[2026-02-05 15:11] –ú–∏–Ω–∏–º–∞–ª—å–Ω—ã–µ —Ç–µ—Å—Ç—ã API —á–µ—Ä–µ–∑ pytest.

1. –ù–∞–±–æ—Ä —Ç–µ—Å—Ç–æ–≤ FastAPI
- –°–æ–∑–¥–∞–Ω —Ñ–∞–π–ª tests/test_api.py –Ω–∞ –±–∞–∑–µ fastapi.testclient.TestClient.
- test_health_ok –ø—Ä–æ–≤–µ—Ä—è–µ—Ç, —á—Ç–æ /api/v1/health –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç status=ok, –∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–π environment –∏ –ø–æ–ª–µ llm_mode.
- test_tasks_list_contains_demo_tasks –ø—Ä–æ–≤–µ—Ä—è–µ—Ç, —á—Ç–æ /api/v1/tasks —Å–æ–¥–µ—Ä–∂–∏—Ç demo_hello –∏ demo_rules.
- test_get_task_demo_rules –≤–∞–ª–∏–¥–∏—Ä—É–µ—Ç /api/v1/tasks/demo_rules (task_id, task_type, name).
- test_task_query_demo_hello –æ—Ç–ø—Ä–∞–≤–ª—è–µ—Ç demo-–∑–∞–ø—Ä–æ—Å –≤ /api/v1/task/query –∏ –ø—Ä–æ–≤–µ—Ä—è–µ—Ç, —á—Ç–æ ok=True –∏ –æ—Ç–≤–µ—Ç –Ω–µ–ø—É—Å—Ç–æ–π.
- test_task_query_corporate_forbidden_in_dev –ø—Ä–æ–≤–µ—Ä—è–µ—Ç, —á—Ç–æ –∑–∞–ø—Ä–æ—Å —Å task_type=corporate –Ω–µ –ø—Ä–æ—Ö–æ–¥–∏—Ç –≤ dev (400/403).

2. –†–µ–∑—É–ª—å—Ç–∞—Ç –ø—Ä–æ–≥–æ–Ω–∞
- pytest -q –æ—Ç—Ä–∞–±–æ—Ç–∞–ª —É—Å–ø–µ—à–Ω–æ: 5 passed in ~17s.



[2026-02-05 20:07] –¢–∞–±–ª–∏—á–Ω—ã–π RAG, –≥–ª–æ—Å—Å–∞—Ä–∏–π –∏ profanity-—Ñ–ª–∞–≥.

1. –¢–∞–±–ª–∏—á–Ω—ã–π RAG –ø–æ employee_data
- –î–æ–±–∞–≤–ª–µ–Ω –º–æ–¥—É–ª—å app/ingestion/employee_table.py —Å SQLite-—Ç–∞–±–ª–∏—Ü–µ–π employees (id, fullname, position, department) –∏ –¥–µ–º–æ-–¥–∞–Ω–Ω—ã–º–∏.
- –î–ª—è corporate-–∑–∞–¥–∞—á–∏ employee_data –≤ app/api/v1/routes.py –¥–æ–±–∞–≤–ª–µ–Ω–∞ –≤–µ—Ç–∫–∞ —Ç–∞–±–ª–∏—á–Ω–æ–≥–æ –ø–æ–∏—Å–∫–∞:
  - ensure_employee_table() + seed_demo_employees() –∏ search_employees(query, limit=5);
  - —Ñ–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–∏–µ —Ç–µ–∫—Å—Ç–æ–≤–æ–≥–æ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ —Å –ø—Ä–∏–º–µ—Ä–∞–º–∏ ¬´–§–ò–û; –î–æ–ª–∂–Ω–æ—Å—Ç—å; –ü–æ–¥—Ä–∞–∑–¥–µ–ª–µ–Ω–∏–µ¬ª;
  - –±–µ–∑–æ–ø–∞—Å–Ω—ã–π –æ—Ç–≤–µ—Ç –±–µ–∑ —Ä–µ–∞–ª—å–Ω—ã—Ö –ø–µ—Ä—Å–æ–Ω–∞–ª—å–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö, —Ç–æ–ª—å–∫–æ –Ω–∞ –æ—Å–Ω–æ–≤–µ –≤—ã–º—ã—à–ª–µ–Ω–Ω—ã—Ö –∑–∞–ø–∏—Å–µ–π.

2. Event-–ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ
- –°–æ–∑–¥–∞–Ω –º–æ–¥—É–ª—å app/core/event_logger.py —Å —Ñ—É–Ω–∫—Ü–∏–µ–π log_event(...) ‚Üí JSONL-–ª–æ–≥ –≤ data/logs/app.log.
- –í _run_task() –¥–ª—è /api/v1/task/query –ª–æ–≥–∏—Ä—É—é—Ç—Å—è —Å–æ–±—ã—Ç–∏—è:
  - query: request_id, task_id, task_type, –∏—Å—Ö–æ–¥–Ω—ã–π query –∏ normalized_query;
  - search: –¥–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å –ø–æ–∏—Å–∫–∞ –∏ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –Ω–∞–π–¥–µ–Ω–Ω—ã—Ö chunks/—Å—Ç—Ä–æ–∫;
  - llm / llm_error: –¥–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å –≤—ã–∑–æ–≤–∞ LLM –∏ —Ñ–ª–∞–≥ —É—Å–ø–µ—Ö–∞.
- –ü–æ request_id –º–æ–∂–Ω–æ —Å–≤—è–∑–∞—Ç—å query, search –∏ llm-—Å–æ–±—ã—Ç–∏—è –æ–¥–Ω–æ–≥–æ –∑–∞–ø—Ä–æ—Å–∞.

3. –ì–ª–æ—Å—Å–∞—Ä–∏–π —Å–∏–Ω–æ–Ω–∏–º–æ–≤
- –î–æ–±–∞–≤–ª–µ–Ω config/glossary.yaml —Å —Å–∏–Ω–æ–Ω–∏–º–∞–º–∏ –¥–ª—è —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏—Ö —Å—É—â–Ω–æ—Å—Ç–µ–π (clickhouse, chromadb, sqlite).
- –°–æ–∑–¥–∞–Ω –º–æ–¥—É–ª—å app/core/glossary.py —Å —Ñ—É–Ω–∫—Ü–∏—è–º–∏ get_glossary() –∏ normalize_query().
- –í _run_task() demo-–∑–∞–¥–∞—á–∏ –∏—Å–ø–æ–ª—å–∑—É—é—Ç normalized_query –¥–ª—è retrieval –∏ –ø–æ—Å—Ç—Ä–æ–µ–Ω–∏—è –ø—Ä–æ–º–ø—Ç–∞, –∞ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—é –ø–æ–∫–∞–∑—ã–≤–∞–µ—Ç—Å—è –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–π —Ç–µ–∫—Å—Ç.

4. Profanity-—Ñ–∏–ª—å—Ç—Ä
- –°–æ–∑–¥–∞–Ω app/core/profanity_filter.py:
  - –±–∞–∑–æ–≤—ã–π —Å–ø–∏—Å–æ–∫ —Ä—É/–µ–Ω –∫–æ—Ä–Ω–µ–π –º–∞—Ç–∞;
  - check_profanity(text) –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç detected + —Å–ø–∏—Å–æ–∫ matches;
  - –ø–æ–¥–¥–µ—Ä–∂–∫–∞ –∏—Å–∫–ª—é—á–µ–Ω–∏–π –∏–∑ config/profanity_exceptions.yaml (–Ω–∞–ø—Ä–∏–º–µ—Ä, —Ñ–∞–º–∏–ª–∏—è ¬´–ß–µ–±–∞–Ω¬ª).
- –í _run_task():
  - –ø–µ—Ä–µ–¥ –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏–µ–π –≤—ã–∑—ã–≤–∞–µ—Ç—Å—è check_profanity(query);
  - –≤ —Å–æ–±—ã—Ç–∏—è—Ö query –∏ llm –ª–æ–≥–∏—Ä—É—é—Ç—Å—è –ø–æ–ª—è profanity_detected –∏ profanity_matches;
  - –º–∞—Ç –Ω–µ –±–ª–æ–∫–∏—Ä—É–µ—Ç –∑–∞–ø—Ä–æ—Å—ã, —Ç–æ–ª—å–∫–æ –ø–æ–º–µ—á–∞–µ—Ç –∏—Ö –≤ –ª–æ–≥–∞—Ö.

5. –¢–µ–∫—É—â–µ–µ —Å–æ—Å—Ç–æ—è–Ω–∏–µ
- demo_hello –∏ demo_rules —Ä–∞–±–æ—Ç–∞—é—Ç —á–µ—Ä–µ–∑ RAG –ø–æ ChromaDB.
- employee_data –∏—Å–ø–æ–ª—å–∑—É–µ—Ç —Ç–∞–±–ª–∏—á–Ω—ã–π SQLite-–ø–æ–∏—Å–∫ —Å –¥–µ–º–æ-–¥–∞–Ω–Ω—ã–º–∏ —Å–æ—Ç—Ä—É–¥–Ω–∏–∫–æ–≤.
- –í—Å–µ –∑–∞–ø—Ä–æ—Å—ã –ø—Ä–æ—Ö–æ–¥—è—Ç —á–µ—Ä–µ–∑ –≥–ª–æ—Å—Å–∞—Ä–∏–π –∏ profanity-—Ñ–∏–ª—å—Ç—Ä –∏ –ª–æ–≥–∏—Ä—É—é—Ç—Å—è –≤ data/logs/app.log.

–í–ê–ñ–ù–û!!!!

–°–ª–µ–ø–æ–∫ –∫–æ–¥–∞ —É —Ç–µ–±—è —É–∂–µ –µ—Å—Ç—å —á–µ—Ä–µ–∑ code_collector.py ‚Üí all_code.txt, —Ç–∞–∫ —á—Ç–æ —Å–µ–π—á–∞—Å —Å–¥–µ–ª–∞–µ–º –∏–º–µ–Ω–Ω–æ –ø–æ–¥—Ä–æ–±–Ω—É—é –∑–∞–ø–∏—Å—å –Ω–∞—à–∏—Ö –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–Ω—ã—Ö —Ä–µ—à–µ–Ω–∏–π –≤ DEV_LOG.txt.
‚Äã

–í—Å—Ç–∞–≤—å —ç—Ç–æ –≤ –∫–æ–Ω–µ—Ü DEV_LOG.txt:

bash
cat >> DEV_LOG.txt << 'EOF'

[2026-02-05 22:18] RAG-—Ä–µ–∂–∏–º—ã, test-–±–µ–∑-LLM –∏ —Å—Ç—Ä–∞—Ç–µ–≥–∏—è —Ä–∞–±–æ—Ç—ã —Å —Ç–∞–±–ª–∏—Ü–∞–º–∏/–≤–µ–∫—Ç–æ—Ä–∫–æ–π.

1. –†–µ–∂–∏–º—ã –æ–∫—Ä—É–∂–µ–Ω–∏—è –∏ test-—Ä–µ–∂–∏–º –±–µ–∑ LLM
- –ü–æ–¥—Ç–≤–µ—Ä–¥–∏–ª–∏ –º–æ–¥–µ–ª—å –æ–∫—Ä—É–∂–µ–Ω–∏–π —Å—Ç—Ä–æ–≥–æ –ø–æ config/system.yaml:
  - environment: dev | test | prod.
- –ü—Ä–∏–Ω—è—Ç–æ —Ä–µ—à–µ–Ω–∏–µ:
  - –í dev –∏ prod –ø–∞–π–ø–ª–∞–π–Ω —Ä–∞–±–æ—Ç–∞–µ—Ç –ø–æ–ª–Ω–æ—Ü–µ–Ω–Ω–æ: RAG + –≤—ã–∑–æ–≤ LLM.
  - –í test –ø–∞–π–ø–ª–∞–π–Ω —Ä–∞–±–æ—Ç–∞–µ—Ç –∫–∞–∫ ¬´–≤–∏–∑—É–∞–ª—å–Ω—ã–π –æ—Ç–ª–∞–¥—á–∏–∫¬ª –ø–æ–∏—Å–∫–∞:
    - LLM –≤–æ–æ–±—â–µ –Ω–µ –≤—ã–∑—ã–≤–∞–µ—Ç—Å—è.
    - –í –æ—Ç–≤–µ—Ç API –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç—Å—è —Ç–æ–ª—å–∫–æ –Ω–∞–π–¥–µ–Ω–Ω—ã–π –∫–æ–Ω—Ç–µ–∫—Å—Ç (—á–∞–Ω–∫–∏/—Å—Ç—Ä–æ–∫–∏ —Ç–∞–±–ª–∏—Ü) –≤ meta.
- –†–µ–∞–ª–∏–∑–∞—Ü–∏—è:
  - –í app/core/config_loader.py —É–∂–µ –µ—Å—Ç—å get_environment(), –æ–Ω –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –≤ _run_task().
  - –í app/api/v1/routes.py –≤–Ω—É—Ç—Ä—å _run_task(task_id, task_type, query, debug) –¥–æ–±–∞–≤–ª–µ–Ω–∞ –ø–µ—Ä–µ–º–µ–Ω–Ω–∞—è env = get_environment().
  - –î–ª—è demo-–∑–∞–¥–∞—á:
    - –í–µ—Ç–∫–∞ if task_cfg.task_type == "demo":
      - –î–µ–ª–∞–µ—Ç—Å—è retrieve_text_chunks(task_cfg, normalized_query, top_k=3).
      - –°–æ–±—ã—Ç–∏–µ "search" –ª–æ–≥–∏—Ä—É–µ—Ç duration_ms –∏ chunks_found.
      - –ï—Å–ª–∏ env == "test":
        - –í meta.retrieved_chunks —Å–∫–ª–∞–¥—ã–≤–∞–µ—Ç—Å—è —Å–ø–∏—Å–æ–∫ —á–∞–Ω–∫–æ–≤:
          - text, source_id, score.
        - –í –ª–æ–≥ –ø–∏—à–µ—Ç—Å—è event_type="final" —Å payload:
          - ok=True, answer_length=0, mode="test_no_llm".
        - –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç—Å—è TaskQueryResponse:
          - ok=True,
          - answer="TEST MODE: LLM –Ω–µ –≤—ã–∑—ã–≤–∞–ª—Å—è, –≤–æ–∑–≤—Ä–∞—â–µ–Ω—ã —Ç–æ–ª—å–∫–æ –Ω–∞–π–¥–µ–Ω–Ω—ã–µ —á–∞–Ω–∫–∏.",
          - meta —Å retrieved_chunks.
      - –ï—Å–ª–∏ env != "test" (dev/prod):
        - –ü—Ä–∏ debug=True —Ç–µ –∂–µ chunks –¥–æ–±–∞–≤–ª—è—é—Ç—Å—è –≤ meta.retrieved_chunks.
        - –°—Ç—Ä–æ–∏—Ç—Å—è system_prompt —á–µ—Ä–µ–∑ build_llm_prompt(...).
        - –î–∞–ª–µ–µ —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–π –≤—ã–∑–æ–≤ LLM (call_llm) –∏ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ —Å–æ–±—ã—Ç–∏–π "llm" –∏ "final".
  - –î–ª—è corporate-–∑–∞–¥–∞—á–∏ employee_data:
    - –í–µ—Ç–∫–∞ if task_cfg.task_type == "corporate" and task_cfg.task_id == "employee_data":
      - ensure_employee_table(), seed_demo_employees().
      - search_employees(query, limit=5) –ø–æ –¥–µ–º–æ-—Ç–∞–±–ª–∏—Ü–µ employees.
      - –õ–æ–≥–∏—Ä—É–µ—Ç—Å—è "search" —Å rows_found.
      - –ï—Å–ª–∏ env == "test":
        - –í meta.table_rows —Å–∫–ª–∞–¥—ã–≤–∞—é—Ç—Å—è —Å—Ç—Ä–æ–∫–∏ (fullname, position, department).
        - –í –ª–æ–≥ –ø–∏—à–µ—Ç—Å—è "final" —Å ok=True, answer_length=0, mode="test_no_llm".
        - –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç—Å—è TaskQueryResponse:
          - ok=True,
          - answer="TEST MODE: LLM –Ω–µ –≤—ã–∑—ã–≤–∞–ª—Å—è, –≤–æ–∑–≤—Ä–∞—â–µ–Ω—ã —Ç–æ–ª—å–∫–æ —Å—Ç—Ä–æ–∫–∏ —Ç–∞–±–ª–∏—Ü—ã.",
          - meta —Å table_rows.
      - –ï—Å–ª–∏ env != "test":
        - –ü—Ä–∏ debug=True —Ç–µ –∂–µ rows –∫–ª–∞–¥—É—Ç—Å—è –≤ meta.table_rows.
        - –§–æ—Ä–º–∏—Ä—É–µ—Ç—Å—è –∫–æ–Ω—Ç–µ–∫—Å—Ç–Ω—ã–π –±–ª–æ–∫ —Å –ø–µ—Ä–µ—á–∏—Å–ª–µ–Ω–∏–µ–º –∑–∞–ø–∏—Å–µ–π —Å–æ—Ç—Ä—É–¥–Ω–∏–∫–æ–≤.
        - –í—ã–∑—ã–≤–∞–µ—Ç—Å—è LLM, –∫–∞–∫ –∏ —Ä–∞–Ω—å—à–µ.

–ò—Ç–æ–≥–æ: –≤ test-–æ–∫—Ä—É–∂–µ–Ω–∏–∏ —Å–µ—Ä–≤–∏—Å –ø—Ä–µ–≤—Ä–∞—â–∞–µ—Ç—Å—è –≤ ¬´–ø—Ä–æ—Å–º–æ—Ç—Ä—â–∏–∫ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞¬ª, —á—Ç–æ–±—ã –≥–ª–∞–∑–∞–º–∏ –≤–∏–¥–µ—Ç—å, –∫–∞–∫–∏–µ —Ç–µ–∫—Å—Ç–æ–≤—ã–µ —á–∞–Ω–∫–∏ –∏ –∫–∞–∫–∏–µ —Å—Ç—Ä–æ–∫–∏ —Ç–∞–±–ª–∏—Ü —Ä–µ–∞–ª—å–Ω–æ –∏–¥—É—Ç –≤ RAG, –±–µ–∑ –Ω–∞–∫–ª–∞–¥–Ω—ã—Ö —Ä–∞—Å—Ö–æ–¥–æ–≤ –∏ –Ω–µ–æ–ø—Ä–µ–¥–µ–ª—ë–Ω–Ω–æ—Å—Ç–∏ –æ—Ç LLM.

2. Debug meta –≤ /api/v1/task/query
- –î–ª—è /api/v1/task/query –≤–≤–µ–¥—ë–Ω —Ñ–ª–∞–≥ debug (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é True) –≤ TaskQueryRequest.
- TaskQueryResponse —Ä–∞—Å—à–∏—Ä–µ–Ω –ø–æ–ª–µ–º meta: Optional[Dict[str, Any]].
- –í dev/prod –ø—Ä–∏ debug=True:
  - –î–ª—è demo-–∑–∞–¥–∞—á –≤ meta.retrieved_chunks –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç—Å—è —Å–ø–∏—Å–æ–∫ —á–∞–Ω–∫–æ–≤:
    - text, source_id, score.
  - –î–ª—è employee_data –≤ meta.table_rows –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç—Å—è —Å–ø–∏—Å–æ–∫ —Å—Ç—Ä–æ–∫:
    - fullname, position, department.
- –≠—Ç–æ –ø–æ–∑–≤–æ–ª—è–µ—Ç –ø–æ—Å–º–æ—Ç—Ä–µ—Ç—å, –∫–∞–∫ –∏–º–µ–Ω–Ω–æ Chroma/—Ç–∞–±–ª–∏—á–Ω—ã–π –ø–æ–∏—Å–∫ —Ä–µ–∂—É—Ç –∏ –æ—Ç–±–∏—Ä–∞—é—Ç –¥–∞–Ω–Ω—ã–µ, –Ω–µ –∑–∞–ª–µ–∑–∞—è –≤ –ª–æ–≥–∏.

3. –°—Ç—Ä–∞—Ç–µ–≥–∏—è —Ä–∞–±–æ—Ç—ã —Å —Ç–∞–±–ª–∏—Ü–∞–º–∏ –∏ –≤–µ–∫—Ç–æ—Ä–Ω—ã–º –ø–æ–∏—Å–∫–æ–º
- –ü—Ä–∏–Ω—è—Ç–æ –≤–∞–∂–Ω–æ–µ –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–Ω–æ–µ —Ä–µ—à–µ–Ω–∏–µ –ø–æ —Ç–∞–±–ª–∏—á–Ω—ã–º –¥–∞–Ω–Ω—ã–º:
  - –ú—ã –ù–ï –ø—Ä–∏–≤—è–∑—ã–≤–∞–µ–º—Å—è –∂—ë—Å—Ç–∫–æ –∫ —Ä–µ–ª—è—Ü–∏–æ–Ω–Ω–æ–π SQL-—Ç–∞–±–ª–∏—Ü–µ –∫–∞–∫ –∫ ¬´–æ—Å–Ω–æ–≤–Ω–æ–º—É¬ª –ø–æ–∏—Å–∫–æ–≤–æ–º—É –º–µ—Ö–∞–Ω–∏–∑–º—É.
  - –°–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–∏–π –ø–æ–∏—Å–∫ (–ø–æ —Å–º—ã—Å–ª—É, —Å —É—á—ë—Ç–æ–º —Å–∏–Ω–æ–Ω–∏–º–æ–≤ –∏ ¬´—Ä–∞–∑–≥–æ–≤–æ—Ä–Ω—ã—Ö¬ª —Ñ–æ—Ä–º —Ç–∏–ø–∞ "–∫–∏–∫—Ö–∞—É—Å", "–Ω–∏–∫–∏—Ç–æ—Å—É") –±—É–¥–µ—Ç —Ä–µ–∞–ª–∏–∑–æ–≤–∞–Ω —á–µ—Ä–µ–∑ –≤–µ–∫—Ç–æ—Ä–∫—É (Chroma –∏–ª–∏ SQLite-–≤–µ–∫—Ç–æ—Ä–Ω–æ–µ —Ä–∞—Å—à–∏—Ä–µ–Ω–∏–µ), –∞ –Ω–µ —á–µ—Ä–µ–∑ LIKE.
- –ü—Ä–∏ —ç—Ç–æ–º —Ç–∞–±–ª–∏—á–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ (employees, services –∏ —Ç.–ø.) —Ä–∞—Å—Å–º–∞—Ç—Ä–∏–≤–∞—é—Ç—Å—è –∫–∞–∫ –û–¢–î–ï–õ–¨–ù–´–ï –∏—Å—Ç–æ—á–Ω–∏–∫–∏, –∫–æ—Ç–æ—Ä—ã–µ –º–æ–∂–Ω–æ:
  - –ª–∏–±–æ —Ö—Ä–∞–Ω–∏—Ç—å –≤ SQLite –¥–ª—è —Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏–æ–Ω–Ω–æ—Å—Ç–∏ –∏ —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏;
  - –ª–∏–±–æ –ø–æ–ª–Ω–æ—Å—Ç—å—é –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞—Ç—å –≤ JSON –∏ –ø—Ä–æ–∏–Ω–¥–µ–∫—Å–∏—Ä–æ–≤–∞—Ç—å –≤ –≤–µ–∫—Ç–æ—Ä–Ω–æ–π –±–∞–∑–µ –∫–∞–∫ –Ω–∞–±–æ—Ä —á–∞–Ω–∫–æ–≤.

–ö–ª—é—á–µ–≤—ã–µ —Å–æ–≥–ª–∞—à–µ–Ω–∏—è –ø–æ —Ç–∞–±–ª–∏—Ü–∞–º:
- –¢–∞–±–ª–∏—Ü—ã –ø—Ä–µ–æ–±—Ä–∞–∑—É—é—Ç—Å—è –≤ JSON-–ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∏–µ.
- –î–ª—è –≤–µ–∫—Ç–æ—Ä–Ω–æ–≥–æ –ø–æ–∏—Å–∫–∞ —Å—É—â–µ—Å—Ç–≤—É—é—Ç –¥–≤–∞ —Ä–µ–∂–∏–º–∞ —á–∞–Ω–∫–∏–Ω–≥–∞:
  1) "row_to_chunk" (–ø–æ —Å—Ç—Ä–æ–∫–∞–º):
     - –∫–∞–∂–¥–∞—è —Å—Ç—Ä–æ–∫–∞ —Ç–∞–±–ª–∏—Ü—ã –ø—Ä–µ–≤—Ä–∞—â–∞–µ—Ç—Å—è –≤ –æ—Ç–¥–µ–ª—å–Ω—ã–π —á–∞–Ω–∫.
     - –ø—Ä–∏–º–µ—Ä: "–§–ò–û ‚Äî –¥–æ–ª–∂–Ω–æ—Å—Ç—å ‚Äî –ø–æ–¥—Ä–∞–∑–¥–µ–ª–µ–Ω–∏–µ".
     - —ç—Ç–æ—Ç —á–∞–Ω–∫ –ø–æ–ª—É—á–∞–µ—Ç —Å–≤–æ–π source_id (–Ω–∞–ø—Ä–∏–º–µ—Ä, employee:<id>).
  2) "full_table_as_single_chunk" (–∏—Å—Ç–æ—á–Ω–∏–∫ —Ü–µ–ª–∏–∫–æ–º):
     - –≤—Å—è –Ω–µ–±–æ–ª—å—à–∞—è —Ç–∞–±–ª–∏—Ü–∞ (–∏–ª–∏ –µ—ë –ª–æ–≥–∏—á–µ—Å–∫–∏–π —Ñ—Ä–∞–≥–º–µ–Ω—Ç) –ø—Ä–µ–æ–±—Ä–∞–∑—É–µ—Ç—Å—è –≤ –æ–¥–∏–Ω JSON-–±–ª–æ–∫/—Ç–µ–∫—Å—Ç –∏ –∫–ª–∞–¥—ë—Ç—Å—è –≤ –æ–¥–∏–Ω —á–∞–Ω–∫.
     - —ç—Ç–æ—Ç —Ä–µ–∂–∏–º –ø–æ–ª–µ–∑–µ–Ω, –∫–æ–≥–¥–∞ —Ç–∞–±–ª–∏—Ü–∞ –∫–æ–º–ø–∞–∫—Ç–Ω–∞—è –∏ –±–µ–∑–æ–ø–∞—Å–Ω–æ —Ü–µ–ª–∏–∫–æ–º –ø–æ–¥–º–µ—à–∞—Ç—å –µ—ë –≤ –∫–æ–Ω—Ç–µ–∫—Å—Ç.
- –ü—Ä–∏ —ç—Ç–æ–º –º—ã —Å–æ–∑–Ω–∞—Ç–µ–ª—å–Ω–æ –≤—ã–±–∏—Ä–∞–µ–º:
  - —Ä–µ–ª—è—Ü–∏–æ–Ω–Ω—É—é —Ç–∞–±–ª–∏—Ü—É –∫–∞–∫ "–∏—Å—Ç–æ—á–Ω–∏–∫ –¥–∞–Ω–Ω—ã—Ö" (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ),
  - –Ω–æ —Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–∏–π search ‚Äî —á–µ—Ä–µ–∑ –≤–µ–∫—Ç–æ—Ä–∫—É,
  - SQL –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è —Ç–æ–ª—å–∫–æ –¥–ª—è –∂—ë—Å—Ç–∫–∏—Ö —Ñ–∏–ª—å—Ç—Ä–æ–≤/–¥–∂–æ–π–Ω–æ–≤ (–µ—Å–ª–∏/–∫–æ–≥–¥–∞ —ç—Ç–æ –ø–æ–Ω–∞–¥–æ–±–∏—Ç—Å—è), –∞ –Ω–µ –¥–ª—è –ø–æ–∏—Å–∫–∞ "–ø–æ —Å–º—ã—Å–ª—É".

4. –†–∞–∑–¥–µ–ª–µ–Ω–∏–µ –æ—Ç–≤–µ—Ç—Å—Ç–≤–µ–Ω–Ω–æ—Å—Ç–∏: –∏—Å—Ç–æ—á–Ω–∏–∫ vs –∑–∞–¥–∞—á–∞
- –°—Ñ–æ—Ä–º—É–ª–∏—Ä–æ–≤–∞–Ω–æ –≤–∞–∂–Ω–æ–µ –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–Ω–æ–µ —Ä–∞–∑–¥–µ–ª–µ–Ω–∏–µ:
  1) –ò—Å—Ç–æ—á–Ω–∏–∫ (source) –æ—Ç–≤–µ—á–∞–µ—Ç –∑–∞:
     - —Ç–∏–ø —Ö—Ä–∞–Ω–µ–Ω–∏—è: file / table / api;
     - —Ñ–æ—Ä–º–∞—Ç —Ö—Ä–∞–Ω–µ–Ω–∏—è: raw CSV/Excel/SQLite/json;
     - —Å–ø–æ—Å–æ–± –Ω–∞—Ä–µ–∑–∫–∏ –≤ —á–∞–Ω–∫–∏ (chunker):
       - semanticsplit / by_row / full_table / fixed_size / none.
     - —Ç–æ –µ—Å—Ç—å –∏—Å—Ç–æ—á–Ω–∏–∫ —Ä–µ—à–∞–µ—Ç "–∫–∞–∫ –¥–∞–Ω–Ω—ã–µ —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–∏—Ä–æ–≤–∞—Ç—å –≤ –Ω–∞–±–æ—Ä —á–∞–Ω–∫–æ–≤ –∏ –∫—É–¥–∞ –∏–º–µ–Ω–Ω–æ –∏—Ö –ø–æ–ª–æ–∂–∏—Ç—å (Chroma, SQLite-–≤–µ–∫—Ç–æ—Ä–∫–∞ –∏ —Ç.–ø.)".
  2) –ó–∞–¥–∞—á–∞ (task, TaskConfig) –æ—Ç–≤–µ—á–∞–µ—Ç –∑–∞:
     - –≤—ã–±–æ—Ä embedding-–º–æ–¥–µ–ª–∏ (embedding_model: technical-ru / default-multilingual –∏ —Ç.–ø.);
     - —Ä–µ–∂–∏–º –ø–æ–∏—Å–∫–∞ (search.mode: topk / allwiththreshold / hybrid);
     - –ø–∞—Ä–∞–º–µ—Ç—Ä—ã —Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–æ–≥–æ –ø–æ–∏—Å–∫–∞:
       - top_k, max_rows, similarity_threshold;
     - —Ä–µ–∂–∏–º RAG –ø–æ –∏—Å—Ç–æ—á–Ω–∏–∫–∞–º:
       - sources.mode: text | tables | text+tables.
- –¢–∞–∫–∏–º –æ–±—Ä–∞–∑–æ–º:
  - –û–¥–∏–Ω –∏ —Ç–æ—Ç –∂–µ –∏—Å—Ç–æ—á–Ω–∏–∫ (–Ω–∞–ø—Ä–∏–º–µ—Ä, "employees.csv" –∏–ª–∏ "services.csv") –º–æ–∂–µ—Ç –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å—Å—è –≤ –Ω–µ—Å–∫–æ–ª—å–∫–∏—Ö –∑–∞–¥–∞—á–∞—Ö —Å —Ä–∞–∑–Ω—ã–º–∏ embedding-–º–æ–¥–µ–ª—è–º–∏ –∏ –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏ –ø–æ–∏—Å–∫–∞.
  - –î–ª—è –Ω–µ–±–æ–ª—å—à–æ–π —Ç–∞–±–ª–∏—Ü—ã –º–æ–∂–Ω–æ –≤ –æ–¥–Ω–æ–π –∑–∞–¥–∞—á–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å —Ä–µ–∂–∏–º "full_table_as_single_chunk" (–ø–æ–¥–º–µ—à–∏–≤–∞—Ç—å —Ü–µ–ª–∏–∫–æ–º –≤ –∫–æ–Ω—Ç–µ–∫—Å—Ç),
    –∞ –≤ –¥—Ä—É–≥–æ–π ‚Äî "row_to_chunk" (—Å—Ç—Ä–æ–∫–∏ –∫–∞–∫ –æ—Ç–¥–µ–ª—å–Ω—ã–µ —á–∞–Ω–∫–∏ —Å –ø–æ—Ä–æ–≥–æ–º –ø–æ similarity).
- –≠—Ç–æ —Å–æ–≤–º–µ—â–∞–µ—Ç —Ç—Ä–µ–±–æ–≤–∞–Ω–∏—è –¢–ó –∫ TaskConfig (—Ä–∞–∑–¥–µ–ª sources/search/postprocessing) —Å –ø—Ä–∞–∫—Ç–∏—á–Ω–æ–π —Ä–µ–∞–ª–∏–∑–∞—Ü–∏–µ–π –≤ —Ç–µ–∫—É—â–µ–º –ø—Ä–æ—Ç–æ—Ç–∏–ø–µ.

5. –†–µ—à–µ–Ω–∏—è –ø–æ –≤–µ–∫—Ç–æ—Ä–Ω–æ–º—É –ø–æ–∏—Å–∫—É –∏ "–≤—Å–µ–º –≤—Ö–æ–∂–¥–µ–Ω–∏—è–º"
- –û–±—Å—É–∂–¥—ë–Ω –≤–∞–∂–Ω—ã–π –∫–µ–π—Å: "–Ω–∞–π—Ç–∏ –Ω–µ —Ñ–∏–∫—Å–∏—Ä–æ–≤–∞–Ω–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ N –≤—Ö–æ–∂–¥–µ–Ω–∏–π, –∞ –≤—Å–µ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã–µ –≤—Ö–æ–∂–¥–µ–Ω–∏—è".
- –ü—Ä–∏–Ω—è—Ç–æ —Ä–µ—à–µ–Ω–∏–µ:
  - –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å search –ø–æ –≤–µ–∫—Ç–æ—Ä–∫–µ –Ω–µ —Ç–æ–ª—å–∫–æ –≤ —Ä–µ–∂–∏–º–µ "top_k", –Ω–æ –∏ –≤ —Ä–µ–∂–∏–º–µ "all_with_threshold":
    - —Å–Ω–∞—á–∞–ª–∞ –∑–∞–ø—Ä–∞—à–∏–≤–∞–µ–º –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –±–æ–ª—å—à–æ–π –Ω–∞–±–æ—Ä –∫–∞–Ω–¥–∏–¥–∞—Ç–æ–≤ (–Ω–∞–ø—Ä–∏–º–µ—Ä, –¥–æ max_rows),
    - –∑–∞—Ç–µ–º —Ñ–∏–ª—å—Ç—Ä—É–µ–º –ø–æ similarity_threshold (–Ω–∞–ø—Ä–∏–º–µ—Ä, ‚â• 0.35-0.4),
    - –∏—Ç–æ–≥–æ–≤—ã–π —Å–ø–∏—Å–æ–∫ –º–æ–∂–µ—Ç –±—ã—Ç—å –ª—é–±–æ–π –¥–ª–∏–Ω—ã –¥–æ max_rows, –Ω–æ –≥–∞—Ä–∞–Ω—Ç–∏—Ä–æ–≤–∞–Ω–Ω–æ "–Ω–µ —Å–ª—É—á–∞–π–Ω—ã–π –º—É—Å–æ—Ä".
- –õ–õ–ú –≤ —Ç–∞–∫–æ–º —Å—Ü–µ–Ω–∞—Ä–∏–∏:
  - –ø–æ–ª—É—á–∞–µ—Ç –≤ –∫–æ–Ω—Ç–µ–∫—Å—Ç –≤—Å–µ –Ω–∞–π–¥–µ–Ω–Ω—ã–µ —Å—Ç—Ä–æ–∫–∏/—á–∞–Ω–∫–∏, —É–¥–æ–≤–ª–µ—Ç–≤–æ—Ä—è—é—â–∏–µ –ø–æ—Ä–æ–≥—É,
  - –¥–∞–ª–µ–µ —Å–∞–º –≤—ã–±–∏—Ä–∞–µ—Ç, —á—Ç–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –≤ –æ—Ç–≤–µ—Ç–µ.
- –≠—Ç–æ –æ—Ç—Ä–∞–∂–∞–µ—Ç –∏–¥–µ—é –∏–∑ –¢–ó (mode: allwiththreshold, max_rows, similarity_threshold) –∏ —Ö–æ—Ä–æ—à–æ —Ä–µ—à–∞–µ—Ç –∑–∞–¥–∞—á—É "–Ω–∞–π—Ç–∏ –≤—Å–µ—Ö —Å–æ—Ç—Ä—É–¥–Ω–∏–∫–æ–≤/—Å–µ—Ä–≤–∏—Å—ã, –∏–º–µ—é—â–∏—Ö –æ—Ç–Ω–æ—à–µ–Ω–∏–µ –∫ ClickHouse" –∏ —Ç.–ø.

6. –ë—É–¥—É—â–∏–µ —à–∞–≥–∏ (–∑–∞–¥–∞–Ω–Ω–æ–µ –Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–∏–µ)
- –ù–∞ —Ç–µ–∫—É—â–µ–º —ç—Ç–∞–ø–µ –º—ã:
  - —Ä–µ–∞–ª–∏–∑–æ–≤–∞–ª–∏ test-—Ä–µ–∂–∏–º –±–µ–∑ LLM —Å –ø—Ä–æ–∑—Ä–∞—á–Ω—ã–º –≤—ã–≤–æ–¥–æ–º retrieved_chunks/table_rows;
  - —Å–æ–≥–ª–∞—Å–æ–≤–∞–ª–∏ —Å—Ç—Ä–∞—Ç–µ–≥–∏—é, —á—Ç–æ —Ç–∞–±–ª–∏—á–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –º–æ–≥—É—Ç:
    - –ª–∏–±–æ —Ä–∞–±–æ—Ç–∞—Ç—å –∫–∞–∫ –æ—Ç–¥–µ–ª—å–Ω—ã–µ —á–∞–Ω–∫–∏ –≤ –≤–µ–∫—Ç–æ—Ä–∫–µ (row_to_chunk / full_table_as_single_chunk),
    - –ª–∏–±–æ, –ø—Ä–∏ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ—Å—Ç–∏, –¥–æ–ø–æ–ª–Ω—è—Ç—å—Å—è SQL-—Ñ–∏–ª—å—Ç—Ä–∞–º–∏, –Ω–æ —Å–µ–º–∞–Ω—Ç–∏–∫–∞ –æ—Å—Ç–∞—ë—Ç—Å—è –∑–∞ –≤–µ–∫—Ç–æ—Ä–∫–æ–π.
- –°–ª–µ–¥—É—é—â–∏–µ —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏–µ —à–∞–≥–∏, –∫–æ—Ç–æ—Ä—ã–µ –±—É–¥—É—Ç —Å–¥–µ–ª–∞–Ω—ã –ø–æ–∑–∂–µ (–≤ –æ—Ç–¥–µ–ª—å–Ω–æ–º —Ü–∏–∫–ª–µ):
  - —Ä–∞—Å—à–∏—Ä–∏—Ç—å TaskConfig –¥–æ —Å—Ö–µ–º—ã –∏–∑ –¢–ó:
    - sources.mode (text/tables/text+tables),
    - sources.<...>.chunker (semanticsplit/by_row/full_table),
    - search.mode (topk/allwiththreshold),
    - search.similarity_threshold, search.max_rows,
    - embedding_model.
  - –≤—ã–Ω–µ—Å—Ç–∏ —Ç–∞–±–ª–∏—á–Ω—ã–π RAG –≤ –æ—Ç–¥–µ–ª—å–Ω—ã–π –º–æ–¥—É–ª—å (table_rag.py) –∏ –ø–µ—Ä–µ–≤–µ—Å—Ç–∏ —Ç–µ–∫—É—â—É—é –ª–æ–≥–∏–∫—É employee_data –Ω–∞ —É–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω—ã–π –º–µ—Ö–∞–Ω–∏–∑–º:
    - –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ —Ç–∞–±–ª–∏—Ü—ã –≤ JSON/—á–∞–Ω–∫–∏,
    - —Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–∏–π –ø–æ–∏—Å–∫ –ø–æ –≤–µ–∫—Ç–æ—Ä–∫–µ,
    - —Ñ–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–∏–µ —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω–æ–≥–æ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ –¥–ª—è LLM.
  - —Ä–µ–∞–ª–∏–∑–æ–≤–∞—Ç—å CSV‚ÜíJSON-–ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞—Ç–µ–ª—å –¥–ª—è ingestion —Ç–∞–±–ª–∏—á–Ω—ã—Ö –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤:
    - –∫–∞–∂–¥–∞—è —Å—Ç—Ä–æ–∫–∞ CSV –ø—Ä–µ–≤—Ä–∞—â–∞–µ—Ç—Å—è –≤ JSON-–æ–±—ä–µ–∫—Ç,
    - –¥–∞–ª–µ–µ –ª–∏–±–æ —Å–æ–±–∏—Ä–∞–µ—Ç—Å—è –≤ –æ–¥–∏–Ω —á–∞–Ω–∫ (full_table), –ª–∏–±–æ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –ø–æ —Å—Ç—Ä–æ–∫–∞–º (row_to_chunk).

–í—Å–µ —ç—Ç–∏ —Ä–µ—à–µ–Ω–∏—è —Å–æ–≥–ª–∞—Å–æ–≤–∞–Ω—ã –∏ –∑–∞—Ñ–∏–∫—Å–∏—Ä–æ–≤–∞–Ω—ã –≤ —ç—Ç–æ–º –ª–æ–≥-–∑–∞–ø–∏—Å–∏ –∫–∞–∫ —Ü–µ–ª–µ–≤–æ–π –≤–µ–∫—Ç–æ—Ä —Ä–∞–∑–≤–∏—Ç–∏—è –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã RAG –≤ –ø—Ä–æ–µ–∫—Ç–µ N3R7A2C7.
!!!!

–†–µ–∂–∏–º—ã –∏ –∫–æ–Ω—Ñ–∏–≥–∏
–ì–ª–æ–±–∞–ª—å–Ω–æ–µ –æ–∫—Ä—É–∂–µ–Ω–∏–µ —Å–µ—Ä–≤–∏—Å–∞ –∑–∞–¥–∞—ë—Ç—Å—è –≤ config/system.yaml, –ø–æ–ª–µ environment: dev/test/prod.
‚Äã

–°–µ–π—á–∞—Å —Ç–∞–º —Å—Ç–æ–∏—Ç environment: test, –ø–æ—ç—Ç–æ–º—É:

LLM –Ω–µ –≤—ã–∑—ã–≤–∞–µ—Ç—Å—è,

–≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç—Å—è answer="TEST MODE: ..." –∏ –ø–æ–¥—Ä–æ–±–Ω–∞—è meta (—á–∞–Ω–∫–∏/—Å—Ç—Ä–æ–∫–∏).
‚Äã

–ë–æ—Ç —Ä–µ–∂–∏–º –±–æ–ª—å—à–µ –Ω–µ –±–µ—Ä—ë—Ç –∏–∑ .env, –æ–Ω –∑–∞–ø—Ä–∞—à–∏–≤–∞–µ—Ç /api/v1/health –∏ –ø–æ–∫–∞–∑—ã–≤–∞–µ—Ç –°–µ–π—á–∞—Å –æ–∫—Ä—É–∂–µ–Ω–∏–µ —Å–µ—Ä–≤–∏—Å–∞: test/dev –ø–æ —Ñ–∞–∫—Ç—É.
‚Äã

CLI –∏ TaskConfig
–ï—Å—Ç—å –∞–¥–º–∏–Ω‚ÄëCLI app/cli/admin_cli.py —Å –∫–æ–º–∞–Ω–¥–∞–º–∏:

python -m app.cli.admin_cli env ‚Äî –ø–æ–∫–∞–∑–∞—Ç—å –æ–∫—Ä—É–∂–µ–Ω–∏–µ (–∏–∑ config/system.yaml).
‚Äã

python -m app.cli.admin_cli tasks-list ‚Äî —Å–ø–∏—Å–æ–∫ –∑–∞–¥–∞—á —Å task_type –∏ sources.mode.
‚Äã

python -m app.cli.admin_cli task-info <task_id> ‚Äî –ø–æ–¥—Ä–æ–±–Ω—ã–π TaskConfig, –≤–∫–ª—é—á–∞—è sources.mode, text_search/table_search, postprocessing, technical_prompt.
‚Äã

TaskConfig —Ä–∞—Å—à–∏—Ä–µ–Ω: —É–º–µ–µ—Ç sources_mode, —Ñ–ª–∞–≥–∏ enable_* –∏ –≤–ª–æ–∂–µ–Ω–Ω—ã–µ text_search / table_search —Å –ø–æ–ª—è–º–∏ –¥–ª—è —á–∞–Ω–∫–∏–Ω–≥–∞ (chunker, topk, thresholds –∏ —Ç.–ø.).
‚Äã

–ë–æ—Ç –∏ –ø–æ–≤–µ–¥–µ–Ω–∏–µ –≤ test
–ë–æ—Ç –ª–µ–∂–∏—Ç –≤ app/bot/telegram_bot.py, –∑–∞–ø—É—Å–∫–∞–µ—Ç—Å—è python -m app.bot.telegram_bot.
‚Äã

–ö–æ–º–∞–Ω–¥—ã/–∫–Ω–æ–ø–∫–∏:

/start ‚Äî –ø—Ä–∏–≤–µ—Ç—Å—Ç–≤–∏–µ + –ø–æ–∫–∞–∑—ã–≤–∞–µ—Ç –æ–∫—Ä—É–∂–µ–Ω–∏–µ —Å–µ—Ä–≤–∏—Å–∞ –∏–∑ /api/v1/health.
‚Äã

/tasks –∏–ª–∏ –∫–Ω–æ–ø–∫–∞ üìù Tasks ‚Äî —Å–ø–∏—Å–æ–∫ –∑–∞–¥–∞—á –∏–∑ /api/v1/tasks.
‚Äã

–∫–Ω–æ–ø–∫–∏ üéØ <task_id> ‚Äî –≤—ã–±–æ—Ä –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–π –∑–∞–¥–∞—á–∏ –¥–ª—è —á–∞—Ç–∞.
‚Äã

–í test‚Äë–æ–∫—Ä—É–∂–µ–Ω–∏–∏:

demo‚Äë—Ç–∞—Å–∫–∏ (demo_hello, demo_rules) –≤–æ–∑–≤—Ä–∞—â–∞—é—Ç TEST MODE: LLM –Ω–µ –≤—ã–∑—ã–≤–∞–ª—Å—è, –≤–æ–∑–≤—Ä–∞—â–µ–Ω—ã —Ç–æ–ª—å–∫–æ –Ω–∞–π–¥–µ–Ω–Ω—ã–µ —á–∞–Ω–∫–∏. –∏ meta.retrieved_chunks.
‚Äã

employee_data –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç TEST MODE: LLM –Ω–µ –≤—ã–∑—ã–≤–∞–ª—Å—è, –≤–æ–∑–≤—Ä–∞—â–µ–Ω—ã —Ç–æ–ª—å–∫–æ —Å—Ç—Ä–æ–∫–∏ —Ç–∞–±–ª–∏—Ü—ã (—á–µ—Ä–µ–∑ –≤–µ–∫—Ç–æ—Ä–Ω—ã–π –ø–æ–∏—Å–∫). –∏ meta.table_rows.
‚Äã

–ë–æ—Ç –ø—Ä–∏ debug=True –¥–æ–ø–∏—Å—ã–≤–∞–µ—Ç –∫ –æ—Ç–≤–µ—Ç—É –±–ª–æ–∫ [TEST META] ... (–ø–µ—Ä–≤—ã–µ –Ω–µ—Å–∫–æ–ª—å–∫–æ —á–∞–Ω–∫–æ–≤/—Å—Ç—Ä–æ–∫ —Å source_id/score/—Ç–µ–∫—Å—Ç–æ–º).
‚Äã

–ü–æ–∏—Å–∫ –∏ –∫–∞—á–µ—Å—Ç–≤–æ
–î–ª—è demo‚Äë—Ç–∞—Å–∫–∏ demo_rules —Ç—ã —É–∂–µ –≤–∏–¥–µ–ª –≤ –±–æ—Ç–µ:

TEST MODE...

[TEST META] –ü–µ—Ä–≤—ã–µ –Ω–∞–π–¥–µ–Ω–Ω—ã–µ —á–∞–Ω–∫–∏: —Å –∫—É—Å–∫–∞–º–∏ —Ä–µ–≥–ª–∞–º–µ–Ω—Ç–æ–≤ (–ø—Ä–æ –¥–æ—Å—Ç—É–ø—ã, –ò–ë –∏ —Ç.–ø.).
‚Äã

–î–ª—è employee_data:

–ø—Ä–∏ –≤–æ–ø—Ä–æ—Å–∞—Ö –ø—Ä–æ ‚Äú–ò–≤–∞–Ω–æ–≤–∞‚Äù –≤ test —Ä–µ–∂–∏–º –¥–∞—ë—Ç TEST MODE... ‚Äî —Ç–æ–ª—å–∫–æ —Å—Ç—Ä–æ–∫–∏ —Ç–∞–±–ª–∏—Ü—ã, —á–µ—Ä–µ–∑ –≤–µ–∫—Ç–æ—Ä–Ω—ã–π –ø–æ–∏—Å–∫ –ø–æ –¥–µ–º–æ‚Äë—Å–æ—Ç—Ä—É–¥–Ω–∏–∫–∞–º.
‚Äã

–§–∏–ª—å—Ç—Ä –º–∞—Ç–∞ —Ä–∞–±–æ—Ç–∞–µ—Ç –Ω–∞ —É—Ä–æ–≤–Ω–µ –ª–æ–≥–æ–≤/—Ñ–ª–∞–≥–æ–≤, –Ω–æ –≤ TEST MODE –æ—Ç–≤–µ—Ç —Ñ–æ—Ä–º–∏—Ä—É–µ—Ç—Å—è –±–µ–∑ LLM, –ø–æ—ç—Ç–æ–º—É —Å–æ–¥–µ—Ä–∂–∏–º–æ–µ –æ—Ç–≤–µ—Ç–∞ —Å–µ–π—á–∞—Å –Ω–µ ‚Äú—Å–º—è–≥—á–∞–µ—Ç—Å—è‚Äù; —ç—Ç–æ –æ–∂–∏–¥–∞–µ–º–æ –¥–ª—è —Ç–µ—Å—Ç–æ–≤–æ–≥–æ —Ä–µ–∂–∏–º–∞.

–ß—Ç–æ –¥–∞–ª—å—à–µ –ª–æ–≥–∏—á–Ω–æ –¥–µ–ª–∞—Ç—å
–ö–æ–≥–¥–∞ –∑–∞—Ö–æ—á–µ—à—å —Ä–µ–∞–ª—å–Ω—ã–µ –æ—Ç–≤–µ—Ç—ã ‚Äî –≤ config/system.yaml –ø–µ—Ä–µ–∫–ª—é—á–∏—Ç—å environment: dev, –ø–µ—Ä–µ–∑–∞–ø—É—Å—Ç–∏—Ç—å API –∏ –±–æ—Ç–∞; —Ç–æ–≥–¥–∞ LLM –±—É–¥–µ—Ç –≤—ã–∑—ã–≤–∞—Ç—å—Å—è, –∞ –±–æ—Ç –ø–µ—Ä–µ—Å—Ç–∞–Ω–µ—Ç –≤–∏–¥–µ—Ç—å TEST MODE –∏ —Å—Ç–∞–Ω–µ—Ç –ø–æ–∫–∞–∑—ã–≤–∞—Ç—å –Ω–æ—Ä–º–∞–ª—å–Ω—ã–µ –æ—Ç–≤–µ—Ç—ã.

–î–∞–ª–µ–µ –ø–ª–∞–Ω: –¥–æ–±–∞–≤–∏—Ç—å –Ω–æ–≤—ã–µ –∑–∞–¥–∞—á–∏ (–ß–∏–ø–æ–ª–ª–∏–Ω–æ, –£–ö, —Ç–∞–±–ª–∏—á–Ω—ã–µ) —á–µ—Ä–µ–∑ YAML + ingestion, –∏ —É–∂–µ –∏—Ö —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞—Ç—å —á–µ—Ä–µ–∑ —Ç–æ—Ç –∂–µ CLI –∏ –±–æ—Ç–∞ –±–µ–∑ –ø—Ä–∞–≤–∫–∏ –∫–æ–¥–∞.

–í–æ—Ç –ø–æ–ª–Ω—ã–π –ª–æ–≥ –¥–ª—è –ø–µ—Ä–µ–¥–∞—á–∏ –¥—Ä—É–≥–æ–º—É –∞–≥–µ–Ω—Ç—É:

text
cat >> DEV_LOG.txt << 'EOF'

================================================================================
2026-02-06 07:45 ‚Äî –ü–û–õ–ù–´–ô –ö–û–ù–¢–ï–ö–°–¢–ù–´–ô –õ–û–ì –î–õ–Ø –ü–ï–†–ï–î–ê–ß–ò
================================================================================

## –ü–†–û–ï–ö–¢: N3R7A2C7 (ragadvct)

RAG-—Å–∏—Å—Ç–µ–º–∞ –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ —Ç–µ–∫—Å—Ç–æ–≤—ã—Ö –∑–∞—è–≤–æ–∫ —Å –º–Ω–æ–≥–æ–∑–∞–¥–∞—á–Ω–æ–π –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–æ–π,
LLM-–∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–µ–π (Ollama), –≤–µ–∫—Ç–æ—Ä–Ω—ã–º –ø–æ–∏—Å–∫–æ–º (ChromaDB) –∏ —Ç–∞–±–ª–∏—á–Ω—ã–º RAG (SQLite).

GitHub: github.com/N3RT/N3R7A2C7

--------------------------------------------------------------------------------
## –¢–ï–ö–£–©–ê–Ø –í–ï–†–°–ò–Ø: 0.3.x
--------------------------------------------------------------------------------

### –°–¢–†–£–ö–¢–£–†–ê –ü–†–û–ï–ö–¢–ê

ragadvct/
‚îú‚îÄ‚îÄ app/
‚îÇ ‚îú‚îÄ‚îÄ api/v1/routes.py # FastAPI endpoints, –≥–ª–∞–≤–Ω—ã–π _run_task
‚îÇ ‚îú‚îÄ‚îÄ bot/telegrambot.py # Telegram-–±–æ—Ç (polling mode)
‚îÇ ‚îú‚îÄ‚îÄ cli/admin_cli.py # CLI: env, task-info, tasks-list
‚îÇ ‚îú‚îÄ‚îÄ core/
‚îÇ ‚îÇ ‚îú‚îÄ‚îÄ config_loader.py # load_system_config, get_environment
‚îÇ ‚îÇ ‚îú‚îÄ‚îÄ task_config.py # TaskConfig dataclass + load_task_config
‚îÇ ‚îÇ ‚îú‚îÄ‚îÄ task_registry.py # TaskRegistry singleton
‚îÇ ‚îÇ ‚îú‚îÄ‚îÄ access_control.py # check_task_access (demo/corporate –ø–æ–ª–∏—Ç–∏–∫–∏)
‚îÇ ‚îÇ ‚îú‚îÄ‚îÄ chroma_client.py # get_chroma_client (persistent)
‚îÇ ‚îÇ ‚îú‚îÄ‚îÄ rag_pipeline.py # retrieve_text_chunks, build_llm_prompt
‚îÇ ‚îÇ ‚îú‚îÄ‚îÄ table_rag.py # search_table_semantic, ingest_table_rows_to_chroma
‚îÇ ‚îÇ ‚îú‚îÄ‚îÄ task_classifier.py # classify_query (LLM-—Ä–æ—É—Ç–µ—Ä)
‚îÇ ‚îÇ ‚îú‚îÄ‚îÄ event_logger.py # log_event ‚Üí .data/logs/app.log (JSONL)
‚îÇ ‚îÇ ‚îú‚îÄ‚îÄ glossary.py # normalize_query (—Å–∏–Ω–æ–Ω–∏–º—ã)
‚îÇ ‚îÇ ‚îî‚îÄ‚îÄ profanity_filter.py# check_profanity
‚îÇ ‚îú‚îÄ‚îÄ ingestion/
‚îÇ ‚îÇ ‚îú‚îÄ‚îÄ employee_table.py # ensure_employee_table, seed_demo_employees
‚îÇ ‚îÇ ‚îî‚îÄ‚îÄ employee_ingest.py # ingest_employee_table_to_chroma
‚îÇ ‚îî‚îÄ‚îÄ postprocessing/
‚îÇ ‚îî‚îÄ‚îÄ files.py # save_markdown, save_docx ‚Üí .data/outputs/
‚îú‚îÄ‚îÄ config/
‚îÇ ‚îú‚îÄ‚îÄ system.yaml # environment, paths, llm, access_control
‚îÇ ‚îú‚îÄ‚îÄ glossary.yaml # —Å–∏–Ω–æ–Ω–∏–º—ã –¥–ª—è –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏–∏
‚îÇ ‚îú‚îÄ‚îÄ profanity_exceptions.yaml
‚îÇ ‚îî‚îÄ‚îÄ tasks/
‚îÇ ‚îú‚îÄ‚îÄ demo_hello.yaml
‚îÇ ‚îú‚îÄ‚îÄ demo_rules.yaml
‚îÇ ‚îî‚îÄ‚îÄ employee_data.yaml # (–Ω—É–∂–Ω–æ —Å–æ–∑–¥–∞—Ç—å/–æ–±–Ω–æ–≤–∏—Ç—å)
‚îú‚îÄ‚îÄ data/ (.data/)
‚îÇ ‚îú‚îÄ‚îÄ chroma_db/ # ChromaDB persistent storage
‚îÇ ‚îú‚îÄ‚îÄ sqlite/tables.db # SQLite –¥–ª—è —Ç–∞–±–ª–∏—á–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö
‚îÇ ‚îú‚îÄ‚îÄ logs/app.log # JSONL event log
‚îÇ ‚îî‚îÄ‚îÄ outputs/ # –°–æ—Ö—Ä–∞–Ω—ë–Ω–Ω—ã–µ –æ—Ç–≤–µ—Ç—ã (md/docx)
‚îú‚îÄ‚îÄ llm_connectors/
‚îÇ ‚îî‚îÄ‚îÄ connector_dev.py # call_llm ‚Üí ollama_chat_4b (http://127.0.0.1:4004)
‚îú‚îÄ‚îÄ tests/
‚îÇ ‚îî‚îÄ‚îÄ test_api.py # pytest, 5 –±–∞–∑–æ–≤—ã—Ö —Ç–µ—Å—Ç–æ–≤
‚îú‚îÄ‚îÄ docker/
‚îÇ ‚îú‚îÄ‚îÄ Dockerfile
‚îÇ ‚îî‚îÄ‚îÄ docker-compose.dev.yml
‚îú‚îÄ‚îÄ code_collector.py # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç all_code.txt snapshot
‚îú‚îÄ‚îÄ requirements.txt
‚îú‚îÄ‚îÄ .env # TELEGRAM_BOT_TOKEN, OLLAMA_CHAT_URL
‚îî‚îÄ‚îÄ DEV_LOG.txt # –≠—Ç–æ—Ç —Ñ–∞–π–ª

text

--------------------------------------------------------------------------------
## –ß–¢–û –£–ñ–ï –†–ï–ê–õ–ò–ó–û–í–ê–ù–û
--------------------------------------------------------------------------------

### 1. CORE INFRASTRUCTURE

- [x] FastAPI app —Å —Ä–æ—É—Ç–µ—Ä–æ–º /api/v1
- [x] Health endpoint: GET /api/v1/health
- [x] LLM test endpoint: GET /api/v1/llm_test
- [x] –ö–æ–Ω—Ñ–∏–≥-—Å–∏—Å—Ç–µ–º–∞: config/system.yaml ‚Üí get_environment(), get_llm_mode()
- [x] –¢—Ä–∏ –æ–∫—Ä—É–∂–µ–Ω–∏—è: dev, test, prod
  - dev: –ø–æ–ª–Ω—ã–π RAG + LLM
  - test: RAG –±–µ–∑ LLM (–≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç meta —Å —á–∞–Ω–∫–∞–º–∏)
  - prod: —Ç–æ–ª—å–∫–æ corporate –∑–∞–¥–∞—á–∏

### 2. TASK SYSTEM

- [x] TaskConfig dataclass —Å –ø–æ–ª—è–º–∏:
  - task_id, name, description, task_type (demo|corporate)
  - technical_prompt
  - sources_mode: text | tables | texttables
  - enable_text_search, enable_table_search, enable_research
  - postprocessing_type: none | markdown-file | docx-file | customscript
  - text_search: TextSearchConfig (embedding_model, mode, topk, threshold, chunker)
  - table_search: TableSearchConfig (embedding_model, mode, topk, max_rows, threshold, chunker)

- [x] TaskRegistry singleton:
  - scan_tasks_dir() ‚Äî —Å–∫–∞–Ω–∏—Ä—É–µ—Ç config/tasks/*.yaml
  - get_task_config(task_id) ‚Äî –∑–∞–≥—Ä—É–∂–∞–µ—Ç –∏ –∫–µ—à–∏—Ä—É–µ—Ç
  - list_registered_tasks() ‚Äî —Å–ø–∏—Å–æ–∫ –¥–ª—è API/–±–æ—Ç–∞

- [x] REST endpoints:
  - GET /api/v1/tasks ‚Äî —Å–ø–∏—Å–æ–∫ –∑–∞–¥–∞—á (–≤ prod —Å–∫—Ä—ã–≤–∞–µ—Ç demo)
  - GET /api/v1/tasks/{task_id} ‚Äî –∏–Ω—Ñ–æ –æ –∑–∞–¥–∞—á–µ
  - POST /api/v1/task/query ‚Äî –∑–∞–ø—Ä–æ—Å –∫ –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–π –∑–∞–¥–∞—á–µ
  - POST /api/v1/query ‚Äî generic router —á–µ—Ä–µ–∑ LLM-–∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä

### 3. RAG PIPELINE (–¥–ª—è demo-–∑–∞–¥–∞—á)

- [x] ChromaDB persistent client (.data/chroma_db/)
- [x] ensure_collection_for_task() ‚Äî —Å–æ–∑–¥–∞—ë—Ç –∫–æ–ª–ª–µ–∫—Ü–∏–∏ —Å seed-–¥–∞–Ω–Ω—ã–º–∏ –¥–ª—è demo
- [x] retrieve_text_chunks(task_cfg, query, top_k) ‚Äî —Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–∏–π –ø–æ–∏—Å–∫
- [x] retrieve_text_chunks_for_research() ‚Äî —Ä–∞—Å—à–∏—Ä–µ–Ω–Ω—ã–π –ø–æ–∏—Å–∫ –¥–ª—è 2–π –ø–æ–ø—ã—Ç–∫–∏
- [x] build_llm_prompt() ‚Äî —Å–æ–±–∏—Ä–∞–µ—Ç system prompt –∏–∑ technical_prompt + –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞

### 4. TABLE RAG

- [x] SQLite: .data/sqlite/tables.db
- [x] employee_table.py: ensure_employee_table(), seed_demo_employees()
- [x] table_rag.py:
  - build_row_text(row) ‚Äî —Ñ–æ—Ä–º–∏—Ä—É–µ—Ç —Ç–µ–∫—Å—Ç –∏–∑ —Å—Ç—Ä–æ–∫–∏ —Ç–∞–±–ª–∏—Ü—ã
  - ingest_table_rows_to_chroma() ‚Äî row-to-chunk ingestion
  - search_table_semantic() ‚Äî —Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–∏–π –ø–æ–∏—Å–∫ –ø–æ —Ç–∞–±–ª–∏—Ü–µ

### 5. ACCESS CONTROL

- [x] check_task_access(task_cfg) ‚Üí AccessDecision(allowed, reason)
- [x] –ü–æ–ª–∏—Ç–∏–∫–∏:
  - demo: —Ä–∞–∑—Ä–µ—à–µ–Ω–æ –≤ dev –∏ test, –∑–∞–ø—Ä–µ—â–µ–Ω–æ –≤ prod
  - corporate: —Ä–∞–∑—Ä–µ—à–µ–Ω–æ –≤ prod, –≤ dev ‚Äî –ø–æ —Ñ–ª–∞–≥—É allow_corporate_in_dev

### 6. PREPROCESSING

- [x] glossary.py: normalize_query() ‚Äî –∑–∞–º–µ–Ω–∞ —Å–∏–Ω–æ–Ω–∏–º–æ–≤ –∏–∑ config/glossary.yaml
- [x] profanity_filter.py: check_profanity() ‚Äî –¥–µ—Ç–µ–∫—Ü–∏—è –Ω–µ—Ü–µ–Ω–∑—É—Ä–Ω–æ–π –ª–µ–∫—Å–∏–∫–∏

### 7. POSTPROCESSING

- [x] save_markdown(content, task_cfg) ‚Üí (.data/outputs/{task_id}_{timestamp}.md, filename)
- [x] save_docx(content, task_cfg) ‚Üí (.data/outputs/{task_id}_{timestamp}.docx, filename)
- [x] –†–µ–∑—É–ª—å—Ç–∞—Ç –≤ meta.postprocessing: {type, path, filename}
- [x] –§–∞–π–ª—ã —Å–æ–∑–¥–∞—é—Ç—Å—è –í–°–ï–ì–î–ê –ø—Ä–∏ postprocessing_type != none, –Ω–µ–∑–∞–≤–∏—Å–∏–º–æ –æ—Ç –±–æ—Ç–∞

### 8. EVENT LOGGING

- [x] log_event() ‚Üí .data/logs/app.log (JSONL)
- [x] –°–æ–±—ã—Ç–∏—è: query, query_error, access_denied, search, llm, llm_error, final, classification, research_search
- [x] –ö–∞–∂–¥—ã–π –∑–∞–ø—Ä–æ—Å –∏–º–µ–µ—Ç request_id –¥–ª—è —Ç—Ä–∞—Å—Å–∏—Ä–æ–≤–∫–∏

### 9. LLM INTEGRATION

- [x] connector_dev.py: call_llm(messages, model) ‚Üí async httpx –∫ ollama_chat_4b
- [x] –ú–æ–¥–µ–ª–∏: llama3.2:1b, llama3.2:3b
- [x] LLMError exception –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ –æ—à–∏–±–æ–∫
- [x] task_classifier.py: classify_query() ‚Äî LLM –æ–ø—Ä–µ–¥–µ–ª—è–µ—Ç task_id –ø–æ —Ç–µ–∫—Å—Ç—É –∑–∞–ø—Ä–æ—Å–∞

### 10. TELEGRAM BOT

- [x] Polling mode, long-polling getUpdates
- [x] –ö–æ–º–∞–Ω–¥—ã: /start, /tasks
- [x] Keyboard —Å –∫–Ω–æ–ø–∫–∞–º–∏ –∑–∞–¥–∞—á
- [x] –í—ã–±–æ—Ä –∑–∞–¥–∞—á–∏ —á–µ—Ä–µ–∑ "üéØ task_id"
- [x] –û—Ç–ø—Ä–∞–≤–∫–∞ –∑–∞–ø—Ä–æ—Å–æ–≤ –∫ RAG API
- [x] –í test-—Ä–µ–∂–∏–º–µ –ø–æ–∫–∞–∑—ã–≤–∞–µ—Ç TEST META —Å —á–∞–Ω–∫–∞–º–∏/—Å—Ç—Ä–æ–∫–∞–º–∏
- [ ] –ù–ï –æ—Ç–ø—Ä–∞–≤–ª—è–µ—Ç —Ñ–∞–π–ª—ã (docx/md) ‚Äî —Ç–æ–ª—å–∫–æ —Ç–µ–∫—Å—Ç

### 11. CLI

- [x] python -m app.cli.admin_cli env ‚Äî –ø–æ–∫–∞–∑–∞—Ç—å –æ–∫—Ä—É–∂–µ–Ω–∏–µ
- [x] python -m app.cli.admin_cli tasks-loaded ‚Äî —Å–ø–∏—Å–æ–∫ –∑–∞–≥—Ä—É–∂–µ–Ω–Ω—ã—Ö –∑–∞–¥–∞—á
- [x] python -m app.cli.admin_cli tasks-list ‚Äî —Ç–∞–±–ª–∏—Ü–∞ –∑–∞–¥–∞—á —Å sources.mode
- [x] python -m app.cli.admin_cli task-info {task_id} ‚Äî –¥–µ—Ç–∞–ª–∏ TaskConfig

### 12. DEPENDENCIES (requirements.txt)

fastapi, uvicorn, pydantic, httpx, requests, pyyaml, python-dotenv,
chromadb, sentence-transformers, click, python-docx

--------------------------------------------------------------------------------
## –¢–ï–ö–£–©–ï–ï –°–û–°–¢–û–Ø–ù–ò–ï _run_task (app/api/v1/routes.py)
--------------------------------------------------------------------------------

async def _run_task(task_id, task_type, query, debug=True):
    1. –ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç request_id
    2. –ü—Ä–æ–≤–µ—Ä—è–µ—Ç profanity
    3. –ù–æ—Ä–º–∞–ª–∏–∑—É–µ—Ç query —á–µ—Ä–µ–∑ glossary
    4. –õ–æ–≥–∏—Ä—É–µ—Ç event "query"
    5. –ó–∞–≥—Ä—É–∂–∞–µ—Ç TaskConfig —á–µ—Ä–µ–∑ task_registry
    6. –ü—Ä–æ–≤–µ—Ä—è–µ—Ç —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ task_type
    7. –ü—Ä–æ–≤–µ—Ä—è–µ—Ç access —á–µ—Ä–µ–∑ check_task_access
    
    –î–õ–Ø task_type == "demo":
        8. retrieve_text_chunks() ‚Äî —Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–∏–π –ø–æ–∏—Å–∫
        9. –õ–æ–≥–∏—Ä—É–µ—Ç event "search"
        10. –ï—Å–ª–∏ env == "test": –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Ç–æ–ª—å–∫–æ —á–∞–Ω–∫–∏ –±–µ–∑ LLM
        11. build_llm_prompt() + call_llm()
        12. –ï—Å–ª–∏ enable_research: –≤—Ç–æ—Ä–∞—è –ø–æ–ø—ã—Ç–∫–∞ —Å —Ä–∞—Å—à–∏—Ä–µ–Ω–Ω—ã–º –∫–æ–Ω—Ç–µ–∫—Å—Ç–æ–º
        13. –ï—Å–ª–∏ postprocessing_type: save_markdown/save_docx
        14. –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç {ok, answer, meta}
    
    –î–õ–Ø task_type == "corporate":
        ‚Üí –ó–ê–ì–õ–£–®–ö–ê: "—Ñ—É–Ω–∫—Ü–∏–æ–Ω–∞–ª—å–Ω–æ—Å—Ç—å –≤ —Ä–∞–∑—Ä–∞–±–æ—Ç–∫–µ"
        (–Ω—É–∂–Ω–æ –∑–∞–º–µ–Ω–∏—Ç—å –Ω–∞ —Ç–æ—Ç –∂–µ RAG-–ø—Ä–æ—Ü–µ—Å—Å)

--------------------------------------------------------------------------------
## –ß–¢–û –ù–£–ñ–ù–û –°–î–ï–õ–ê–¢–¨ (ROADMAP)
--------------------------------------------------------------------------------

### –ü–†–ò–û–†–ò–¢–ï–¢ 1: –£–ù–ò–§–ò–ö–ê–¶–ò–Ø RAG –î–õ–Ø –í–°–ï–• –ó–ê–î–ê–ß (NO-CODE ADDING)

**–¶–µ–ª—å**: –õ—é–±–∞—è –∑–∞–¥–∞—á–∞ (demo –∏–ª–∏ corporate) –¥–æ–±–∞–≤–ª—è–µ—Ç—Å—è —Ç–æ–ª—å–∫–æ —á–µ—Ä–µ–∑ YAML,
–±–µ–∑ –ø—Ä–∞–≤–æ–∫ Python-–∫–æ–¥–∞.

**–®–∞–≥–∏**:

1. –£–±—Ä–∞—Ç—å –∑–∞–≥–ª—É—à–∫—É –¥–ª—è corporate –≤ _run_task:
   - corporate –¥–æ–ª–∂–µ–Ω –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å —Ç–æ—Ç –∂–µ RAG-–ø—Ä–æ—Ü–µ—Å—Å, —á—Ç–æ –∏ demo
   - –æ—Ç–ª–∏—á–∏—è —Ç–æ–ª—å–∫–æ –≤ access_control –∏ –∞—É–¥–∏—Ç–µ

2. –°–¥–µ–ª–∞—Ç—å RAG-–ø—Ä–æ—Ü–µ—Å—Å –ø–æ–ª–Ω–æ—Å—Ç—å—é —É–ø—Ä–∞–≤–ª—è–µ–º—ã–º —á–µ—Ä–µ–∑ TaskConfig:
   - sources_mode –æ–ø—Ä–µ–¥–µ–ª—è–µ—Ç, –∫–∞–∫–∏–µ retrieval –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å
   - text_search/table_search –±–ª–æ–∫–∏ –æ–ø—Ä–µ–¥–µ–ª—è—é—Ç –ø–∞—Ä–∞–º–µ—Ç—Ä—ã
   - –ù–ï –¥–æ–ª–∂–Ω–æ –±—ã—Ç—å if task_id == "employee_data" –≤ –∫–æ–¥–µ

3. –§–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞—Ç—å –±–ª–æ–∫ sources –≤ TaskConfig:
   ```yaml
   sources:
     text:
       enabled: true
       collection: "{task_id}_text"  # –∏–ª–∏ —è–≤–Ω–æ–µ –∏–º—è
       files: ["config/docs/..."]    # –¥–ª—è ingestion
     tables:
       enabled: true
       table_name: "employees"
       collection: "{task_id}_rows"
Ingestion –¥–æ–ª–∂–µ–Ω —á–∏—Ç–∞—Ç—å TaskConfig –∏ –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏:

—Å–æ–∑–¥–∞–≤–∞—Ç—å –Ω—É–∂–Ω—ã–µ Chroma-–∫–æ–ª–ª–µ–∫—Ü–∏–∏

–∏–Ω–¥–µ–∫—Å–∏—Ä–æ–≤–∞—Ç—å —É–∫–∞–∑–∞–Ω–Ω—ã–µ —Ñ–∞–π–ª—ã/—Ç–∞–±–ª–∏—Ü—ã

–ü–†–ò–û–†–ò–¢–ï–¢ 2: –ü–û–õ–ù–û–¶–ï–ù–ù–´–ô employee_data
–¢–µ–∫—É—â–µ–µ —Å–æ—Å—Ç–æ—è–Ω–∏–µ: employee_data –±—ã–ª corporate —Å–ø–µ—Ü–∫–µ–π—Å–æ–º, —Ç–µ–ø–µ—Ä—å –Ω—É–∂–Ω–æ
—Å–¥–µ–ª–∞—Ç—å –µ–≥–æ –æ–±—ã—á–Ω–æ–π demo-–∑–∞–¥–∞—á–µ–π —Å —Ç–∞–±–ª–∏—á–Ω—ã–º RAG.

–®–∞–≥–∏:

–°–æ–∑–¥–∞—Ç—å/–æ–±–Ω–æ–≤–∏—Ç—å config/tasks/employee_data.yaml:

text
task_id: employee_data
name: Demo employee directory
description: –ü–æ–∏—Å–∫ —Å–æ—Ç—Ä—É–¥–Ω–∏–∫–æ–≤ –≤ –¥–µ–º–æ-—Ç–∞–±–ª–∏—Ü–µ
task_type: demo

sources_mode: tables
enable_text_search: false
enable_table_search: true
enable_research: false
postprocessing_type: docx-file

table_search:
  enabled: true
  embedding_model: technical-ru
  mode: topk
  topk: 5
  max_rows: 50
  similarity_threshold: 0.4
  chunker: rowtochunk

technical_prompt: |
  –¢—ã –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç –ø–æ —Å–ø—Ä–∞–≤–æ—á–Ω–∏–∫—É —Å–æ—Ç—Ä—É–¥–Ω–∏–∫–æ–≤.
  –û—Ç–≤–µ—á–∞–π —Ç–æ–ª—å–∫–æ –Ω–∞ –æ—Å–Ω–æ–≤–µ –¥–∞–Ω–Ω—ã—Ö –∏–∑ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞.
  –ù–µ –≤—ã–¥—É–º—ã–≤–∞–π –ª—é–¥–µ–π, –∫–æ—Ç–æ—Ä—ã—Ö –Ω–µ—Ç –≤ —Å–ø–∏—Å–∫–µ.
–ü—Ä–æ–≥–Ω–∞—Ç—å ingestion:

bash
python -m app.ingestion.employee_ingest
–≠—Ç–æ –¥–æ–ª–∂–Ω–æ: ensure_employee_table ‚Üí seed_demo_employees ‚Üí ingest –≤ Chroma

–í rag_pipeline.py / _run_task:

–µ—Å–ª–∏ sources_mode == "tables" –∏–ª–∏ enable_table_search:

–∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å search_table_semantic –≤–º–µ—Å—Ç–æ retrieve_text_chunks

build_llm_prompt –¥–æ–ª–∂–µ–Ω —É–º–µ—Ç—å —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞—Ç—å —Ç–∞–±–ª–∏—á–Ω—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã

–ü–†–ò–û–†–ò–¢–ï–¢ 3: TELEGRAM BOT ‚Äî –û–¢–ü–†–ê–í–ö–ê –§–ê–ô–õ–û–í
–¢–µ–∫—É—â–µ–µ —Å–æ—Å—Ç–æ—è–Ω–∏–µ: –±–æ—Ç –ø–æ–∫–∞–∑—ã–≤–∞–µ—Ç —Ç–æ–ª—å–∫–æ —Ç–µ–∫—Å—Ç answer,
–∏–≥–Ω–æ—Ä–∏—Ä—É–µ—Ç meta.postprocessing.

–®–∞–≥–∏:

–î–æ–±–∞–≤–∏—Ç—å —Ñ—É–Ω–∫—Ü–∏—é tg_send_document(chat_id, file_path)

–í handle_text_message –ø–æ—Å–ª–µ –ø–æ–ª—É—á–µ–Ω–∏—è –æ—Ç–≤–µ—Ç–∞:

–ø—Ä–æ–≤–µ—Ä–∏—Ç—å meta.postprocessing

–µ—Å–ª–∏ –µ—Å—Ç—å path ‚Äî –æ—Ç–ø—Ä–∞–≤–∏—Ç—å —Ñ–∞–π–ª —á–µ—Ä–µ–∑ sendDocument

–û–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ: –∫–æ–º–∞–Ω–¥–∞ /outputs ‚Äî —Å–ø–∏—Å–æ–∫ –ø–æ—Å–ª–µ–¥–Ω–∏—Ö —Ñ–∞–π–ª–æ–≤

–ü–†–ò–û–†–ò–¢–ï–¢ 4: –ê–í–¢–û–¢–ï–°–¢–´
–¢–µ—Å—Ç: employee_data –∫–∞–∫ demo + postprocessing_type=docx-file

–¢–µ—Å—Ç: meta.postprocessing —Å–æ–¥–µ—Ä–∂–∏—Ç path –ø–æ—Å–ª–µ –∑–∞–ø—Ä–æ—Å–∞

–¢–µ—Å—Ç: —Ñ–∞–π–ª —Ä–µ–∞–ª—å–Ω–æ —Å–æ–∑–¥–∞—ë—Ç—Å—è –≤ .data/outputs/

–¢–µ—Å—Ç: corporate –∑–∞–¥–∞—á–∞ —Å –ø–æ–ª–Ω—ã–º RAG (–∫–æ–≥–¥–∞ —É–±–µ—Ä—ë–º –∑–∞–≥–ª—É—à–∫—É)

–ü–†–ò–û–†–ò–¢–ï–¢ 5: INGESTION CLI/UI
CLI –∫–æ–º–∞–Ω–¥–∞: python -m app.cli.admin_cli ingest {task_id}

–ß–∏—Ç–∞–µ—Ç TaskConfig, –æ–ø—Ä–µ–¥–µ–ª—è–µ—Ç sources, –∑–∞–ø—É—Å–∫–∞–µ—Ç –Ω—É–∂–Ω—ã–π ingestion

–õ–æ–≥–∏—Ä—É–µ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç (—Å–∫–æ–ª—å–∫–æ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤/—Å—Ç—Ä–æ–∫ –ø—Ä–æ–∏–Ω–¥–µ–∫—Å–∏—Ä–æ–≤–∞–Ω–æ)

–ê–†–•–ò–¢–ï–ö–¢–£–†–ù–´–ï –ü–†–ò–ù–¶–ò–ü–´
NO-CODE TASK ADDING
–ù–æ–≤—ã–µ –∑–∞–¥–∞—á–∏ –¥–æ–±–∞–≤–ª—è—é—Ç—Å—è —Ç–æ–ª—å–∫–æ —á–µ—Ä–µ–∑ config/tasks/{task_id}.yaml.
–ö–æ–¥ _run_task —É–Ω–∏–≤–µ—Ä—Å–∞–ª–µ–Ω –∏ –Ω–µ –∑–Ω–∞–µ—Ç –ø—Ä–æ –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–µ task_id.

TASK_TYPE ‚Äî –¢–û–õ–¨–ö–û –ü–û–õ–ò–¢–ò–ö–ò

demo vs corporate –ù–ï –≤–ª–∏—è–µ—Ç –Ω–∞ RAG-–ª–æ–≥–∏–∫—É

–≤–ª–∏—è–µ—Ç —Ç–æ–ª—å–∫–æ –Ω–∞: access_control, –≤–∏–¥–∏–º–æ—Å—Ç—å –≤ prod, –∞—É–¥–∏—Ç

SOURCES_MODE + ENABLE_ = –ü–û–í–ï–î–ï–ù–ò–ï*

sources_mode: text ‚Üí —Ç–æ–ª—å–∫–æ —Ç–µ–∫—Å—Ç–æ–≤—ã–π RAG

sources_mode: tables ‚Üí —Ç–æ–ª—å–∫–æ —Ç–∞–±–ª–∏—á–Ω—ã–π RAG

sources_mode: texttables ‚Üí –æ–±–∞

enable_research ‚Üí –≤—Ç–æ—Ä–∞—è –ø–æ–ø—ã—Ç–∫–∞ —Å —Ä–∞—Å—à–∏—Ä–µ–Ω–Ω—ã–º –∫–æ–Ω—Ç–µ–∫—Å—Ç–æ–º

POSTPROCESSING –ö–ê–ö –û–ü–¶–ò–Ø

postprocessing_type: none ‚Äî —Ç–æ–ª—å–∫–æ —Ç–µ–∫—Å—Ç

postprocessing_type: markdown-file ‚Äî —Ç–µ–∫—Å—Ç + —Å–æ—Ö—Ä–∞–Ω–∏—Ç—å .md

postprocessing_type: docx-file ‚Äî —Ç–µ–∫—Å—Ç + —Å–æ—Ö—Ä–∞–Ω–∏—Ç—å .docx

–§–∞–π–ª—ã –í–°–ï–ì–î–ê —Å–æ—Ö—Ä–∞–Ω—è—é—Ç—Å—è –Ω–∞ —Å–µ—Ä–≤–µ—Ä–µ, –±–æ—Ç –º–æ–∂–µ—Ç –∏—Ö –æ—Ç–ø—Ä–∞–≤–ª—è—Ç—å

ENVIRONMENT = –†–ï–ñ–ò–ú –†–ê–ë–û–¢–´

dev: –≤—Å—ë —Ä–∞–±–æ—Ç–∞–µ—Ç, –º–æ–∂–Ω–æ —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–∏—Ä–æ–≤–∞—Ç—å

test: RAG —Ä–∞–±–æ—Ç–∞–µ—Ç, LLM –Ω–µ –≤—ã–∑—ã–≤–∞–µ—Ç—Å—è (–¥–ª—è –æ—Ç–ª–∞–¥–∫–∏ retrieval)

prod: —Ç–æ–ª—å–∫–æ corporate –∑–∞–¥–∞—á–∏, —Å—Ç—Ä–æ–≥–∏–π —Ä–µ–∂–∏–º


## FILE: README.md
# N3R7A2C7

**Version:** 0.3

## –û–ø–∏—Å–∞–Ω–∏–µ

–°–∏—Å—Ç–µ–º–∞ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è –∑–∞—è–≤–æ–∫ - –ø—Ä–æ—Ñ–µ—Å—Å–∏–æ–Ω–∞–ª—å–Ω—ã–π –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç –¥–ª—è —É–ø—Ä–∞–≤–ª–µ–Ω–∏—è –∏ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –∑–∞—è–≤–æ–∫.

## –í–æ–∑–º–æ–∂–Ω–æ—Å—Ç–∏

- –¶–µ–Ω—Ç—Ä–∞–ª–∏–∑–æ–≤–∞–Ω–Ω–æ–µ —Ö—Ä–∞–Ω–µ–Ω–∏–µ –∑–∞—è–≤–æ–∫
- –û—Ç—Å–ª–µ–∂–∏–≤–∞–Ω–∏–µ —Å—Ç–∞—Ç—É—Å–∞ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è
- –ê–≤—Ç–æ–º–∞—Ç–∏–∑–∞—Ü–∏—è —Ä–∞–±–æ—á–∏—Ö –ø—Ä–æ—Ü–µ—Å—Å–æ–≤
- –î–µ—Ç–∞–ª—å–Ω–∞—è –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—è –ø—Ä–æ–µ–∫—Ç–∞

## –°—Ç—Ä—É–∫—Ç—É—Ä–∞ –ø—Ä–æ–µ–∫—Ç–∞

```
N3R7A2C7/
‚îú‚îÄ‚îÄ README.md              # –û—Å–Ω–æ–≤–Ω–∞—è –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—è
‚îú‚îÄ‚îÄ CHANGELOG.md           # –ò—Å—Ç–æ—Ä–∏—è –∏–∑–º–µ–Ω–µ–Ω–∏–π
‚îú‚îÄ‚îÄ PROJECT_PLAN.md        # –ü–ª–∞–Ω —Ä–∞–∑—Ä–∞–±–æ—Ç–∫–∏
‚îú‚îÄ‚îÄ logs/                  # –õ–æ–≥–∏ —Å–∏—Å—Ç–µ–º—ã
‚îú‚îÄ‚îÄ docs/                  # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—è
‚îî‚îÄ‚îÄ src/                   # –ò—Å—Ö–æ–¥–Ω—ã–π –∫–æ–¥
```

## –¢–µ—Ö–Ω–æ–ª–æ–≥–∏–∏

- –°–∏—Å—Ç–µ–º–∞ –∫–æ–Ω—Ç—Ä–æ–ª—è –≤–µ—Ä—Å–∏–π: Git/GitHub
- –î–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—è: Markdown
- –ú–æ–¥—É–ª—å–Ω–∞—è –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞

## –°—Ç–∞—Ç—É—Å

üîß –í —Ä–∞–∑—Ä–∞–±–æ—Ç–∫–µ - –≤–µ—Ä—Å–∏—è 0.3

---
*–ü—Ä–æ–µ–∫—Ç –Ω–∞—Ö–æ–¥–∏—Ç—Å—è –≤ –∞–∫—Ç–∏–≤–Ω–æ–π —Ä–∞–∑—Ä–∞–±–æ—Ç–∫–µ. –î–µ—Ç–∞–ª—å–Ω—ã–π –ø–ª–∞–Ω —Å–º. –≤ PROJECT_PLAN.md*

## FILE: app/api/v1/__init__.py


## FILE: app/api/v1/routes.py
from typing import Optional, List, Literal, Any, Dict
import time
import uuid

from fastapi import APIRouter, HTTPException
from pydantic import BaseModel, Field

from app.core.task_registry import task_registry, TaskRegistryError
from app.core.access_control import check_task_access
from app.core.rag_pipeline import (
    retrieve_text_chunks,
    retrieve_text_chunks_for_research,
    build_llm_prompt,
)
from app.core.event_logger import log_event
from app.core.glossary import normalize_query
from app.core.profanity_filter import check_profanity
from app.core.config_loader import get_environment
from llm_connectors.connector_dev import call_llm, LLMError
from app.core.task_classifier import classify_query
from app.postprocessing.files import save_markdown, save_docx


router = APIRouter(prefix="/api/v1", tags=["tasks"])


class TaskQueryRequest(BaseModel):
    task_id: str = Field(..., description="–ò–¥–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ç–æ—Ä –∑–∞–¥–∞—á–∏, –Ω–∞–ø—Ä–∏–º–µ—Ä demo_hello")
    task_type: Literal["demo", "corporate"] = Field(
        "demo",
        description="–¢–∏–ø –∑–∞–¥–∞—á–∏: demo –∏–ª–∏ corporate (–¥–æ–ª–∂–µ–Ω —Å–æ–≤–ø–∞–¥–∞—Ç—å —Å TaskConfig)",
    )
    query: str = Field(..., description="–¢–µ–∫—Å—Ç –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å—Å–∫–æ–≥–æ –∑–∞–ø—Ä–æ—Å–∞")
    debug: bool = Field(
        True,
        description="–ï—Å–ª–∏ true, –≤ –æ—Ç–≤–µ—Ç –¥–æ–±–∞–≤–ª—è–µ—Ç—Å—è –æ—Ç–ª–∞–¥–æ—á–Ω–∞—è meta-–∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è",
    )


class TaskQueryResponse(BaseModel):
    ok: bool
    answer: Optional[str] = None
    error: Optional[str] = None
    meta: Optional[Dict[str, Any]] = None


class TaskInfo(BaseModel):
    task_id: str
    task_type: str
    name: str
    description: str


class GenericQueryRequest(BaseModel):
    query: str = Field(..., description="–¢–µ–∫—Å—Ç –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å—Å–∫–æ–≥–æ –∑–∞–ø—Ä–æ—Å–∞")
    debug: bool = Field(False, description="–í–æ–∑–≤—Ä–∞—â–∞—Ç—å —Å–ª—É–∂–µ–±–Ω—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é")


class GenericQueryResponse(BaseModel):
    ok: bool
    answer: Optional[str] = None
    routed_task_id: Optional[str] = None
    routed_task_type: Optional[str] = None
    error: Optional[str] = None
    classification_confidence: Optional[float] = None


async def _run_task(task_id: str, task_type: str, query: str, debug: bool = True) -> TaskQueryResponse:
    from app.core.task_config import TaskConfig

    request_id = str(uuid.uuid4())
    env = get_environment()

    prof = check_profanity(query)
    profanity_flag = prof.detected

    normalized_query = normalize_query(query)

    log_event(
        event_type="query",
        request_id=request_id,
        task_id=task_id,
        task_type=task_type,
        payload={
            "query": query,
            "normalized_query": normalized_query,
            "profanity_detected": profanity_flag,
            "profanity_matches": prof.matches,
        },
    )

    try:
        task_cfg: TaskConfig = task_registry.get_task_config(task_id)
    except TaskRegistryError as e:
        log_event(
            event_type="query_error",
            request_id=request_id,
            task_id=task_id,
            task_type=task_type,
            payload={"error": str(e)},
        )
        raise HTTPException(status_code=404, detail=str(e))

    if task_cfg.task_type != task_type:
        detail = (
            f"Request task_type={task_type} does not match "
            f"TaskConfig.task_type={task_cfg.task_type}"
        )
        log_event(
            event_type="query_error",
            request_id=request_id,
            task_id=task_id,
            task_type=task_type,
            payload={"error": detail},
        )
        raise HTTPException(status_code=400, detail=detail)

    decision = check_task_access(task_cfg)
    if not decision.allowed:
        log_event(
            event_type="access_denied",
            request_id=request_id,
            task_id=task_id,
            task_type=task_type,
            payload={"reason": decision.reason},
        )
        raise HTTPException(status_code=403, detail=decision.reason)

    meta: Dict[str, Any] = {}

    # ========== DEMO-–∑–∞–¥–∞—á–∏: –æ–±—â–∏–π RAG-–ø—É—Ç—å ==========
    if task_cfg.task_type == "demo":
        t0 = time.time()
        chunks = retrieve_text_chunks(task_cfg, normalized_query, top_k=3)
        t1 = time.time()

        log_event(
            event_type="search",
            request_id=request_id,
            task_id=task_id,
            task_type=task_type,
            payload={
                "duration_ms": int((t1 - t0) * 1000),
                "chunks_found": len(chunks),
            },
        )

        # TEST MODE: —Ç–æ–ª—å–∫–æ retrieval –±–µ–∑ LLM
        if env == "test":
            meta["retrieved_chunks"] = [
                {
                    "text": ch.text,
                    "source_id": ch.source_id,
                    "score": ch.score,
                }
                for ch in chunks
            ]

            log_event(
                event_type="final",
                request_id=request_id,
                task_id=task_id,
                task_type=task_type,
                payload={
                    "ok": True,
                    "answer_length": 0,
                    "mode": "test_no_llm",
                },
            )

            return TaskQueryResponse(
                ok=True,
                answer="TEST MODE: LLM –Ω–µ –≤—ã–∑—ã–≤–∞–ª—Å—è, –≤–æ–∑–≤—Ä–∞—â–µ–Ω—ã —Ç–æ–ª—å–∫–æ –Ω–∞–π–¥–µ–Ω–Ω—ã–µ —á–∞–Ω–∫–∏.",
                meta=meta,
            )

        if debug:
            meta["retrieved_chunks"] = [
                {
                    "text": ch.text,
                    "source_id": ch.source_id,
                    "score": ch.score,
                }
                for ch in chunks
            ]

        system_prompt = build_llm_prompt(task_cfg, normalized_query, chunks)

        messages = [
            {"role": "system", "content": system_prompt},
            {"role": "user", "content": query},
        ]
        try:
            # –ø–µ—Ä–≤–∞—è –ø–æ–ø—ã—Ç–∫–∞ LLM
            t_llm0 = time.time()
            resp = await call_llm(messages, model="llama3.2:1b")
            t_llm1 = time.time()
            answer = resp["choices"][0]["message"]["content"]

            log_event(
                event_type="llm",
                request_id=request_id,
                task_id=task_id,
                task_type=task_type,
                payload={
                    "duration_ms": int((t_llm1 - t_llm0) * 1000),
                    "ok": True,
                    "profanity_detected": profanity_flag,
                    "attempt": 1,
                },
            )

            # –ª—ë–≥–∫–∏–π research: –≤—Ç–æ—Ä–∞—è –ø–æ–ø—ã—Ç–∫–∞ —Å —Ä–∞—Å—à–∏—Ä–µ–Ω–Ω—ã–º –∫–æ–Ω—Ç–µ–∫—Å—Ç–æ–º (–µ—Å–ª–∏ –≤–∫–ª—é—á–µ–Ω)
            if task_cfg.enable_research:
                t_r0 = time.time()
                research_chunks = retrieve_text_chunks_for_research(task_cfg, normalized_query)
                t_r1 = time.time()

                log_event(
                    event_type="research_search",
                    request_id=request_id,
                    task_id=task_id,
                    task_type=task_type,
                    payload={
                        "duration_ms": int((t_r1 - t_r0) * 1000),
                        "chunks_found": len(research_chunks),
                    },
                )

                if debug:
                    meta["research_chunks"] = [
                        {
                            "text": ch.text,
                            "source_id": ch.source_id,
                            "score": ch.score,
                        }
                        for ch in research_chunks
                    ]

                research_prompt = (
                    build_llm_prompt(task_cfg, normalized_query, research_chunks)
                    + "\n\n–≠—Ç–æ –≤—Ç–æ—Ä–∞—è –ø–æ–ø—ã—Ç–∫–∞ –æ—Ç–≤–µ—Ç–∞ —Å —Ä–∞—Å—à–∏—Ä–µ–Ω–Ω—ã–º –∫–æ–Ω—Ç–µ–∫—Å—Ç–æ–º. "
                      "–ï—Å–ª–∏ –≤ –Ω–æ–≤–æ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç–µ –µ—Å—Ç—å —É—Ç–æ—á–Ω—è—é—â–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è, —É—á—Ç–∏ –µ—ë."
                )
                research_messages = [
                    {"role": "system", "content": research_prompt},
                    {"role": "user", "content": query},
                ]

                t_llm2_0 = time.time()
                resp2 = await call_llm(research_messages, model="llama3.2:1b")
                t_llm2_1 = time.time()
                answer2 = resp2["choices"][0]["message"]["content"]

                log_event(
                    event_type="llm",
                    request_id=request_id,
                    task_id=task_id,
                    task_type=task_type,
                    payload={
                        "duration_ms": int((t_llm2_1 - t_llm2_0) * 1000),
                        "ok": True,
                        "profanity_detected": profanity_flag,
                        "attempt": 2,
                    },
                )

                answer = answer2

            # –ø–æ—Å—Ç–æ–±—Ä–∞–±–æ—Ç–∫–∞ –≤ —Ñ–∞–π–ª
            if task_cfg.postprocessing_type == "markdown-file":
                abs_path, fname = save_markdown(answer, task_cfg)
                meta["postprocessing"] = {
                    "type": "markdown-file",
                    "path": abs_path,
                    "filename": fname,
                }
            elif task_cfg.postprocessing_type == "docx-file":
                abs_path, fname = save_docx(answer, task_cfg)
                meta["postprocessing"] = {
                    "type": "docx-file",
                    "path": abs_path,
                    "filename": fname,
                }

            log_event(
                event_type="final",
                request_id=request_id,
                task_id=task_id,
                task_type=task_type,
                payload={
                    "ok": True,
                    "answer_length": len(answer) if isinstance(answer, str) else None,
                },
            )

            return TaskQueryResponse(ok=True, answer=answer, meta=meta or None)
        except LLMError as e:
            log_event(
                event_type="llm_error",
                request_id=request_id,
                task_id=task_id,
                task_type=task_type,
                payload={"error": str(e), "profanity_detected": profanity_flag},
            )
            log_event(
                event_type="final",
                request_id=request_id,
                task_id=task_id,
                task_type=task_type,
                payload={"ok": False, "error": str(e)},
            )
            return TaskQueryResponse(ok=False, error=str(e), meta=meta or None)

    # ===== –õ—é–±—ã–µ corporate-–∑–∞–¥–∞—á–∏ (–æ–±—â–∞—è –∑–∞–≥–ª—É—à–∫–∞) =====
    if task_cfg.task_type == "corporate":
        # –í test-–æ–∫—Ä—É–∂–µ–Ω–∏–∏ –Ω–µ –≤—ã–∑—ã–≤–∞–µ–º LLM
        if env == "test":
            log_event(
                event_type="final",
                request_id=request_id,
                task_id=task_id,
                task_type=task_type,
                payload={"ok": True, "answer_length": 0, "mode": "test_no_llm"},
            )
            return TaskQueryResponse(
                ok=True,
                answer="TEST MODE: LLM –Ω–µ –≤—ã–∑—ã–≤–∞–ª—Å—è, corporate-–∑–∞–¥–∞—á–∞ –µ—â—ë –Ω–µ —Ä–µ–∞–ª–∏–∑–æ–≤–∞–Ω–∞.",
                meta=meta or None,
            )

        system_prompt = (
            "–¢—ã –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç –∫–æ—Ä–ø–æ—Ä–∞—Ç–∏–≤–Ω–æ–π —Å–∏—Å—Ç–µ–º—ã –∑–∞—è–≤–æ–∫. "
            "–ü–æ–∫–∞ –¥–ª—è —ç—Ç–æ–π corporate-–∑–∞–¥–∞—á–∏ –Ω–µ—Ç —Å–ø–µ—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–æ–≥–æ RAG-–ø–∞–π–ø–ª–∞–π–Ω–∞, "
            "–æ—Ç–≤–µ—Ç—å –∞–∫–∫—É—Ä–∞—Ç–Ω–æ, —á—Ç–æ —Ñ—É–Ω–∫—Ü–∏–æ–Ω–∞–ª—å–Ω–æ—Å—Ç—å –≤ —Ä–∞–∑—Ä–∞–±–æ—Ç–∫–µ."
        )
        messages = [
            {"role": "system", "content": system_prompt},
            {"role": "user", "content": query},
        ]
        try:
            t_llm0 = time.time()
            resp = await call_llm(messages, model="llama3.2:1b")
            t_llm1 = time.time()
            answer = resp["choices"][0]["message"]["content"]

            if task_cfg.postprocessing_type == "markdown-file":
                abs_path, fname = save_markdown(answer, task_cfg)
                meta["postprocessing"] = {
                    "type": "markdown-file",
                    "path": abs_path,
                    "filename": fname,
                }
            elif task_cfg.postprocessing_type == "docx-file":
                abs_path, fname = save_docx(answer, task_cfg)
                meta["postprocessing"] = {
                    "type": "docx-file",
                    "path": abs_path,
                    "filename": fname,
                }

            log_event(
                event_type="llm",
                request_id=request_id,
                task_id=task_id,
                task_type=task_type,
                payload={
                    "duration_ms": int((t_llm1 - t_llm0) * 1000),
                    "ok": True,
                },
            )
            log_event(
                event_type="final",
                request_id=request_id,
                task_id=task_id,
                task_type=task_type,
                payload={
                    "ok": True,
                    "answer_length": len(answer) if isinstance(answer, str) else None,
                },
            )
            return TaskQueryResponse(ok=True, answer=answer, meta=meta or None)
        except LLMError as e:
            log_event(
                event_type="llm_error",
                request_id=request_id,
                task_id=task_id,
                task_type=task_type,
                payload={"error": str(e)},
            )
            log_event(
                event_type="final",
                request_id=request_id,
                task_id=task_id,
                task_type=task_type,
                payload={"ok": False, "error": str(e)},
            )
            return TaskQueryResponse(ok=False, error=str(e), meta=meta or None)

    raise HTTPException(status_code=400, detail="Unsupported task_type")


@router.get("/tasks", response_model=List[TaskInfo])
async def list_tasks() -> List[TaskInfo]:
    env = get_environment()
    tasks = task_registry.list_registered_tasks()
    visible: List[TaskInfo] = []

    for t in tasks:
        if env == "prod" and t.task_type == "demo":
            continue
        visible.append(
            TaskInfo(
                task_id=t.task_id,
                task_type=t.task_type,
                name=t.name,
                description=t.description,
            )
        )

    return visible


@router.get("/tasks/{task_id}", response_model=TaskInfo)
async def get_task(task_id: str) -> TaskInfo:
    env = get_environment()
    try:
        cfg = task_registry.get_task_config(task_id)
    except TaskRegistryError as e:
        raise HTTPException(status_code=404, detail=str(e))

    if env == "prod" and cfg.task_type == "demo":
        raise HTTPException(
            status_code=404,
            detail="Task not found",
        )

    return TaskInfo(
        task_id=cfg.task_id,
        task_type=cfg.task_type,
        name=cfg.name,
        description=cfg.description,
    )


@router.post("/task/query", response_model=TaskQueryResponse)
async def task_query(request: TaskQueryRequest) -> TaskQueryResponse:
    return await _run_task(
        task_id=request.task_id,
        task_type=request.task_type,
        query=request.query,
        debug=request.debug,
    )


@router.post("/query", response_model=GenericQueryResponse)
async def generic_query(request: GenericQueryRequest) -> GenericQueryResponse:
    request_id = str(uuid.uuid4())
    env = get_environment()

    classification = await classify_query(
        query=request.query,
        request_id=request_id,
        debug=request.debug,
    )

    if not classification.ok or not classification.task_id or not classification.task_type:
        return GenericQueryResponse(
            ok=False,
            error=classification.error or "classification_failed",
            classification_confidence=classification.confidence,
        )

    if env == "prod" and classification.task_type == "demo":
        return GenericQueryResponse(
            ok=False,
            error="demo tasks are not available in prod environment",
            routed_task_id=None,
            routed_task_type=None,
            classification_confidence=classification.confidence,
        )

    try:
        task_registry.get_task_config(classification.task_id)
    except TaskRegistryError as e:
        return GenericQueryResponse(
            ok=False,
            error=str(e),
            routed_task_id=classification.task_id,
            routed_task_type=classification.task_type,
            classification_confidence=classification.confidence,
        )

    task_resp = await _run_task(
        task_id=classification.task_id,
        task_type=classification.task_type,
        query=request.query,
        debug=request.debug,
    )

    return GenericQueryResponse(
        ok=task_resp.ok,
        answer=task_resp.answer,
        routed_task_id=classification.task_id,
        routed_task_type=classification.task_type,
        error=task_resp.error,
        classification_confidence=classification.confidence,
    )

## FILE: app/bot/telegram_bot.py
import os
import asyncio
import httpx
from typing import Optional
from dotenv import load_dotenv

load_dotenv()

TELEGRAM_TOKEN = os.getenv("TELEGRAM_BOT_TOKEN")
API_BASE_URL = os.getenv("API_BASE_URL", "http://127.0.0.1:8000")

if not TELEGRAM_TOKEN:
    raise ValueError("TELEGRAM_BOT_TOKEN –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω")

TG_API_URL = f"https://api.telegram.org/bot{TELEGRAM_TOKEN}"


async def tg_send_message(chat_id: int, text: str, reply_markup: Optional[dict] = None):
    async with httpx.AsyncClient(timeout=30) as client:
        payload = {"chat_id": chat_id, "text": text, "parse_mode": "Markdown"}
        if reply_markup:
            payload["reply_markup"] = reply_markup
        resp = await client.post(f"{TG_API_URL}/sendMessage", json=payload)
        resp.raise_for_status()


async def tg_send_document(chat_id: int, file_path: str, caption: Optional[str] = None):
    """–û—Ç–ø—Ä–∞–≤–ª—è–µ—Ç —Ñ–∞–π–ª –¥–æ–∫—É–º–µ–Ω—Ç–∞ –≤ —á–∞—Ç"""
    async with httpx.AsyncClient(timeout=60) as client:
        with open(file_path, "rb") as f:
            files = {"document": f}
            data = {"chat_id": chat_id}
            if caption:
                data["caption"] = caption
            resp = await client.post(f"{TG_API_URL}/sendDocument", files=files, data=data)
            resp.raise_for_status()


async def rag_task_query(chat_id: int, task_id: str, task_type: str, query: str):
    async with httpx.AsyncClient(timeout=120) as client:
        payload = {"task_id": task_id, "task_type": task_type, "query": query, "debug": True}
        try:
            resp = await client.post(f"{API_BASE_URL}/api/v1/task/query", json=payload)
            resp.raise_for_status()
            data = resp.json()

            if data.get("ok"):
                answer = data.get("answer") or "–û—Ç–≤–µ—Ç –ø—É—Å—Ç"
                meta = data.get("meta") or {}

                await tg_send_message(chat_id, answer)

                # –µ—Å–ª–∏ –µ—Å—Ç—å —Ñ–∞–π–ª –≤ –ø–æ—Å—Ç–æ–±—Ä–∞–±–æ—Ç–∫–µ ‚Äî –æ—Ç–ø—Ä–∞–≤–ª—è–µ–º
                pp = meta.get("postprocessing")
                if pp and pp.get("path"):
                    file_path = pp["path"]
                    filename = pp.get("filename") or file_path.split("/")[-1]
                    await tg_send_document(
                        chat_id,
                        file_path,
                        caption=f"üìÑ –†–µ–∑—É–ª—å—Ç–∞—Ç —Å–æ—Ö—Ä–∞–Ω—ë–Ω: {filename}"
                    )

                if meta.get("retrieved_chunks"):
                    chunks_info = f"üìö –ù–∞–π–¥–µ–Ω–æ —á–∞–Ω–∫–æ–≤: {len(meta['retrieved_chunks'])}"
                    await tg_send_message(chat_id, chunks_info)

                if meta.get("research_chunks"):
                    research_info = f"üîç Research: –Ω–∞–π–¥–µ–Ω–æ –¥–æ–ø. {len(meta['research_chunks'])} —á–∞–Ω–∫–æ–≤"
                    await tg_send_message(chat_id, research_info)

                if meta.get("table_rows"):
                    rows_info = f"üìä –ù–∞–π–¥–µ–Ω–æ —Å—Ç—Ä–æ–∫ –≤ —Ç–∞–±–ª–∏—Ü–µ: {len(meta['table_rows'])}"
                    await tg_send_message(chat_id, rows_info)
            else:
                error = data.get("error") or "–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–∞—è –æ—à–∏–±–∫–∞"
                await tg_send_message(chat_id, f"‚ùå –û—à–∏–±–∫–∞: {error}")

        except Exception as e:
            await tg_send_message(chat_id, f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–ø—Ä–æ—Å–µ –∫ API: {str(e)}")


async def rag_generic_query(chat_id: int, query: str):
    async with httpx.AsyncClient(timeout=120) as client:
        payload = {"query": query, "debug": True}
        try:
            resp = await client.post(f"{API_BASE_URL}/api/v1/query", json=payload)
            resp.raise_for_status()
            data = resp.json()

            if data.get("ok"):
                answer = data.get("answer") or "–û—Ç–≤–µ—Ç –ø—É—Å—Ç"
                routed = data.get("routed_task_id")
                confidence = data.get("classification_confidence")

                info = f"üéØ –ó–∞–¥–∞—á–∞: {routed} (—É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å: {confidence:.2f})\n\n{answer}"
                await tg_send_message(chat_id, info)

                # –µ—Å–ª–∏ –µ—Å—Ç—å —Ñ–∞–π–ª ‚Äî –æ—Ç–ø—Ä–∞–≤–ª—è–µ–º
                meta = data.get("meta") or {}
                pp = meta.get("postprocessing")
                if pp and pp.get("path"):
                    file_path = pp["path"]
                    filename = pp.get("filename") or file_path.split("/")[-1]
                    await tg_send_document(
                        chat_id,
                        file_path,
                        caption=f"üìÑ –†–µ–∑—É–ª—å—Ç–∞—Ç —Å–æ—Ö—Ä–∞–Ω—ë–Ω: {filename}"
                    )

            else:
                error = data.get("error") or "–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–∞—è –æ—à–∏–±–∫–∞"
                await tg_send_message(chat_id, f"‚ùå –û—à–∏–±–∫–∞: {error}")

        except Exception as e:
            await tg_send_message(chat_id, f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–ø—Ä–æ—Å–µ –∫ API: {str(e)}")


async def handle_update(update: dict):
    message = update.get("message")
    if not message:
        return

    chat_id = message["chat"]["id"]
    text = message.get("text", "")

    if text == "/start":
        async with httpx.AsyncClient(timeout=30) as client:
            try:
                resp = await client.get(f"{API_BASE_URL}/api/v1/health")
                health = resp.json()
                env = health.get("environment", "unknown")
                llm_mode = health.get("llm_mode", "unknown")
                status = f"‚úÖ –°–∏—Å—Ç–µ–º–∞ —Ä–∞–±–æ—Ç–∞–µ—Ç\n–û–∫—Ä—É–∂–µ–Ω–∏–µ: {env}\nLLM: {llm_mode}"
            except Exception as e:
                status = f"‚ùå API –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω: {str(e)}"

        keyboard = {
            "keyboard": [
                [{"text": "üìã Tasks"}],
                [{"text": "üí¨ –°–ø—Ä–æ—Å–∏ —á—Ç–æ-–Ω–∏–±—É–¥—å"}],
            ],
            "resize_keyboard": True,
        }
        await tg_send_message(chat_id, f"{status}\n\n–í—ã–±–µ—Ä–∏ –¥–µ–π—Å—Ç–≤–∏–µ:", reply_markup=keyboard)
        return

    if text == "üìã Tasks":
        async with httpx.AsyncClient(timeout=30) as client:
            try:
                resp = await client.get(f"{API_BASE_URL}/api/v1/tasks")
                tasks = resp.json()
                if tasks:
                    lines = ["–î–æ—Å—Ç—É–ø–Ω—ã–µ –∑–∞–¥–∞—á–∏:"]
                    for t in tasks:
                        lines.append(f"‚Ä¢ {t['task_id']} ({t['task_type']}): {t['name']}")
                    await tg_send_message(chat_id, "\n".join(lines))
                else:
                    await tg_send_message(chat_id, "–ù–µ—Ç –¥–æ—Å—Ç—É–ø–Ω—ã—Ö –∑–∞–¥–∞—á")
            except Exception as e:
                await tg_send_message(chat_id, f"‚ùå –û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è –∑–∞–¥–∞—á: {str(e)}")
        return

    if text.startswith("/task "):
        parts = text.split(maxsplit=2)
        if len(parts) < 3:
            await tg_send_message(chat_id, "–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ: /task <task_id> <–≤–æ–ø—Ä–æ—Å>")
            return

        task_id = parts[1]
        query = parts[2]

        async with httpx.AsyncClient(timeout=30) as client:
            try:
                resp = await client.get(f"{API_BASE_URL}/api/v1/tasks/{task_id}")
                task_info = resp.json()
                task_type = task_info["task_type"]
            except Exception as e:
                await tg_send_message(chat_id, f"‚ùå –ó–∞–¥–∞—á–∞ –Ω–µ –Ω–∞–π–¥–µ–Ω–∞: {str(e)}")
                return

        await tg_send_message(chat_id, f"‚è≥ –û–±—Ä–∞–±–∞—Ç—ã–≤–∞—é –∑–∞–ø—Ä–æ—Å –∫ –∑–∞–¥–∞—á–µ {task_id}...")
        await rag_task_query(chat_id, task_id, task_type, query)
        return

    if text == "üí¨ –°–ø—Ä–æ—Å–∏ —á—Ç–æ-–Ω–∏–±—É–¥—å" or text.startswith("?"):
        await tg_send_message(
            chat_id,
            "–ü—Ä–æ—Å—Ç–æ –Ω–∞–ø–∏—à–∏ —Å–≤–æ–π –≤–æ–ø—Ä–æ—Å, –∏ —è –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –æ–ø—Ä–µ–¥–µ–ª—é –ø–æ–¥—Ö–æ–¥—è—â—É—é –∑–∞–¥–∞—á—É."
        )
        return

    await tg_send_message(chat_id, "‚è≥ –û–±—Ä–∞–±–∞—Ç—ã–≤–∞—é –∑–∞–ø—Ä–æ—Å...")
    await rag_generic_query(chat_id, text)


async def get_updates(offset: int = 0):
    async with httpx.AsyncClient(timeout=30) as client:
        resp = await client.get(f"{TG_API_URL}/getUpdates", params={"offset": offset, "timeout": 25})
        resp.raise_for_status()
        return resp.json()


async def main():
    print("ü§ñ Telegram-–±–æ—Ç –∑–∞–ø—É—â–µ–Ω, —Å–ª—É—à–∞—é –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è...")
    offset = 0

    while True:
        try:
            data = await get_updates(offset)
            updates = data.get("result", [])

            for upd in updates:
                offset = upd["update_id"] + 1
                await handle_update(upd)

        except KeyboardInterrupt:
            print("\nüõë –ë–æ—Ç –æ—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω")
            break
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –≤ main loop: {e}")
            await asyncio.sleep(3)


if __name__ == "__main__":
    asyncio.run(main())

## FILE: app/cli/admin_cli.py
import sys
from pathlib import Path
from typing import List

import click

PROJECT_ROOT = Path(__file__).parent.parent.parent.resolve()
if str(PROJECT_ROOT) not in sys.path:
    sys.path.insert(0, str(PROJECT_ROOT))

from app.core.task_registry import task_registry, TaskRegistryError  # noqa: E402
from app.core.task_config import TaskConfigError  # noqa: E402
from app.core.config_loader import get_environment  # noqa: E402


@click.group()
def cli() -> None:
    """
    –ê–¥–º–∏–Ω-CLI –¥–ª—è RAG-—Å–µ—Ä–≤–∏—Å–∞ n3r7.
    –ü–æ–∑–≤–æ–ª—è–µ—Ç —Å–º–æ—Ç—Ä–µ—Ç—å –æ–∫—Ä—É–∂–µ–Ω–∏–µ, —Å–ø–∏—Å–æ–∫ –∑–∞–¥–∞—á –∏ –ø–æ–¥—Ä–æ–±–Ω—ã–π –∫–æ–Ω—Ñ–∏–≥ –∑–∞–¥–∞—á–∏.
    """
    pass


@cli.command("env")
def show_env() -> None:
    env = get_environment()
    click.echo(f"Environment: {env}")


@cli.command("tasks-loaded")
def tasks_loaded() -> None:
    tasks = task_registry.list_registered_tasks()
    if not tasks:
        click.echo("No tasks loaded in registry yet.")
        return

    click.echo("Loaded tasks:")
    for t in tasks:
        click.echo(f"- {t.task_id} [{t.task_type}] {t.name}")


@cli.command("tasks-list")
def tasks_list() -> None:
    """
    –ö—Ä–∞—Å–∏–≤—ã–π —Å–ø–∏—Å–æ–∫ –∑–∞–¥–∞—á —Å —Ç–∏–ø–æ–º –∏ —Ä–µ–∂–∏–º–æ–º sources_mode.
    """
    tasks = task_registry.list_registered_tasks()
    if not tasks:
        click.echo("No tasks registered.")
        return

    from app.core.task_config import TaskConfig  # noqa: E402

    click.echo("Registered tasks:")
    click.echo("------------------------------------------------------------")
    click.echo(f"{'task_id':20} {'type':10} {'sources.mode':14} name")
    click.echo("------------------------------------------------------------")

    for t in tasks:
        try:
            cfg: TaskConfig = task_registry.get_task_config(t.task_id)
            sources_mode = cfg.sources_mode
        except TaskRegistryError:
            sources_mode = "?"
        click.echo(
            f"{t.task_id:20} {t.task_type:10} {sources_mode:14} {t.name}"
        )


@cli.command("task-info")
@click.argument("task_id", type=str)
def task_info(task_id: str) -> None:
    """
    –ü–æ–∫–∞–∑–∞—Ç—å –ø–æ–¥—Ä–æ–±–Ω—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –∑–∞–¥–∞—á–µ –ø–æ –µ—ë task_id,
    –≤–∫–ª—é—á–∞—è —Ä–µ–∂–∏–º—ã –ø–æ–∏—Å–∫–∞ –∏ —á–∞–Ω–∫–µ—Ä.
    """
    from app.core.task_config import TaskConfig  # noqa: E402

    try:
        cfg: TaskConfig = task_registry.get_task_config(task_id)
    except TaskConfigError as e:
        click.echo(f"Error: {e}")
        sys.exit(1)
    except TaskRegistryError as e:
        click.echo(f"Registry error: {e}")
        sys.exit(1)
    except Exception as e:
        click.echo(f"Unexpected error: {e}")
        sys.exit(1)

    click.echo(f"task_id       : {cfg.task_id}")
    click.echo(f"name          : {cfg.name}")
    click.echo(f"description   : {cfg.description}")
    click.echo(f"task_type     : {cfg.task_type}")
    click.echo(f"sources.mode  : {cfg.sources_mode}")
    click.echo(f"text_search   : {cfg.enable_text_search}")
    click.echo(f"table_search  : {cfg.enable_table_search}")
    click.echo(f"postprocessing: {cfg.postprocessing_type}")

    # –î–µ—Ç–∞–ª–∏ text_search
    if cfg.text_search is not None:
        ts = cfg.text_search
        click.echo("\ntext_search:")
        click.echo(f"  enabled             : {ts.enabled}")
        click.echo(f"  embedding_model     : {ts.embedding_model}")
        click.echo(f"  mode                : {ts.mode}")
        click.echo(f"  topk                : {ts.topk}")
        click.echo(f"  max_chunks          : {ts.max_chunks}")
        click.echo(f"  similarity_threshold: {ts.similarity_threshold}")
        click.echo(f"  chunker             : {ts.chunker}")

    # –î–µ—Ç–∞–ª–∏ table_search
    if cfg.table_search is not None:
        tbl = cfg.table_search
        click.echo("\ntable_search:")
        click.echo(f"  enabled             : {tbl.enabled}")
        click.echo(f"  embedding_model     : {tbl.embedding_model}")
        click.echo(f"  mode                : {tbl.mode}")
        click.echo(f"  topk                : {tbl.topk}")
        click.echo(f"  max_rows            : {tbl.max_rows}")
        click.echo(f"  similarity_threshold: {tbl.similarity_threshold}")
        click.echo(f"  chunker             : {tbl.chunker}")

    click.echo("\ntechnical_prompt:")
    click.echo(cfg.technical_prompt or "(empty)")


@cli.command("ingest-employee-data")
def ingest_employee_data() -> None:
    """
    Ingestion –¥–µ–º–æ-–¥–∞–Ω–Ω—ã—Ö —Å–æ—Ç—Ä—É–¥–Ω–∏–∫–æ–≤ –≤ Chroma (collection=employee_data_rows).
    –ë–µ—Ä—ë—Ç —Å—Ç—Ä–æ–∫–∏ –∏–∑ SQLite (ensure_employee_table + seed_demo_employees),
    –∫–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ—Ç –≤ —á–∞–Ω–∫–∏ (row_to_chunk) –∏ –ø–∏—à–µ—Ç –≤ –≤–µ–∫—Ç–æ—Ä–∫—É.
    """
    from app.ingestion.employee_table import ensure_employee_table, seed_demo_employees
    from app.ingestion.employee_ingest import ingest_employee_table_to_chroma

    click.echo("Ensuring employee table and seeding demo employees...")
    ensure_employee_table()
    seed_demo_employees()

    click.echo("Ingesting employee table into Chroma collection 'employee_data_rows'...")
    ingest_employee_table_to_chroma(collection_name="employee_data_rows")
    click.echo("Done.")


if __name__ == "__main__":
    cli()

## FILE: app/core/__init__.py


## FILE: app/core/access_control.py
from dataclasses import dataclass

from app.core.config_loader import get_environment, load_system_config
from app.core.task_config import TaskConfig


@dataclass
class AccessDecision:
    allowed: bool
    reason: str


def _allow_corporate_in_dev() -> bool:
    """
    –ß–∏—Ç–∞–µ—Ç —Ñ–ª–∞–≥ –∏–∑ config/system.yaml:
    accesscontrol.allow_corporate_in_dev: true/false
    """
    cfg = load_system_config()
    ac = cfg.get("accesscontrol", {}) or {}
    return bool(ac.get("allow_corporate_in_dev", False))


def check_task_access(task_cfg: TaskConfig) -> AccessDecision:
    """
    –¶–µ–Ω—Ç—Ä–∞–ª–∏–∑–æ–≤–∞–Ω–Ω–∞—è –ø–æ–ª–∏—Ç–∏–∫–∞ –¥–æ—Å—Ç—É–ø–∞ –∫ –∑–∞–¥–∞—á–∞–º –ø–æ –æ–∫—Ä—É–∂–µ–Ω–∏—é –∏ —Ç–∏–ø—É.

    –ü—Ä–∞–≤–∏–ª–∞:
    - demo:
        - dev:  —Ä–∞–∑—Ä–µ—à–µ–Ω–æ
        - test: —Ä–∞–∑—Ä–µ—à–µ–Ω–æ (–≤–∏–∑—É–∞–ª—å–Ω—ã–π –æ—Ç–ª–∞–¥—á–∏–∫ –±–µ–∑ LLM)
        - prod: –ó–ê–ü–†–ï–©–ï–ù–û
    - corporate:
        - prod: –≤—Å–µ–≥–¥–∞ —Ä–∞–∑—Ä–µ—à–µ–Ω–æ
        - dev:  —Ä–∞–∑—Ä–µ—à–µ–Ω–æ, –µ—Å–ª–∏ accesscontrol.allow_corporate_in_dev = true
        - test: —Ä–∞–∑—Ä–µ—à–µ–Ω–æ (–¥–ª—è –æ—Ç–ª–∞–¥–∫–∏ –±–µ–∑ LLM)
    """
    env = get_environment()

    # DEMO: —Ç–æ–ª—å–∫–æ dev –∏ test, prod –∑–∞–ø—Ä–µ—â—ë–Ω
    if task_cfg.task_type == "demo":
        if env in ("dev", "test"):
            return AccessDecision(
                allowed=True,
                reason=f"demo task in environment={env} is allowed",
            )
        return AccessDecision(
            allowed=False,
            reason=f"demo tasks are not allowed in environment={env} by policy",
        )

    # CORPORATE: –∑–∞–≤—è–∑–∞–Ω–æ –Ω–∞ –æ–∫—Ä—É–∂–µ–Ω–∏–µ –∏ —Ñ–ª–∞–≥ –≤ –∫–æ–Ω—Ñ–∏–≥–µ
    if task_cfg.task_type == "corporate":
        if env == "prod":
            return AccessDecision(
                allowed=True,
                reason="corporate task is allowed in prod",
            )
        if env == "dev" and _allow_corporate_in_dev():
            return AccessDecision(
                allowed=True,
                reason="corporate task allowed in dev for development purposes",
            )
        if env == "test":
            # –í test-—Ä–µ–∂–∏–º–µ –º—ã –Ω–µ –∑–æ–≤—ë–º LLM, –Ω–æ —Ö–æ—Ç–∏–º –≤–∏–¥–µ—Ç—å –∫–æ–Ω—Ç–µ–∫—Å—Ç –¥–ª—è corporate
            return AccessDecision(
                allowed=True,
                reason="corporate task allowed in test for debugging without LLM",
            )
        return AccessDecision(
            allowed=False,
            reason=f"corporate tasks are not allowed in environment={env} by policy",
        )

    return AccessDecision(
        allowed=False,
        reason=f"Unknown task_type={task_cfg.task_type}",
    )

## FILE: app/core/chroma_client.py
from pathlib import Path
from typing import Optional

import chromadb
from chromadb.api import ClientAPI
from chromadb.config import Settings

from app.core.config_loader import load_system_config, SystemConfigError


_chroma_client: Optional[ClientAPI] = None


def get_chroma_client() -> ClientAPI:
    global _chroma_client
    if _chroma_client is not None:
        return _chroma_client

    cfg = load_system_config()
    paths = cfg.get("paths", {}) or {}
    chroma_dir = paths.get("chromadb_dir", "./data/chromadb")
    chroma_path = Path(chroma_dir)
    chroma_path.mkdir(parents=True, exist_ok=True)

    _chroma_client = chromadb.Client(
        Settings(
            is_persistent=True,
            persist_directory=str(chroma_path),
        )
    )
    return _chroma_client

## FILE: app/core/config_loader.py
from pathlib import Path
from functools import lru_cache
from typing import Any, Dict

import yaml


class SystemConfigError(Exception):
    pass


@lru_cache(maxsize=1)
def load_system_config() -> Dict[str, Any]:
    """
    –ó–∞–≥—Ä—É–∂–∞–µ—Ç config/system.yaml –æ–¥–∏–Ω —Ä–∞–∑ –∑–∞ –∂–∏–∑–Ω—å –ø—Ä–æ—Ü–µ—Å—Å–∞.
    """
    config_path = Path(__file__).parent.parent.parent / "config" / "system.yaml"
    if not config_path.is_file():
        raise SystemConfigError(f"Config file not found: {config_path}")

    try:
        data = yaml.safe_load(config_path.read_text(encoding="utf-8"))
    except Exception as e:
        raise SystemConfigError(f"Failed to read system config: {e}") from e

    if not isinstance(data, dict):
        raise SystemConfigError("System config must be a mapping at top level")

    return data


def get_environment() -> str:
    cfg = load_system_config()
    env = cfg.get("environment", "dev")
    if env not in {"dev", "test", "prod"}:
        raise SystemConfigError(f"Invalid environment in config: {env}")
    return env


def get_llm_mode() -> str:
    cfg = load_system_config()
    llm = cfg.get("llm", {}) or {}
    mode = llm.get("mode", "dev")
    return mode


def get_llm_connector_path() -> str:
    cfg = load_system_config()
    llm = cfg.get("llm", {}) or {}
    connector = llm.get("connector")
    if not connector:
        raise SystemConfigError("llm.connector is not set in system config")
    return connector

## FILE: app/core/event_logger.py
import json
import time
from dataclasses import dataclass, asdict
from pathlib import Path
from typing import Any, Dict, Optional

from app.core.config_loader import load_system_config, get_environment, SystemConfigError


@dataclass
class Event:
    timestamp: float
    event_type: str  # "query" | "search" | "llm"
    request_id: Optional[str]
    task_id: Optional[str]
    task_type: Optional[str]
    environment: str
    payload: Dict[str, Any]


def _get_log_path() -> Path:
    cfg = load_system_config()
    paths = cfg.get("paths", {}) or {}
    log_path = paths.get("logs_path", "./data/logs/app.log")
    path = Path(log_path)
    path.parent.mkdir(parents=True, exist_ok=True)
    return path


def log_event(
    event_type: str,
    payload: Dict[str, Any],
    request_id: Optional[str] = None,
    task_id: Optional[str] = None,
    task_type: Optional[str] = None,
) -> None:
    """
    –ü–∏—à–µ—Ç –æ–¥–Ω–æ —Å–æ–±—ã—Ç–∏–µ –≤ JSONL-–ª–æ–≥.
    """
    try:
        env = get_environment()
    except SystemConfigError:
        env = "unknown"

    evt = Event(
        timestamp=time.time(),
        event_type=event_type,
        request_id=request_id,
        task_id=task_id,
        task_type=task_type,
        environment=env,
        payload=payload,
    )

    log_path = _get_log_path()
    line = json.dumps(asdict(evt), ensure_ascii=False)

    try:
        with log_path.open("a", encoding="utf-8") as f:
            f.write(line + "\n")
    except Exception:
        # –õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ –Ω–µ –¥–æ–ª–∂–Ω–æ —Ä–æ–Ω—è—Ç—å –æ—Å–Ω–æ–≤–Ω–æ–π –ø–æ—Ç–æ–∫
        return

## FILE: app/core/glossary.py
from dataclasses import dataclass
from pathlib import Path
from typing import Dict, List

import yaml


class GlossaryError(Exception):
    pass


@dataclass
class Glossary:
    synonyms: Dict[str, List[str]]

    @classmethod
    def load(cls) -> "Glossary":
        """
        –ó–∞–≥—Ä—É–∂–∞–µ—Ç config/glossary.yaml –∏ —Å—Ç—Ä–æ–∏—Ç —Å–ª–æ–≤–∞—Ä—å —Å–∏–Ω–æ–Ω–∏–º–æ–≤.
        """
        config_path = Path(__file__).parent.parent.parent / "config" / "glossary.yaml"
        if not config_path.is_file():
            raise GlossaryError(f"Glossary config not found: {config_path}")

        try:
            data = yaml.safe_load(config_path.read_text(encoding="utf-8"))
        except Exception as e:
            raise GlossaryError(f"Failed to read glossary config: {e}") from e

        if not isinstance(data, dict) or "synonyms" not in data:
            raise GlossaryError("Glossary config must contain 'synonyms' mapping")

        syn = data["synonyms"]
        if not isinstance(syn, dict):
            raise GlossaryError("'synonyms' must be a mapping")

        normalized: Dict[str, List[str]] = {}
        for canon, variants in syn.items():
            if not isinstance(canon, str):
                continue
            if not isinstance(variants, list):
                continue
            vs: List[str] = []
            for v in variants:
                if isinstance(v, str):
                    vs.append(v.strip().lower())
            if vs:
                normalized[canon.strip().lower()] = vs

        return cls(synonyms=normalized)

    def normalize_text(self, text: str) -> str:
        """
        –ü—Ä–æ—Å—Ç–µ–π—à–∞—è –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è: –∑–∞–º–µ–Ω—è–µ–º —Å–∏–Ω–æ–Ω–∏–º—ã –Ω–∞ –∫–∞–Ω–æ–Ω–∏—á–µ—Å–∫–æ–µ –∏–º—è —Å—É—â–Ω–æ—Å—Ç–∏.
        –†–∞–±–æ—Ç–∞–µ—Ç –ø–æ –ø—Ä–∏–Ω—Ü–∏–ø—É "–ø–æ–¥—Å—Ç—Ä–æ–∫–∞ ‚Üí –∫–∞–Ω–æ–Ω" –≤ –Ω–∏–∂–Ω–µ–º —Ä–µ–≥–∏—Å—Ç—Ä–µ.
        """
        if not text:
            return text

        result = text
        lower = result.lower()

        # –î–ª—è —É–ø—Ä–æ—â–µ–Ω–∏—è –ø—Ä–æ—Ö–æ–¥–∏–º –ø–æ –≤—Å–µ–º —Å–∏–Ω–æ–Ω–∏–º–∞–º –∏ –¥–µ–ª–∞–µ–º .replace
        for canon, variants in self.synonyms.items():
            for v in variants:
                if not v:
                    continue
                if v in lower:
                    # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ä–µ–≥–∏—Å—Ç—Ä –æ—Å—Ç–∞–ª—å–Ω–æ–≥–æ —Ç–µ–∫—Å—Ç–∞, –∑–∞–º–µ–Ω—è–µ–º –ø–æ–Ω–∏–∂–µ–Ω–Ω—ã–π –≤–∞—Ä–∏–∞–Ω—Ç
                    result = result.replace(v, canon)
                    lower = result.lower()

        return result


_glossary: Glossary | None = None


def get_glossary() -> Glossary:
    global _glossary
    if _glossary is None:
        _glossary = Glossary.load()
    return _glossary


def normalize_query(text: str) -> str:
    """
    –ü—É–±–ª–∏—á–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –¥–ª—è –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏–∏ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å—Å–∫–æ–≥–æ —Ç–µ–∫—Å—Ç–∞ –ø–æ –≥–ª–æ—Å—Å–∞—Ä–∏—é.
    """
    g = get_glossary()
    return g.normalize_text(text)

## FILE: app/core/llm_client.py


## FILE: app/core/profanity_filter.py
from dataclasses import dataclass
from pathlib import Path
from typing import List, Set

import yaml


@dataclass
class ProfanityResult:
    detected: bool
    matches: List[str]


_RU_BAD = [
    "—Ö—É–π",
    "—Ö—É–µ",
    "—Ö—É—ë",
    "—Ö—É–∏",
    "–ø–∏–∑–¥",
    "–µ–±–∞—Ç",
    "–µ–±–∞–Ω",
    "–µ–±–ª",
    "–±–ª—è",
    "—Å—É–∫–∞",
    "–º—Ä–∞–∑—å",
]

_EN_BAD = [
    "fuck",
    "shit",
    "bitch",
    "asshole",
    "bastard",
    "cunt",
]

_FALSE_POSITIVES: Set[str] | None = None


def _load_false_positives() -> Set[str]:
    """
    –ó–∞–≥—Ä—É–∂–∞–µ—Ç —Å–ø–∏—Å–æ–∫ –∏—Å–∫–ª—é—á–µ–Ω–∏–π –∏–∑ config/profanity_exceptions.yaml,
    —Å–µ–∫—Ü–∏—è false_positives: [ "—á–µ–±–∞–Ω", ... ].
    """
    global _FALSE_POSITIVES
    if _FALSE_POSITIVES is not None:
        return _FALSE_POSITIVES

    path = Path(__file__).parent.parent.parent / "config" / "profanity_exceptions.yaml"
    result: Set[str] = set()

    if path.is_file():
        try:
            data = yaml.safe_load(path.read_text(encoding="utf-8"))
            if isinstance(data, dict):
                items = data.get("false_positives") or []
                if isinstance(items, list):
                    for v in items:
                        if isinstance(v, str):
                            result.add(v.strip().lower())
        except Exception:
            # –ï—Å–ª–∏ –∫–æ–Ω—Ñ–∏–≥ –±–∏—Ç—ã–π ‚Äî –ø—Ä–æ—Å—Ç–æ —Ä–∞–±–æ—Ç–∞–µ–º –±–µ–∑ –∏—Å–∫–ª—é—á–µ–Ω–∏–π
            result = set()

    _FALSE_POSITIVES = result
    return _FALSE_POSITIVES


def _is_false_positive_context(text: str, token: str, index: int) -> bool:
    """
    –°—á–∏—Ç–∞–µ—Ç —Å–æ–≤–ø–∞–¥–∞–Ω–∏–µ –ª–æ–∂–Ω—ã–º, –µ—Å–ª–∏ —Ç–æ–∫–µ–Ω –ø–æ–ø–∞–ª –≤–Ω—É—Ç—Ä—å —Å–ª–æ–≤–∞-–∏—Å–∫–ª—é—á–µ–Ω–∏—è.
    –ù–∞–ø—Ä–∏–º–µ—Ä, '–µ–±–∞–Ω' –≤–Ω—É—Ç—Ä–∏ '—á–µ–±–∞–Ω'.
    """
    fps = _load_false_positives()
    if not fps:
        return False

    for word in fps:
        pos = text.find(word)
        if pos == -1:
            continue
        # –ï—Å–ª–∏ —Ç–µ–∫—É—â–∏–π —Ç–æ–∫–µ–Ω –ª–µ–∂–∏—Ç –≤–Ω—É—Ç—Ä–∏ –Ω–∞–π–¥–µ–Ω–Ω–æ–≥–æ —Å–ª–æ–≤–∞-–∏—Å–∫–ª—é—á–µ–Ω–∏—è
        if pos <= index < pos + len(word):
            return True
    return False


def check_profanity(text: str) -> ProfanityResult:
    """
    –ü—Ä–æ—Å—Ç–µ–π—à–∏–π –¥–µ—Ç–µ–∫—Ç–æ—Ä: –∏—â–µ–º –≤—Ö–æ–∂–¥–µ–Ω–∏—è –∫–æ—Ä–Ω–µ–π –ø–ª–æ—Ö–∏—Ö —Å–ª–æ–≤ –≤ –Ω–∏–∂–Ω–µ–º —Ä–µ–≥–∏—Å—Ç—Ä–µ,
    –∏–≥–Ω–æ—Ä–∏—Ä—É—è –∑–∞—Ä–∞–Ω–µ–µ —Å–∫–æ–Ω—Ñ–∏–≥—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –ª–æ–∂–Ω—ã–µ —Å—Ä–∞–±–∞—Ç—ã–≤–∞–Ω–∏—è (—Ñ–∞–º–∏–ª–∏–∏ –∏ —Ç.–ø.).
    """
    if not text:
        return ProfanityResult(detected=False, matches=[])

    low = text.lower()
    matches: List[str] = []

    for token in _RU_BAD + _EN_BAD:
        start = 0
        while True:
            idx = low.find(token, start)
            if idx == -1:
                break
            if not _is_false_positive_context(low, token, idx):
                matches.append(token)
                break
            start = idx + 1

    return ProfanityResult(detected=bool(matches), matches=matches)

## FILE: app/core/rag_pipeline.py
from dataclasses import dataclass
from typing import List, Optional

from app.core.task_config import TaskConfig
from app.core.chroma_client import get_chroma_client


@dataclass
class RetrievedChunk:
    text: str
    source_id: str
    score: float


def _get_collection_name_for_task(task_cfg: TaskConfig) -> Optional[str]:
    if task_cfg.task_id == "demo_hello":
        return "demo_hello_texts"
    if task_cfg.task_id == "demo_rules":
        return "demo_rules_texts"
    return None


def ensure_collection_for_task(task_cfg: TaskConfig):
    client = get_chroma_client()
    coll_name = _get_collection_name_for_task(task_cfg)
    if coll_name is None:
        return None

    coll = client.get_or_create_collection(name=coll_name)

    if coll.count() == 0:
        if task_cfg.task_id == "demo_hello":
            texts = [
                (
                    "demo_hello_doc_1",
                    "–≠—Ç–æ –¥–µ–º–æ-–¥–æ–∫—É–º–µ–Ω—Ç —Å–∏—Å—Ç–µ–º—ã –∑–∞—è–≤–æ–∫. –°–∏—Å—Ç–µ–º–∞ –ø–æ–º–æ–≥–∞–µ—Ç —Å–æ—Ç—Ä—É–¥–Ω–∏–∫–∞–º –∑–∞–¥–∞–≤–∞—Ç—å –≤–æ–ø—Ä–æ—Å—ã "
                    "–ø–æ —Ä–µ–≥–ª–∞–º–µ–Ω—Ç–∞–º –∏ –ø—Ä–æ—Ü–µ—Å—Å–∞–º, –∞ —Ç–∞–∫–∂–µ –ø–æ–ª—É—á–∞—Ç—å –ø–æ–¥—Å–∫–∞–∑–∫–∏ –ø–æ –¥–æ—Å—Ç—É–ø–∞–º –∏ –ò–¢-—Å–µ—Ä–≤–∏—Å–∞–º. "
                    "–í –±—É–¥—É—â–µ–º —Å—é–¥–∞ –±—É–¥—É—Ç –∑–∞–≥—Ä—É–∂–µ–Ω—ã –Ω–∞—Å—Ç–æ—è—â–∏–µ –∫–æ—Ä–ø–æ—Ä–∞—Ç–∏–≤–Ω—ã–µ –¥–æ–∫—É–º–µ–Ω—Ç—ã –∏ –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏–∏.",
                )
            ]
        elif task_cfg.task_id == "demo_rules":
            texts = [
                (
                    "demo_rules_doc_1",
                    "–í –∫–æ–º–ø–∞–Ω–∏–∏ –¥–µ–π—Å—Ç–≤—É—é—Ç –±–∞–∑–æ–≤—ã–µ —Ä–µ–≥–ª–∞–º–µ–Ω—Ç—ã: —Å–æ—Ç—Ä—É–¥–Ω–∏–∫ –æ–±—è–∑–∞–Ω —Å–æ–≥–ª–∞—Å–æ–≤—ã–≤–∞—Ç—å –¥–æ—Å—Ç—É–ø—ã "
                    "–∫ —Å–∏—Å—Ç–µ–º–∞–º —á–µ—Ä–µ–∑ –∑–∞—è–≤–∫–∏, —Å–æ–±–ª—é–¥–∞—Ç—å –ø—Ä–∞–≤–∏–ª–∞ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–æ–Ω–Ω–æ–π –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç–∏ –∏ "
                    "–∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å —Ç–æ–ª—å–∫–æ —É—Ç–≤–µ—Ä–∂–¥—ë–Ω–Ω—ã–µ –∫–∞–Ω–∞–ª—ã –∫–æ–º–º—É–Ω–∏–∫–∞—Ü–∏–∏.",
                )
            ]
        else:
            texts = []

        if texts:
            ids = []
            docs = []
            metadatas = []
            for source_id, text in texts:
                ids.append(source_id)
                docs.append(text)
                metadatas.append({"source_id": source_id, "kind": task_cfg.task_id})
            coll.add(ids=ids, documents=docs, metadatas=metadatas)

    return coll


def retrieve_text_chunks(task_cfg: TaskConfig, query: str, top_k: int = 3) -> List[RetrievedChunk]:
    coll = ensure_collection_for_task(task_cfg)
    results: List[RetrievedChunk] = []
    if coll is None:
        return results

    ts = task_cfg.text_search
    mode = "topk"
    max_chunks = top_k
    threshold = None

    if ts is not None:
        mode = ts.mode or "topk"
        max_chunks = ts.max_chunks or top_k
        threshold = ts.similarity_threshold

    search = coll.query(
        query_texts=[query],
        n_results=max_chunks,
    )
    docs = search.get("documents", [[]])[0]
    ids = search.get("ids", [[]])[0]
    dists = search.get("distances", [[]])[0]

    raw_chunks: List[RetrievedChunk] = []
    for doc, sid, dist in zip(docs, ids, dists):
        raw_chunks.append(
            RetrievedChunk(text=doc, source_id=sid, score=float(dist))
        )

    if mode == "allwiththreshold" and threshold is not None:
        filtered = [ch for ch in raw_chunks if ch.score >= threshold]
        return filtered

    return raw_chunks[:top_k]


def retrieve_text_chunks_for_research(task_cfg: TaskConfig, query: str) -> List[RetrievedChunk]:
    """
    –£–ø—Ä–æ—â—ë–Ω–Ω—ã–π —Ä–∞—Å—à–∏—Ä–µ–Ω–Ω—ã–π –ø–æ–∏—Å–∫ –¥–ª—è research:
    —É–≤–µ–ª–∏—á–∏–≤–∞–µ–º n_results –≤ 2 —Ä–∞–∑–∞ –æ—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω–æ –±–∞–∑–æ–≤–æ–≥–æ top_k.
    """
    base_top_k = 3
    ts = task_cfg.text_search
    if ts is not None and ts.topk:
        base_top_k = ts.topk

    extended_top_k = max(base_top_k * 2, base_top_k + 1)
    return retrieve_text_chunks(task_cfg, query, top_k=extended_top_k)


def build_llm_prompt(task_cfg: TaskConfig, query: str, chunks: List[RetrievedChunk]) -> str:
    base_prompt = task_cfg.technical_prompt or ""
    context_lines: List[str] = []

    for i, ch in enumerate(chunks, start=1):
        context_lines.append(
            f"{i}. [source={ch.source_id}, score={ch.score:.4f}] {ch.text}"
        )

    context_block = "\n".join(context_lines) if context_lines else ""

    full_prompt = (
        f"{base_prompt}\n\n"
        f"–ö–æ–Ω—Ç–µ–∫—Å—Ç –∏–∑ –±–∞–∑—ã –∑–Ω–∞–Ω–∏–π:\n{context_block}\n\n"
        f"–í–æ–ø—Ä–æ—Å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è:\n{query}\n\n"
        f"–û—Ç–≤–µ—á–∞–π, –æ–ø–∏—Ä–∞—è—Å—å —Ç–æ–ª—å–∫–æ –Ω–∞ –∫–æ–Ω—Ç–µ–∫—Å—Ç. "
        f"–ï—Å–ª–∏ –æ—Ç–≤–µ—Ç –Ω–µ–æ—á–µ–≤–∏–¥–µ–Ω, —è–≤–Ω–æ —Å–∫–∞–∂–∏, —á—Ç–æ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –Ω–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ."
    )
    return full_prompt

## FILE: app/core/table_rag.py
from typing import List, Dict, Any

from app.core.chroma_client import get_chroma_client
from app.core.task_config import TaskConfig, TableSearchConfig


def search_table_semantic(
    task_cfg: TaskConfig,
    collection_name: str,
    query: str,
) -> List[Dict[str, Any]]:
    """
    –°–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–∏–π –ø–æ–∏—Å–∫ –ø–æ —Ç–∞–±–ª–∏—á–Ω—ã–º –¥–∞–Ω–Ω—ã–º –≤ Chroma.
    –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –±–µ—Ä—É—Ç—Å—è –∏–∑ task_cfg.table_search (mode, topk, max_rows, similarity_threshold).
    –†–µ–∂–∏–º—ã: topk / allwiththreshold.
    """
    client = get_chroma_client()
    coll = client.get_or_create_collection(name=collection_name)

    tbl_cfg: TableSearchConfig = task_cfg.table_search or TableSearchConfig()
    mode = tbl_cfg.mode or "topk"
    topk = tbl_cfg.topk or 5
    max_rows = tbl_cfg.max_rows or 50
    threshold = tbl_cfg.similarity_threshold

    # –î–ª—è –ø—Ä–æ—Å—Ç–æ—Ç—ã: –≤—Å–µ–≥–¥–∞ –∑–∞–ø—Ä–∞—à–∏–≤–∞–µ–º –¥–æ max_rows –∫–∞–Ω–¥–∏–¥–∞—Ç–æ–≤
    n_results = max_rows

    search = coll.query(
        query_texts=[query],
        n_results=n_results,
    )
    docs = search.get("documents", [[]])[0]
    ids = search.get("ids", [[]])[0]
    dists = search.get("distances", [[]])[0]
    metadatas = search.get("metadatas", [[]])[0]

    raw: List[Dict[str, Any]] = []
    for doc, sid, dist, meta in zip(docs, ids, dists, metadatas):
        meta = meta or {}
        raw.append(
            {
                "text": doc,
                "score": float(dist),
                "id": sid,
                "metadata": meta,
            }
        )

    # allwiththreshold ‚Äî —Ñ–∏–ª—å—Ç—Ä—É–µ–º –ø–æ –ø–æ—Ä–æ–≥—É, –∏–Ω–∞—á–µ topk
    if mode == "allwiththreshold" and threshold is not None:
        filtered = [r for r in raw if r["score"] >= threshold]
        return filtered[:max_rows]

    # topk –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é
    return raw[:topk]

## FILE: app/core/task_classifier.py
from dataclasses import dataclass
from typing import Optional, List, Dict, Any

from app.core.task_registry import task_registry, TaskRegistryError
from app.core.event_logger import log_event
from llm_connectors.connector_dev import call_llm, LLMError


@dataclass
class ClassificationResult:
    ok: bool
    task_id: Optional[str] = None
    task_type: Optional[str] = None
    confidence: Optional[float] = None
    error: Optional[str] = None


async def classify_query(
    query: str,
    request_id: str,
    debug: bool = False,
) -> ClassificationResult:
    """
    –ü—Ä–æ—Å—Ç–µ–π—à–∏–π LLM-–∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä –ø–æ–≤–µ—Ä—Ö —É–∂–µ —Å—É—â–µ—Å—Ç–≤—É—é—â–µ–≥–æ dev-–∫–æ–Ω–Ω–µ–∫—Ç–æ—Ä–∞.

    –õ–æ–≥–∏–∫–∞:
    - –ü–æ–ª—É—á–∞–µ–º —Å–ø–∏—Å–æ–∫ –¥–æ—Å—Ç—É–ø–Ω—ã—Ö –∑–∞–¥–∞—á –∏–∑ —Ä–µ–µ—Å—Ç—Ä–∞.
    - –§–æ—Ä–º–∏—Ä—É–µ–º —Å–∏—Å—Ç–µ–º–Ω—ã–π –ø—Ä–æ–º–ø—Ç —Å –æ–ø–∏—Å–∞–Ω–∏–µ–º –∑–∞–¥–∞—á.
    - –ü—Ä–æ—Å–∏–º LLM –≤–µ—Ä–Ω—É—Ç—å JSON —Å –ø–æ–ª—è–º–∏:
      { "task_id": "...", "task_type": "demo|corporate", "confidence": 0.0-1.0 }
    - –í —Å–ª—É—á–∞–µ –æ—à–∏–±–∫–∏ –∏–ª–∏ –Ω–∏–∑–∫–æ–π —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ–º ok=False.
    """
    try:
        tasks = task_registry.list_registered_tasks()
    except TaskRegistryError as e:
        return ClassificationResult(
            ok=False,
            error=f"Task registry error: {e}",
        )

    if not tasks:
        return ClassificationResult(
            ok=False,
            error="No tasks registered for classification",
        )

    lines: List[str] = []
    lines.append(
        "–¢—ã –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å—Å–∫–∏—Ö –∑–∞–ø—Ä–æ—Å–æ–≤ –ø–æ –≤–Ω—É—Ç—Ä–µ–Ω–Ω–∏–º –∑–∞–¥–∞—á–∞–º RAG-—Å–µ—Ä–≤–∏—Å–∞."
    )
    lines.append(
        "–£ —Ç–µ–±—è –µ—Å—Ç—å —Å–ø–∏—Å–æ–∫ –∑–∞–¥–∞—á. –¢–≤–æ—è –∑–∞–¥–∞—á–∞ ‚Äî –≤—ã–±—Ä–∞—Ç—å –û–î–ù–£ –Ω–∞–∏–±–æ–ª–µ–µ –ø–æ–¥—Ö–æ–¥—è—â—É—é."
    )
    lines.append(
        "–û—Ç–≤–µ—á–∞–π —Å—Ç—Ä–æ–≥–æ –≤ —Ñ–æ—Ä–º–∞—Ç–µ JSON –æ–¥–Ω–æ–π —Å—Ç—Ä–æ–∫–æ–π –±–µ–∑ –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–µ–≤, –±–µ–∑ –ø—Ä–µ—Ñ–∏–∫—Å–æ–≤ –∏ –ø–æ—è—Å–Ω–µ–Ω–∏–π."
    )
    lines.append(
        '–§–æ—Ä–º–∞—Ç –æ—Ç–≤–µ—Ç–∞: {"task_id": "<id>", "task_type": "demo|corporate", "confidence": <—á–∏—Å–ª–æ –æ—Ç 0 –¥–æ 1>}'
    )
    lines.append("")
    lines.append("–°–ø–∏—Å–æ–∫ –∑–∞–¥–∞—á:")
    for t in tasks:
        lines.append(
            f"- task_id={t.task_id}; task_type={t.task_type}; name={t.name}; description={t.description}"
        )
    lines.append("")
    lines.append("–ó–∞–ø—Ä–æ—Å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è:")
    lines.append(query)

    system_prompt = "\n".join(lines)

    messages: List[Dict[str, Any]] = [
        {"role": "system", "content": system_prompt},
        {
            "role": "user",
            "content": (
                "–û–ø—Ä–µ–¥–µ–ª–∏ –Ω–∞–∏–±–æ–ª–µ–µ –ø–æ–¥—Ö–æ–¥—è—â—É—é –∑–∞–¥–∞—á—É –∏ –≤–µ—Ä–Ω–∏ –¢–û–õ–¨–ö–û –æ–¥–∏–Ω JSON-–æ–±—ä–µ–∫—Ç "
                "–±–µ–∑ –ª–∏—à–Ω–µ–≥–æ —Ç–µ–∫—Å—Ç–∞, –±–µ–∑ –ø–æ—è—Å–Ω–µ–Ω–∏–π."
            ),
        },
    ]

    try:
        resp = await call_llm(messages, model="llama3.2:1b")
    except LLMError as e:
        return ClassificationResult(ok=False, error=f"LLMError during classification: {e}")

    try:
        content = resp["choices"][0]["message"]["content"]
    except Exception:
        return ClassificationResult(ok=False, error="Invalid LLM response structure for classification")

    import json

    try:
        parsed = json.loads(content)
    except Exception as e:
        return ClassificationResult(
            ok=False,
            error=f"Failed to parse classifier JSON: {e}",
        )

    task_id = parsed.get("task_id")
    task_type = parsed.get("task_type")
    confidence_raw = parsed.get("confidence")

    try:
        confidence = float(confidence_raw) if confidence_raw is not None else None
    except Exception:
        confidence = None

    # –ü—Ä–æ—Å—Ç–∞—è –≤–∞–ª–∏–¥–∞—Ü–∏—è
    if not isinstance(task_id, str) or not isinstance(task_type, str):
        return ClassificationResult(
            ok=False,
            error="Classifier returned invalid task_id or task_type",
        )

    # –û–≥—Ä–∞–Ω–∏—á–∏–º task_type –æ–∂–∏–¥–∞–µ–º—ã–º–∏ –∑–Ω–∞—á–µ–Ω–∏—è–º–∏
    if task_type not in {"demo", "corporate"}:
        return ClassificationResult(
            ok=False,
            error=f"Classifier returned unsupported task_type={task_type}",
        )

    # –ü–æ—Ä–æ–≥ —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏ (–º–æ–∂–Ω–æ –ø–æ—Ç–æ–º –≤—ã–Ω–µ—Å—Ç–∏ –≤ –∫–æ–Ω—Ñ–∏–≥)
    if confidence is not None and confidence < 0.4:
        log_event(
            event_type="classification_low_confidence",
            request_id=request_id,
            task_id=None,
            task_type=None,
            payload={
                "query": query,
                "task_id": task_id,
                "task_type": task_type,
                "confidence": confidence,
            },
        )
        return ClassificationResult(
            ok=False,
            task_id=task_id,
            task_type=task_type,
            confidence=confidence,
            error="Low classification confidence",
        )

    # –£—Å–ø–µ—à–Ω—ã–π –∫–µ–π—Å
    log_event(
        event_type="classification",
        request_id=request_id,
        task_id=task_id,
        task_type=task_type,
        payload={
            "query": query,
            "task_id": task_id,
            "task_type": task_type,
            "confidence": confidence,
            "raw_response": content if debug else None,
        },
    )

    return ClassificationResult(
        ok=True,
        task_id=task_id,
        task_type=task_type,
        confidence=confidence,
    )

## FILE: app/core/task_config.py
from dataclasses import dataclass
from typing import Any, Dict, Optional, List

from pathlib import Path
import yaml


class TaskConfigError(Exception):
    pass


@dataclass
class TextSearchConfig:
    enabled: bool = True
    embedding_model: str = "default-multilingual"
    mode: str = "topk"  # topk / allwiththreshold / hybrid
    topk: int = 5
    max_chunks: int = 20
    similarity_threshold: float = 0.3
    chunker: str = "semanticsplit"  # semanticsplit / fixedsize / none

    @classmethod
    def from_dict(cls, data: Dict[str, Any]) -> "TextSearchConfig":
        if not isinstance(data, dict):
            raise TaskConfigError("text_search must be a mapping")
        return cls(
            enabled=bool(data.get("enabled", True)),
            embedding_model=str(data.get("embedding_model", "default-multilingual")),
            mode=str(data.get("mode", "topk")),
            topk=int(data.get("topk", 5)),
            max_chunks=int(data.get("max_chunks", 20)),
            similarity_threshold=float(data.get("similarity_threshold", 0.3)),
            chunker=str(data.get("chunker", "semanticsplit")),
        )


@dataclass
class TableSearchConfig:
    enabled: bool = False
    embedding_model: str = "technical-ru"
    mode: str = "topk"  # topk / allwiththreshold / hybrid
    topk: int = 5
    max_rows: int = 50
    similarity_threshold: float = 0.4
    chunker: str = "rowtochunk"  # rowtochunk / fulltable

    @classmethod
    def from_dict(cls, data: Dict[str, Any]) -> "TableSearchConfig":
        if not isinstance(data, dict):
            raise TaskConfigError("table_search must be a mapping")
        return cls(
            enabled=bool(data.get("enabled", False)),
            embedding_model=str(data.get("embedding_model", "technical-ru")),
            mode=str(data.get("mode", "topk")),
            topk=int(data.get("topk", 5)),
            max_rows=int(data.get("max_rows", 50)),
            similarity_threshold=float(data.get("similarity_threshold", 0.4)),
            chunker=str(data.get("chunker", "rowtochunk")),
        )


@dataclass
class TaskConfig:
    task_id: str
    name: str
    description: str
    task_type: str  # demo / corporate
    technical_prompt: str

    # –ò—Å—Ç–æ—á–Ω–∏–∫–∏ –∏ —Ä–µ–∂–∏–º—ã –ø–æ–∏—Å–∫–∞
    sources_mode: str = "text"  # text / tables / texttables
    enable_text_search: bool = True
    enable_table_search: bool = False
    enable_research: bool = False
    postprocessing_type: str = "none"  # none / markdown-file / docx-file / customscript

    text_search: Optional[TextSearchConfig] = None
    table_search: Optional[TableSearchConfig] = None

    # –ö–æ–Ω—Ç–µ–∫—Å—Ç –∏ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ
    context_format: str = "structured_json"  # structured_json / plain_text
    preserve_full_query: bool = True
    include_sources_meta: bool = True
    meta_mode: str = "separate"  # inline / separate
    meta_fields: Optional[List[str]] = None

    # Research (–∏—Ç–µ—Ä–∞—Ç–∏–≤–Ω—ã–π –ø–æ–∏—Å–∫)
    research_enabled: bool = False
    research_trigger_on_low_confidence: bool = True
    research_max_iterations: int = 2
    research_min_confidence: float = 0.6

    # –ò—Å—Ç–æ—Ä–∏—è –¥–∏–∞–ª–æ–≥–∞
    history_max_messages: int = 10
    history_ttl_days: int = 90

    # –õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ
    logging_level: str = "info"
    logging_log_prompts: bool = True
    logging_log_search_results: bool = True
    logging_log_postprocessing: bool = True

    @classmethod
    def from_dict(cls, data: Dict[str, Any]) -> "TaskConfig":
        try:
            task_id = data["task_id"]
            name = data.get("name", task_id)
            description = data.get("description", "")
            task_type = data.get("task_type", "demo")
            technical_prompt = data.get("technical_prompt", "")
        except KeyError as e:
            raise TaskConfigError(f"Missing required field in TaskConfig: {e}") from e

        if task_type not in ("demo", "corporate"):
            raise TaskConfigError(f"Invalid task_type in TaskConfig: {task_type}")

        sources_mode = data.get("sources_mode", "text")
        if sources_mode not in ("text", "tables", "texttables"):
            raise TaskConfigError(f"Invalid sources_mode in TaskConfig: {sources_mode}")

        enable_text_search = bool(data.get("enable_text_search", True))
        enable_table_search = bool(data.get("enable_table_search", False))
        enable_research = bool(data.get("enable_research", False))

        postprocessing_type = data.get("postprocessing_type", "none")
        if postprocessing_type not in ("none", "markdown-file", "docx-file", "customscript"):
            raise TaskConfigError(
                f"Invalid postprocessing_type in TaskConfig: {postprocessing_type}"
            )

        # –í–ª–æ–∂–µ–Ω–Ω—ã–µ —Å–µ–∫—Ü–∏–∏ –ø–æ–∏—Å–∫–∞
        text_search_cfg: Optional[TextSearchConfig] = None
        table_search_cfg: Optional[TableSearchConfig] = None

        ts_data = data.get("text_search")
        if ts_data is not None:
            text_search_cfg = TextSearchConfig.from_dict(ts_data)

        tbl_data = data.get("table_search")
        if tbl_data is not None:
            table_search_cfg = TableSearchConfig.from_dict(tbl_data)

        # –ö–æ–Ω—Ç–µ–∫—Å—Ç –∏ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ
        context_cfg = data.get("context") or {}
        context_format = context_cfg.get("format", "structured_json")
        preserve_full_query = bool(context_cfg.get("preserve_full_query", True))
        include_sources_meta = bool(context_cfg.get("include_sources_meta", True))
        meta_mode = context_cfg.get("meta_mode", "separate")
        meta_fields = context_cfg.get("meta_fields")
        if meta_fields is not None and not isinstance(meta_fields, list):
            raise TaskConfigError("context.meta_fields must be a list if provided")

        # Research
        research_cfg = data.get("research") or {}
        research_enabled = bool(research_cfg.get("enabled", False))
        research_trigger_on_low_confidence = bool(
            research_cfg.get("trigger_on_low_confidence", True)
        )
        research_max_iterations = int(research_cfg.get("max_iterations", 2))
        research_min_confidence = float(research_cfg.get("min_confidence", 0.6))

        # –ò—Å—Ç–æ—Ä–∏—è
        history_cfg = data.get("history") or {}
        history_max_messages = int(history_cfg.get("max_messages", 10))
        history_ttl_days = int(history_cfg.get("ttl_days", 90))

        # –õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ
        logging_cfg = data.get("logging") or {}
        logging_level = logging_cfg.get("level", "info")
        logging_log_prompts = bool(logging_cfg.get("log_prompts", True))
        logging_log_search_results = bool(logging_cfg.get("log_search_results", True))
        logging_log_postprocessing = bool(logging_cfg.get("log_postprocessing", True))

        return cls(
            task_id=task_id,
            name=name,
            description=description,
            task_type=task_type,
            technical_prompt=technical_prompt,
            sources_mode=sources_mode,
            enable_text_search=enable_text_search,
            enable_table_search=enable_table_search,
            enable_research=enable_research,
            postprocessing_type=postprocessing_type,
            text_search=text_search_cfg,
            table_search=table_search_cfg,
            context_format=context_format,
            preserve_full_query=preserve_full_query,
            include_sources_meta=include_sources_meta,
            meta_mode=meta_mode,
            meta_fields=meta_fields,
            research_enabled=research_enabled,
            research_trigger_on_low_confidence=research_trigger_on_low_confidence,
            research_max_iterations=research_max_iterations,
            research_min_confidence=research_min_confidence,
            history_max_messages=history_max_messages,
            history_ttl_days=history_ttl_days,
            logging_level=logging_level,
            logging_log_prompts=logging_log_prompts,
            logging_log_search_results=logging_log_search_results,
            logging_log_postprocessing=logging_log_postprocessing,
        )


def load_task_config(task_id: str) -> TaskConfig:
    """
    –ó–∞–≥—Ä—É–∂–∞–µ—Ç TaskConfig –∏–∑ config/tasks/<task_id>.yaml.
    """
    tasks_dir = Path(__file__).parent.parent.parent / "config" / "tasks"
    cfg_path = tasks_dir / f"{task_id}.yaml"
    if not cfg_path.is_file():
        raise TaskConfigError(f"Task config not found for task_id={task_id} ({cfg_path})")

    try:
        data = yaml.safe_load(cfg_path.read_text(encoding="utf-8"))
    except Exception as e:
        raise TaskConfigError(f"Failed to read TaskConfig YAML: {e}") from e

    if not isinstance(data, dict):
        raise TaskConfigError("TaskConfig YAML must be a mapping at top level")

    return TaskConfig.from_dict(data)

## FILE: app/core/task_registry.py
from dataclasses import dataclass
from pathlib import Path
from typing import Dict, List

import yaml

from app.core.task_config import TaskConfig, load_task_config, TaskConfigError


@dataclass
class RegisteredTask:
    task_id: str
    task_type: str  # "demo" | "corporate"
    name: str
    description: str


class TaskRegistryError(Exception):
    pass


class TaskRegistry:
    """
    –§–∞–π–ª–æ–≤—ã–π —Ä–µ–µ—Å—Ç—Ä –∑–∞–¥–∞—á –ø–æ–≤–µ—Ä—Ö TaskConfig (config/tasks/*.yaml).
    –ö—ç—à–∏—Ä—É–µ—Ç –∑–∞–≥—Ä—É–∂–µ–Ω–Ω—ã–µ –∫–æ–Ω—Ñ–∏–≥–∏ –∏ —É–º–µ–µ—Ç —Å–∫–∞–Ω–∏—Ä–æ–≤–∞—Ç—å –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é –∑–∞–¥–∞—á.
    """

    def __init__(self) -> None:
        self._tasks: Dict[str, TaskConfig] = {}

    def get_task_config(self, task_id: str) -> TaskConfig:
        if task_id in self._tasks:
            return self._tasks[task_id]
        try:
            cfg = load_task_config(task_id)
        except TaskConfigError as e:
            raise TaskRegistryError(str(e)) from e
        self._tasks[task_id] = cfg
        return cfg

    def _scan_tasks_dir(self) -> List[str]:
        """
        –ù–∞—Ö–æ–¥–∏—Ç –≤—Å–µ config/tasks/*.yaml –∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å–ø–∏—Å–æ–∫ task_id.
        """
        tasks_dir = Path(__file__).parent.parent.parent / "config" / "tasks"
        if not tasks_dir.is_dir():
            return []

        task_ids: List[str] = []
        for path in tasks_dir.glob("*.yaml"):
            try:
                data = yaml.safe_load(path.read_text(encoding="utf-8"))
            except Exception:
                continue
            if not isinstance(data, dict):
                continue
            tid = data.get("task_id")
            if isinstance(tid, str):
                task_ids.append(tid)
        return sorted(set(task_ids))

    def list_registered_tasks(self) -> List[RegisteredTask]:
        """
        –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å–ø–∏—Å–æ–∫ –∑–∞–¥–∞—á –ø–æ —Ñ–∞–π–ª–æ–≤–æ–π —Å–∏—Å—Ç–µ–º–µ (config/tasks/*.yaml),
        –∑–∞–≥—Ä—É–∂–∞—è TaskConfig –ø—Ä–∏ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ—Å—Ç–∏.
        """
        result: List[RegisteredTask] = []

        for task_id in self._scan_tasks_dir():
            try:
                cfg = self.get_task_config(task_id)
            except TaskRegistryError:
                continue
            result.append(
                RegisteredTask(
                    task_id=cfg.task_id,
                    task_type=cfg.task_type,
                    name=cfg.name,
                    description=cfg.description,
                )
            )
        return result


# –ì–ª–æ–±–∞–ª—å–Ω—ã–π singleton, —á—Ç–æ–±—ã –Ω–µ –ø–ª–æ–¥–∏—Ç—å —Ä–µ–µ—Å—Ç—Ä—ã
task_registry = TaskRegistry()

## FILE: app/ingestion/employee_ingest.py
from typing import List, Dict, Any

from app.ingestion.employee_table import (
    ensure_employee_table,
    seed_demo_employees,
    get_sqlite_connection,
)
from app.core.table_rag import ingest_table_rows_to_chroma


def load_employee_rows() -> List[Dict[str, Any]]:
    """
    –ó–∞–≥—Ä—É–∂–∞–µ—Ç –≤—Å–µ —Å—Ç—Ä–æ–∫–∏ –∏–∑ —Ç–∞–±–ª–∏—Ü—ã employees –≤ –≤–∏–¥–µ —Å–ø–∏—Å–∫–∞ dict-–æ–≤.
    –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –∫–∞–∫ –∏—Å—Ç–æ—á–Ω–∏–∫ –¥–ª—è –≤–µ–∫—Ç–æ—Ä–Ω–æ–≥–æ ingestion.
    """
    ensure_employee_table()
    seed_demo_employees()

    conn = get_sqlite_connection()
    try:
        cur = conn.execute(
            "SELECT id, fullname, position, department FROM employees ORDER BY id ASC"
        )
        rows = cur.fetchall()
        result: List[Dict[str, Any]] = []
        for r in rows:
            result.append(
                {
                    "id": r["id"],
                    "fullname": r["fullname"],
                    "position": r["position"],
                    "department": r["department"],
                }
            )
        return result
    finally:
        conn.close()


def ingest_employee_table_to_chroma(
    collection_name: str = "employee_data_rows",
) -> None:
    """
    –ß–∏—Ç–∞–µ—Ç –≤—Å–µ —Å—Ç—Ä–æ–∫–∏ employees –∏–∑ SQLite –∏ –∏–Ω–¥–µ–∫—Å–∏—Ä—É–µ—Ç –∏—Ö –≤ Chroma
    –∫–∞–∫ —á–∞–Ω–∫–∏ –ø–æ —Å—Ç—Ä–æ–∫–∞–º (row_to_chunk).
    """
    rows = load_employee_rows()
    if not rows:
        return

    ingest_table_rows_to_chroma(
        collection_name=collection_name,
        rows=rows,
        table_name="employees",
        mode="row_to_chunk",
    )

## FILE: app/ingestion/employee_table.py
from pathlib import Path
import sqlite3
from typing import Iterable, Dict, Any, List, Optional

from app.core.config_loader import load_system_config, SystemConfigError


def get_sqlite_path() -> Path:
    """
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –ø—É—Ç—å –∫ SQLite-–±–∞–∑–µ –¥–∞–Ω–Ω—ã—Ö –∏–∑ config/system.yaml.
    –ï—Å–ª–∏ –ø—É—Ç—å/–¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—è –Ω–µ —Å—É—â–µ—Å—Ç–≤—É—é—Ç ‚Äî —Å–æ–∑–¥–∞—ë—Ç –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é.
    """
    cfg = load_system_config()
    paths = cfg.get("paths") or {}
    sqlite_path = paths.get("sqlite_path", "./data/sqlite/tables.db")
    path = Path(sqlite_path)
    path.parent.mkdir(parents=True, exist_ok=True)
    return path


def get_sqlite_connection() -> sqlite3.Connection:
    """
    –û—Ç–∫—Ä—ã–≤–∞–µ—Ç —Å–æ–µ–¥–∏–Ω–µ–Ω–∏–µ —Å SQLite –∏ –≤–∫–ª—é—á–∞–µ—Ç row_factory=Row –¥–ª—è —É–¥–æ–±–Ω–æ–π —Ä–∞–±–æ—Ç—ã.
    """
    db_path = get_sqlite_path()
    conn = sqlite3.connect(str(db_path))
    conn.row_factory = sqlite3.Row
    return conn


def ensure_employee_table() -> None:
    """
    –°–æ–∑–¥–∞—ë—Ç —Ç–∞–±–ª–∏—Ü—É employees, –µ—Å–ª–∏ –µ—ë –µ—â—ë –Ω–µ—Ç.
    –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –∫–∞–∫ –∏—Å—Ç–æ—á–Ω–∏–∫ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –¥–∞–ª—å–Ω–µ–π—à–µ–≥–æ ingestion –≤ –≤–µ–∫—Ç–æ—Ä–∫—É.
    """
    conn = get_sqlite_connection()
    try:
        conn.execute(
            """
            CREATE TABLE IF NOT EXISTS employees (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                fullname TEXT NOT NULL,
                position TEXT NOT NULL,
                department TEXT NOT NULL
            )
            """
        )
        conn.commit()
    finally:
        conn.close()


def seed_demo_employees() -> None:
    """
    –ó–∞—Å–µ–≤–∞–µ—Ç –¥–µ–º–æ-–¥–∞–Ω–Ω—ã–º–∏ —Ç–∞–±–ª–∏—Ü—É employees, –µ—Å–ª–∏ –æ–Ω–∞ –ø—É—Å—Ç–∞.
    –≠—Ç–∏ –¥–∞–Ω–Ω—ã–µ –ø–æ—Ç–æ–º –±—É–¥—É—Ç –∑–∞–∏–Ω–≥–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω—ã –≤ Chroma (row_to_chunk).
    """
    conn = get_sqlite_connection()
    try:
        cur = conn.execute("SELECT COUNT(*) AS cnt FROM employees")
        row = cur.fetchone()
        if row and row["cnt"] > 0:
            # –£–∂–µ –µ—Å—Ç—å –¥–∞–Ω–Ω—ã–µ ‚Äì –Ω–∏—á–µ–≥–æ –Ω–µ –¥–µ–ª–∞–µ–º
            return

        demo_rows: List[Dict[str, str]] = [
            {
                "fullname": "–ò–≤–∞–Ω–æ–≤ –ò–≤–∞–Ω –ò–≤–∞–Ω–æ–≤–∏—á",
                "position": "–ò–Ω–∂–µ–Ω–µ—Ä –ø–æ —ç–∫—Å–ø–ª—É–∞—Ç–∞—Ü–∏–∏",
                "department": "–ò–¢‚Äë–∏–Ω—Ñ—Ä–∞—Å—Ç—Ä—É–∫—Ç—É—Ä–∞",
            },
            {
                "fullname": "–ü–µ—Ç—Ä–æ–≤ –ü—ë—Ç—Ä –ü–µ—Ç—Ä–æ–≤–∏—á",
                "position": "–°–∏—Å—Ç–µ–º–Ω—ã–π –∞–¥–º–∏–Ω–∏—Å—Ç—Ä–∞—Ç–æ—Ä",
                "department": "–ò–¢‚Äë—Å–µ—Ä–≤–∏—Å—ã",
            },
            {
                "fullname": "–°–∏–¥–æ—Ä–æ–≤–∞ –ê–Ω–Ω–∞ –í–ª–∞–¥–∏–º–∏—Ä–æ–≤–Ω–∞",
                "position": "–ë–∏–∑–Ω–µ—Å‚Äë–∞–Ω–∞–ª–∏—Ç–∏–∫",
                "department": "–î–µ–ø–∞—Ä—Ç–∞–º–µ–Ω—Ç —Ä–∞–∑–≤–∏—Ç–∏—è",
            },
            {
                "fullname": "–ö—É–∑–Ω–µ—Ü–æ–≤–∞ –û–ª—å–≥–∞ –°–µ—Ä–≥–µ–µ–≤–Ω–∞",
                "position": "–°–ø–µ—Ü–∏–∞–ª–∏—Å—Ç –ø–æ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–æ–Ω–Ω–æ–π –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç–∏",
                "department": "–ò–ë",
            },
            {
                "fullname": "–ù–∏–∫–æ–ª–∞–µ–≤ –°–µ—Ä–≥–µ–π –ù–∏–∫–æ–ª–∞–µ–≤–∏—á",
                "position": "DevOps‚Äë–∏–Ω–∂–µ–Ω–µ—Ä",
                "department": "–ò–¢‚Äë–ø–ª–∞—Ç—Ñ–æ—Ä–º–∞",
            },
            {
                "fullname": "Smirnov Alexey",
                "position": "Data Engineer",
                "department": "Data Platform",
            },
        ]

        conn.executemany(
            """
            INSERT INTO employees (fullname, position, department)
            VALUES (:fullname, :position, :department)
            """,
            demo_rows,
        )
        conn.commit()
    finally:
        conn.close()

## FILE: app/main.py
from fastapi import FastAPI
from fastapi.responses import JSONResponse

from llm_connectors.connector_dev import call_llm, LLMError
from app.api.v1.routes import router as api_v1_router
from app.core.config_loader import get_environment, get_llm_mode


app = FastAPI(title="RAG Service", version="0.1.0")

app.include_router(api_v1_router)


@app.get("/api/v1/health")
async def health():
    env = get_environment()
    llm_mode = get_llm_mode()
    return JSONResponse(
        {
            "status": "ok",
            "environment": env,
            "chromadb": "unknown",
            "sqlite": "unknown",
            "llm_mode": llm_mode or "unknown",
            "uptime_seconds": 0,
        }
    )


@app.get("/api/v1/llm_test")
async def llm_test():
    try:
        resp = await call_llm(
            [{"role": "user", "content": "–°–∫–∞–∂–∏ –æ–¥–Ω–æ —Å–ª–æ–≤–æ: —Ç–µ—Å—Ç."}],
            model="llama3.2:1b",
        )
        content = resp["choices"][0]["message"]["content"]
        return {"ok": True, "answer": content}
    except LLMError as e:
        return {"ok": False, "error": str(e)}

## FILE: app/postprocessing/files.py
import time
from pathlib import Path
from typing import Tuple


def save_markdown(content: str, task_cfg) -> Tuple[str, str]:
    """
    –°–æ—Ö—Ä–∞–Ω—è–µ—Ç —Ç–µ–∫—Å—Ç–æ–≤–æ–µ —Å–æ–¥–µ—Ä–∂–∏–º–æ–µ –≤ markdown-—Ñ–∞–π–ª (.md).
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç (–∞–±—Å–æ–ª—é—Ç–Ω—ã–π_–ø—É—Ç—å, –∏–º—è_—Ñ–∞–π–ª–∞).
    """
    from app.core.config_loader import load_system_config

    cfg = load_system_config()
    paths = cfg.get("paths", {})
    output_dir = paths.get("output_dir", ".data/outputs")
    
    output_path = Path(output_dir)
    output_path.mkdir(parents=True, exist_ok=True)
    
    timestamp = int(time.time())
    filename = f"{task_cfg.task_id}_{timestamp}.md"
    filepath = output_path / filename
    
    filepath.write_text(content, encoding="utf-8")
    
    return str(filepath.resolve()), filename


def save_docx(content: str, task_cfg) -> Tuple[str, str]:
    """
    –°–æ—Ö—Ä–∞–Ω—è–µ—Ç —Ç–µ–∫—Å—Ç–æ–≤–æ–µ —Å–æ–¥–µ—Ä–∂–∏–º–æ–µ –≤ DOCX-—Ñ–∞–π–ª.
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç (–∞–±—Å–æ–ª—é—Ç–Ω—ã–π_–ø—É—Ç—å, –∏–º—è_—Ñ–∞–π–ª–∞).
    """
    from docx import Document  # type: ignore
    from app.core.config_loader import load_system_config

    cfg = load_system_config()
    paths = cfg.get("paths", {})
    output_dir = paths.get("output_dir", ".data/outputs")
    
    output_path = Path(output_dir)
    output_path.mkdir(parents=True, exist_ok=True)
    
    timestamp = int(time.time())
    filename = f"{task_cfg.task_id}_{timestamp}.docx"
    filepath = output_path / filename
    
    doc = Document()
    doc.add_paragraph(content)
    doc.save(str(filepath))
    
    return str(filepath.resolve()), filename

## FILE: code_collector.py
from pathlib import Path

PROJECT_ROOT = Path(__file__).parent.resolve()
SNAPSHOT_FILE = PROJECT_ROOT / "all_code.txt"

INCLUDE_EXTS = {".py", ".yaml", ".yml", ".txt", ".md"}
EXCLUDE_FILES = {"all_code.txt", ".env"}


def should_include(path: Path) -> bool:
    # –ø—Ä–æ–ø—É—Å–∫–∞–µ–º —Ñ–∞–π–ª—ã –≤–Ω—É—Ç—Ä–∏ —Å–∫—Ä—ã—Ç—ã—Ö –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–π (–Ω–∞—á–∏–Ω–∞—é—â–∏—Ö—Å—è —Å ".")
    for part in path.parts:
        if part.startswith("."):
            return False
    if path.name in EXCLUDE_FILES:
        return False
    if path.suffix not in INCLUDE_EXTS:
        return False
    return True


def collect_files():
    files = []
    seen = set()
    for p in PROJECT_ROOT.rglob("*"):
        if not p.is_file():
            continue
        rel = p.relative_to(PROJECT_ROOT)
        if rel in seen:
            continue
        if should_include(p):
            seen.add(rel)
            files.append(p)
    return sorted(files, key=lambda p: str(p))


def build_snapshot():
    files = collect_files()
    lines = []
    lines.append("# SNAPSHOT OF PROJECT FILES (TEXT)\n")
    lines.append("# Each file is separated by a marker line: ## FILE: <relative_path>\n\n")

    for path in files:
        rel_path = path.relative_to(PROJECT_ROOT)
        lines.append(f"## FILE: {rel_path}\n")
        try:
            text = path.read_text(encoding="utf-8")
        except Exception as e:
            lines.append(f"# ERROR READING FILE: {e}\n\n")
            continue
        lines.append(text)
        if not text.endswith("\n"):
            lines.append("\n")
        lines.append("\n")

    SNAPSHOT_FILE.write_text("".join(lines), encoding="utf-8")
    print(f"[code_collector] Snapshot written to {SNAPSHOT_FILE} ({len(files)} files).")


def main():
    print("code_collector.py ‚Äî —Å–Ω–∏–º–æ–∫ –ø—Ä–æ–µ–∫—Ç–∞ –≤ all_code.txt")
    print("1) –û–±–Ω–æ–≤–∏—Ç—å all_code.txt (–≤—Å–µ —Ñ–∞–π–ª—ã –∫—Ä–æ–º–µ —Å–∫—Ä—ã—Ç—ã—Ö –ø–∞–ø–æ–∫)")
    choice = input("–í—ã–±–æ—Ä (1): ").strip() or "1"
    if choice == "1":
        build_snapshot()
    else:
        print("–ù–µ–∏–∑–≤–µ—Å—Ç–Ω—ã–π –≤—ã–±–æ—Ä, –Ω–∏—á–µ–≥–æ –Ω–µ –¥–µ–ª–∞—é.")


if __name__ == "__main__":
    main()

## FILE: config/glossary.yaml
synonyms:
  clickhouse:
    - "clickhouse"
    - "–∫–ª–∏–∫—Ö–∞—É—Å"
    - "–∫–ª–∏–∫ —Ö–∞—É—Å"
    - "–∫–æ–ª–æ–Ω–æ—á–Ω–∞—è –±–¥"
    - "–∫–æ–ª–æ–Ω–æ—á–Ω–∞—è –±–∞–∑–∞"
    - "–∫–æ–ª–æ–Ω–æ—á–Ω–∞—è –±–∞–∑–∞ –¥–∞–Ω–Ω—ã—Ö"
  chromadb:
    - "chroma"
    - "chroma db"
    - "—Ö—Ä–æ–º–∞"
    - "–≤–µ–∫—Ç–æ—Ä–Ω–æ–µ —Ö—Ä–∞–Ω–∏–ª–∏—â–µ"
  sqlite:
    - "sqlite"
    - "—Å–∫—É–ª–ª–∞–π—Ç"
    - "—Ñ–∞–π–ª–æ–≤–∞—è –±–¥"

## FILE: config/profanity_exceptions.yaml
false_positives:
  - "—á–µ–±–∞–Ω"

## FILE: config/system.yaml
environment: dev

paths:
  data_root: .data
  chroma_db_dir: .data/chroma_db
  sqlite_path: .data/sqlite/tables.db
  logs_path: .data/logs/app.log
  output_dir: .data/outputs

llm:
  mode: dev
  connector: llm_connectors.connector_dev.call_llm

access_control:
  allow_corporate_in_dev: true

## FILE: config/tasks/demo_hello.yaml
task_id: demo_hello
name: "Demo: –ø—Ä–∏–≤–µ—Ç—Å—Ç–≤–µ–Ω–Ω–∞—è –∑–∞–¥–∞—á–∞"
description: "–ü—Ä–æ—Å—Ç–∞—è –¥–µ–º–æ-–∑–∞–¥–∞—á–∞ –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏ RAG-—Å–µ—Ä–≤–∏—Å–∞ –∏ –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–∏ —Å LLM."
task_type: demo

technical_prompt: |
  –¢—ã –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç —Å–∏—Å—Ç–µ–º—ã RAG, –∫–æ—Ç–æ—Ä–∞—è –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç –∑–∞—è–≤–∫–∏ —Å–æ—Ç—Ä—É–¥–Ω–∏–∫–æ–≤.
  –û—Ç–≤–µ—á–∞–π –∫—Ä–∞—Ç–∫–æ, –¥—Ä—É–∂–µ–ª—é–±–Ω–æ –∏ –ø–æ –¥–µ–ª—É.
  –°–µ–π—á–∞—Å —É –Ω–∞—Å –¥–µ–º–æ-—Ä–µ–∂–∏–º: –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ –∏ —Ç–∞–±–ª–∏—Ü –Ω–µ—Ç, –ø—Ä–æ—Å—Ç–æ –æ–±—ä—è—Å–Ω–∏,
  —á—Ç–æ —ç—Ç–æ –∑–∞ –¥–µ–º–æ-—Å–∏—Å—Ç–µ–º–∞ –∑–∞—è–≤–æ–∫ –∏ —á—Ç–æ –æ–Ω–∞ –≤ –ø–µ—Ä—Å–ø–µ–∫—Ç–∏–≤–µ –±—É–¥–µ—Ç —É–º–µ—Ç—å
  –Ω–∞ —É—Ä–æ–≤–Ω–µ –±–∏–∑–Ω–µ—Å–∞ (–±–µ–∑ —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏—Ö –¥–µ—Ç–∞–ª–µ–π).

## FILE: config/tasks/demo_rules.yaml
task_id: demo_rules
name: "Demo: —Ä–µ–≥–ª–∞–º–µ–Ω—Ç—ã –∏ –ø—Ä–∞–≤–∏–ª–∞"
description: "–î–µ–º–æ-–∑–∞–¥–∞—á–∞ –¥–ª—è –≤–æ–ø—Ä–æ—Å–æ–≤ –ø—Ä–æ –≤–Ω—É—Ç—Ä–µ–Ω–Ω–∏–µ –ø—Ä–∞–≤–∏–ª–∞ –∏ —Ä–µ–≥–ª–∞–º–µ–Ω—Ç—ã –∫–æ–º–ø–∞–Ω–∏–∏."
task_type: demo
technical_prompt: >
  –¢—ã ‚Äî –≤–Ω—É—Ç—Ä–µ–Ω–Ω–∏–π –ø–æ–º–æ—â–Ω–∏–∫ –ø–æ —Ä–µ–≥–ª–∞–º–µ–Ω—Ç–∞–º –∏ –ø—Ä–∞–≤–∏–ª–∞–º –∫–æ–º–ø–∞–Ω–∏–∏.
  –ò—Å–ø–æ–ª—å–∑—É–π –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª–µ–Ω–Ω—ã–π –∫–æ–Ω—Ç–µ–∫—Å—Ç, —á—Ç–æ–±—ã –æ—Ç–≤–µ—Ç–∏—Ç—å –Ω–∞ –≤–æ–ø—Ä–æ—Å —Å–æ—Ç—Ä—É–¥–Ω–∏–∫–∞.
  –ï—Å–ª–∏ –≤ –∫–æ–Ω—Ç–µ–∫—Å—Ç–µ –Ω–µ—Ç —Ç–æ—á–Ω–æ–≥–æ –æ—Ç–≤–µ—Ç–∞, –≥–æ–≤–æ—Ä–∏ –æ–± —ç—Ç–æ–º —è–≤–Ω–æ –∏ –æ—Ç–≤–µ—á–∞–π –≤ –æ–±—â–∏—Ö —á–µ—Ä—Ç–∞—Ö,
  –Ω–µ –ø—Ä–∏–¥—É–º—ã–≤–∞—è –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã—Ö –ø–æ–ª–∏—Ç–∏–∫, –∫–æ—Ç–æ—Ä—ã—Ö –Ω–µ—Ç –≤ —Ç–µ–∫—Å—Ç–µ.

## FILE: config/tasks/employee_data.yaml
task_id: employee_data
name: "–î–∞–Ω–Ω—ã–µ –æ —Å–æ—Ç—Ä—É–¥–Ω–∏–∫–∞—Ö (demo)"
description: "–ü–æ–∏—Å–∫ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ —Å–æ—Ç—Ä—É–¥–Ω–∏–∫–∞—Ö –∫–æ–º–ø–∞–Ω–∏–∏ –ø–æ –∏–º–µ–Ω–∏, –¥–æ–ª–∂–Ω–æ—Å—Ç–∏ –∏–ª–∏ –ø–æ–¥—Ä–∞–∑–¥–µ–ª–µ–Ω–∏—é (–¥–µ–º–æ-–∑–∞–¥–∞—á–∞)"
task_type: demo
technical_prompt: |
  –¢—ã –ø–æ–º–æ–≥–∞–µ—à—å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—é –Ω–∞–π—Ç–∏ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ —Å–æ—Ç—Ä—É–¥–Ω–∏–∫–∞—Ö.
  –ò—Å–ø–æ–ª—å–∑—É–π –∫–æ–Ω—Ç–µ–∫—Å—Ç –∏–∑ –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö –∏ –æ—Ç–≤–µ—á–∞–π –∫—Ä–∞—Ç–∫–æ –∏ –ø–æ –¥–µ–ª—É.

sources_mode: tables
enable_text_search: false
enable_table_search: true

table_search:
  mode: topk
  topk: 5
  similarity_threshold: 0.3

enable_research: false
postprocessing_type: docx-file

## FILE: docker/docker-compose.dev.yml


## FILE: llm_connectors/connector_dev.py
import os
from typing import List, Dict, Any

import httpx


OLLAMA_CHAT_URL = os.getenv(
    "OLLAMA_CHAT_URL",
    "http://127.0.0.1:4004/api/chat",
)


class LLMError(Exception):
    pass


async def call_llm(
    messages: List[Dict[str, Any]],
    model: str | None = None,
) -> Dict[str, Any]:
    """
    –î–µ–≤-–∫–æ–Ω–Ω–µ–∫—Ç–æ—Ä –∫ –ª–æ–∫–∞–ª—å–Ω–æ–º—É —Å–µ—Ä–≤–∏—Å—É ollama_chat_4b.
    messages: —Å–ø–∏—Å–æ–∫ —Å–æ–æ–±—â–µ–Ω–∏–π –≤ —Ñ–æ—Ä–º–∞—Ç–µ OpenAI (role/content).
    model: "llama3.2:1b" –∏–ª–∏ "llama3.2:3b" (–µ—Å–ª–∏ None ‚Äî –¥–µ—Ñ–æ–ª—Ç –≤ —Å–µ—Ä–≤–∏—Å–µ).
    """
    payload: Dict[str, Any] = {"messages": messages}
    if model:
        payload["model"] = model

    async with httpx.AsyncClient(timeout=120.0) as client:
        r = await client.post(OLLAMA_CHAT_URL, json=payload)
        if r.status_code != 200:
            raise LLMError(f"ollama_chat_4b error {r.status_code}: {r.text}")
        data = r.json()
        # –æ–∂–∏–¥–∞–µ–º {"reply": "...", "raw": {...}}
        reply = data.get("reply", "")
        return {
            "model": model or "default",
            "choices": [
                {"message": {"role": "assistant", "content": reply}}
            ],
            "raw": data.get("raw"),
        }

## FILE: requirements.txt
annotated-doc==0.0.4
annotated-types==0.7.0
anyio==4.12.1
attrs==25.4.0
backoff==2.2.1
bcrypt==5.0.0
build==1.4.0
certifi==2026.1.4
charset-normalizer==3.4.4
chromadb==1.4.1
click==8.3.1
coloredlogs==15.0.1
cuda-bindings==12.9.4
cuda-pathfinder==1.3.3
distro==1.9.0
dnspython==2.8.0
durationpy==0.10
email-validator==2.3.0
fastapi==0.128.1
fastapi-cli==0.0.20
fastapi-cloud-cli==0.11.0
fastar==0.8.0
filelock==3.20.3
flatbuffers==25.12.19
fsspec==2026.1.0
googleapis-common-protos==1.72.0
grpcio==1.76.0
h11==0.16.0
hf-xet==1.2.0
httpcore==1.0.9
httptools==0.7.1
httpx==0.28.1
huggingface_hub==1.4.0
humanfriendly==10.0
idna==3.11
importlib_metadata==8.7.1
importlib_resources==6.5.2
Jinja2==3.1.6
joblib==1.5.3
jsonschema==4.26.0
jsonschema-specifications==2025.9.1
kubernetes==35.0.0
markdown-it-py==4.0.0
MarkupSafe==3.0.3
mdurl==0.1.2
mmh3==5.2.0
mpmath==1.3.0
networkx==3.6.1
numpy==2.4.2
nvidia-cublas-cu12==12.8.4.1
nvidia-cuda-cupti-cu12==12.8.90
nvidia-cuda-nvrtc-cu12==12.8.93
nvidia-cuda-runtime-cu12==12.8.90
nvidia-cudnn-cu12==9.10.2.21
nvidia-cufft-cu12==11.3.3.83
nvidia-cufile-cu12==1.13.1.3
nvidia-curand-cu12==10.3.9.90
nvidia-cusolver-cu12==11.7.3.90
nvidia-cusparse-cu12==12.5.8.93
nvidia-cusparselt-cu12==0.7.1
nvidia-nccl-cu12==2.27.5
nvidia-nvjitlink-cu12==12.8.93
nvidia-nvshmem-cu12==3.4.5
nvidia-nvtx-cu12==12.8.90
oauthlib==3.3.1
onnxruntime==1.23.2
opentelemetry-api==1.39.1
opentelemetry-exporter-otlp-proto-common==1.39.1
opentelemetry-exporter-otlp-proto-grpc==1.39.1
opentelemetry-proto==1.39.1
opentelemetry-sdk==1.39.1
opentelemetry-semantic-conventions==0.60b1
orjson==3.11.7
overrides==7.7.0
packaging==26.0
pip==24.0
posthog==5.4.0
protobuf==6.33.5
pybase64==1.4.3
pydantic==2.12.5
pydantic_core==2.41.5
pydantic-extra-types==2.11.0
pydantic-settings==2.12.0
Pygments==2.19.2
PyPika==0.51.1
pyproject_hooks==1.2.0
python-dateutil==2.9.0.post0
python-dotenv==1.2.1
python-multipart==0.0.22
PyYAML==6.0.3
referencing==0.37.0
regex==2026.1.15
requests==2.32.5
requests-oauthlib==2.0.0
rich==14.3.2
rich-toolkit==0.18.1
rignore==0.7.6
rpds-py==0.30.0
safetensors==0.7.0
scikit-learn==1.8.0
scipy==1.17.0
sentence-transformers==5.2.2
sentry-sdk==2.52.0
setuptools==80.10.2
shellingham==1.5.4
six==1.17.0
starlette==0.50.0
sympy==1.14.0
tenacity==9.1.3
threadpoolctl==3.6.0
tokenizers==0.22.2
torch==2.10.0
tqdm==4.67.3
transformers==5.0.0
triton==3.6.0
typer==0.21.1
typer-slim==0.21.1
typing_extensions==4.15.0
typing-inspection==0.4.2
urllib3==2.6.3
uvicorn==0.40.0
uvloop==0.22.1
watchfiles==1.1.1
websocket-client==1.9.0
websockets==16.0
zipp==3.23.0

## FILE: tests/test_api.py
import os
import sys
from pathlib import Path

from fastapi.testclient import TestClient


PROJECT_ROOT = Path(__file__).parent.parent.resolve()
if str(PROJECT_ROOT) not in sys.path:
    sys.path.insert(0, str(PROJECT_ROOT))

from app.main import app  # noqa: E402


client = TestClient(app)


def test_health_ok():
    resp = client.get("/api/v1/health")
    assert resp.status_code == 200
    data = resp.json()
    assert data["status"] == "ok"
    assert data["environment"] in ("dev", "test", "prod")
    assert "llm_mode" in data


def test_tasks_list_contains_demo_tasks():
    resp = client.get("/api/v1/tasks")
    assert resp.status_code == 200
    data = resp.json()
    task_ids = [t["task_id"] for t in data]
    assert "demo_hello" in task_ids
    assert "demo_rules" in task_ids


def test_get_task_demo_rules():
    resp = client.get("/api/v1/tasks/demo_rules")
    assert resp.status_code == 200
    data = resp.json()
    assert data["task_id"] == "demo_rules"
    assert data["task_type"] == "demo"
    assert "Demo" in data["name"]


def test_task_query_demo_hello():
    resp = client.post(
        "/api/v1/task/query",
        json={
            "task_id": "demo_hello",
            "task_type": "demo",
            "query": "–ö—Ä–∞—Ç–∫–æ –æ–ø–∏—à–∏ –¥–µ–º–æ-—Å–∏—Å—Ç–µ–º—É –∑–∞—è–≤–æ–∫.",
        },
    )
    assert resp.status_code == 200
    data = resp.json()
    assert data["ok"] is True
    assert isinstance(data["answer"], str)
    assert data["answer"]


def test_task_query_corporate_forbidden_in_dev():
    resp = client.post(
        "/api/v1/task/query",
        json={
            "task_id": "demo_hello",
            "task_type": "corporate",
            "query": "–ü–æ–ø—Ä–æ–±—É–π –≤—ã–ø–æ–ª–Ω–∏—Ç—å –∫–æ—Ä–ø–æ—Ä–∞—Ç–∏–≤–Ω—É—é –∑–∞–¥–∞—á—É –≤ dev.",
        },
    )
    assert resp.status_code in (400, 403)


def test_generic_query_routes_to_demo_hello():
    resp = client.post(
        "/api/v1/query",
        json={
            "query": "–†–∞—Å—Å–∫–∞–∂–∏ –∫—Ä–∞—Ç–∫–æ, –∫–∞–∫ —É –Ω–∞—Å —É—Å—Ç—Ä–æ–µ–Ω–∞ –¥–µ–º–æ-—Å–∏—Å—Ç–µ–º–∞ –∑–∞—è–≤–æ–∫ –∏ –∫–∞–∫–∏–µ –µ—ë –æ—Å–Ω–æ–≤–Ω—ã–µ –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–∏?",
            "debug": False,
        },
    )
    # –í dev-—Ç–µ—Å—Ç–∞—Ö –Ω–µ –∂—ë—Å—Ç–∫–æ –∑–∞–≤—è–∑—ã–≤–∞–µ–º—Å—è –Ω–∞ 200, —Ç–∞–∫ –∫–∞–∫ LLM –º–æ–∂–µ—Ç –±—ã—Ç—å –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω.
    assert resp.status_code < 500
    data = resp.json()
    assert isinstance(data, dict)
    assert "ok" in data
    assert "routed_task_id" in data
    assert "routed_task_type" in data

